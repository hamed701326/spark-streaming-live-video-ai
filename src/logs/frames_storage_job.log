23/04/08 08:42:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
23/04/08 08:42:08 INFO SparkContext: Running Spark version 3.0.0
23/04/08 08:42:08 INFO ResourceUtils: ==============================================================
23/04/08 08:42:08 INFO ResourceUtils: Resources for spark.driver:

23/04/08 08:42:08 INFO ResourceUtils: ==============================================================
23/04/08 08:42:08 INFO SparkContext: Submitted application: frames-storage
23/04/08 08:42:08 INFO SecurityManager: Changing view acls to: spark
23/04/08 08:42:08 INFO SecurityManager: Changing modify acls to: spark
23/04/08 08:42:08 INFO SecurityManager: Changing view acls groups to: 
23/04/08 08:42:08 INFO SecurityManager: Changing modify acls groups to: 
23/04/08 08:42:08 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(spark); groups with view permissions: Set(); users  with modify permissions: Set(spark); groups with modify permissions: Set()
23/04/08 08:42:09 INFO Utils: Successfully started service 'sparkDriver' on port 32891.
23/04/08 08:42:10 INFO SparkEnv: Registering MapOutputTracker
23/04/08 08:42:10 INFO SparkEnv: Registering BlockManagerMaster
23/04/08 08:42:10 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
23/04/08 08:42:10 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
23/04/08 08:42:10 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
23/04/08 08:42:10 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-1075dbd8-2f88-4a6f-be3d-0cf57d618543
23/04/08 08:42:10 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
23/04/08 08:42:11 INFO SparkEnv: Registering OutputCommitCoordinator
23/04/08 08:42:12 INFO Utils: Successfully started service 'SparkUI' on port 4040.
23/04/08 08:42:13 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://406ecabee5d0:4040
23/04/08 08:42:13 INFO SparkContext: Added JAR file:///opt/bitnami/spark/jars/spark-sql-kafka-0-10_2.12-3.0.0.jar at spark://406ecabee5d0:32891/jars/spark-sql-kafka-0-10_2.12-3.0.0.jar with timestamp 1680943333163
23/04/08 08:42:13 INFO SparkContext: Added JAR file:///opt/bitnami/spark/jars/kafka-clients-2.6.0.jar at spark://406ecabee5d0:32891/jars/kafka-clients-2.6.0.jar with timestamp 1680943333172
23/04/08 08:42:13 INFO SparkContext: Added JAR file:///opt/bitnami/spark/jars/spark-streaming-kafka-0-10_2.12-3.0.0.jar at spark://406ecabee5d0:32891/jars/spark-streaming-kafka-0-10_2.12-3.0.0.jar with timestamp 1680943333172
23/04/08 08:42:13 INFO SparkContext: Added JAR file:///opt/bitnami/spark/jars/spark-token-provider-kafka-0-10_2.12-3.0.0.jar at spark://406ecabee5d0:32891/jars/spark-token-provider-kafka-0-10_2.12-3.0.0.jar with timestamp 1680943333173
23/04/08 08:42:13 INFO SparkContext: Added JAR file:///opt/bitnami/spark/jars/commons-pool2-2.8.1.jar at spark://406ecabee5d0:32891/jars/commons-pool2-2.8.1.jar with timestamp 1680943333179
23/04/08 08:42:13 INFO SparkContext: Added JAR file:///opt/bitnami/spark/jars/spark-cassandra-connector-assembly_2.12-3.0.0.jar at spark://406ecabee5d0:32891/jars/spark-cassandra-connector-assembly_2.12-3.0.0.jar with timestamp 1680943333180
23/04/08 08:42:13 INFO SparkContext: Added file file:///opt/bitnami/spark/spark-jobs/cfg.zip at spark://406ecabee5d0:32891/files/cfg.zip with timestamp 1680943333189
23/04/08 08:42:13 INFO Utils: Copying /opt/bitnami/spark/spark-jobs/cfg.zip to /tmp/spark-c1a48cba-5926-4656-9839-cb699033227c/userFiles-750a8548-9013-424c-978c-5b8d4b88535e/cfg.zip
23/04/08 08:42:15 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark:7077...
23/04/08 08:42:16 INFO TransportClientFactory: Successfully created connection to spark/172.20.0.7:7077 after 379 ms (0 ms spent in bootstraps)
23/04/08 08:42:17 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20230408084217-0000
23/04/08 08:42:18 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41863.
23/04/08 08:42:18 INFO NettyBlockTransferService: Server created on 406ecabee5d0:41863
23/04/08 08:42:18 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
23/04/08 08:42:18 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 406ecabee5d0, 41863, None)
23/04/08 08:42:18 INFO BlockManagerMasterEndpoint: Registering block manager 406ecabee5d0:41863 with 366.3 MiB RAM, BlockManagerId(driver, 406ecabee5d0, 41863, None)
23/04/08 08:42:18 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 406ecabee5d0, 41863, None)
23/04/08 08:42:18 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 406ecabee5d0, 41863, None)
23/04/08 08:42:18 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20230408084217-0000/0 on worker-20230408083931-172.20.0.6-44083 (172.20.0.6:44083) with 1 core(s)
23/04/08 08:42:18 INFO StandaloneSchedulerBackend: Granted executor ID app-20230408084217-0000/0 on hostPort 172.20.0.6:44083 with 1 core(s), 1024.0 MiB RAM
23/04/08 08:42:20 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230408084217-0000/0 is now RUNNING
23/04/08 08:42:22 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
23/04/08 08:42:24 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/opt/bitnami/spark/spark-warehouse').
23/04/08 08:42:24 INFO SharedState: Warehouse path is 'file:/opt/bitnami/spark/spark-warehouse'.
23/04/08 08:42:50 WARN StreamingQueryManager: Temporary checkpoint location created which is deleted normally when the query didn't fail: /tmp/temporary-aee5f4ab-4485-4c7f-83b5-df84caf88e7f. If it's required to delete it under any circumstances, please set spark.sql.streaming.forceDeleteTempCheckpointLocation to true. Important to know deleting temp checkpoint folder is best effort.
