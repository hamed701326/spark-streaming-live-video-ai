Container zookeeper  Created
Container spark  Created
Container spark-worker-4  Created
Container spark-worker-3  Created
Container spark-worker-1  Created
Container spark-worker-2  Created
Container kafka  Created
Container nginx  Created
Container cassandra  Created
Container api  Created
Container video-app  Created
Attaching to api, cassandra, kafka, nginx, spark, spark-worker-1, spark-worker-2, spark-worker-3, spark-worker-4, video-app, zookeeper
zookeeper       | [38;5;6mzookeeper [38;5;5m08:38:58.71 [0m
zookeeper       | [38;5;6mzookeeper [38;5;5m08:38:58.80 [0m[1mWelcome to the Bitnami zookeeper container[0m
zookeeper       | [38;5;6mzookeeper [38;5;5m08:38:58.84 [0mSubscribe to project updates by watching [1mhttps://github.com/bitnami/containers[0m
zookeeper       | [38;5;6mzookeeper [38;5;5m08:38:58.89 [0mSubmit issues and feature requests at [1mhttps://github.com/bitnami/containers/issues[0m
zookeeper       | [38;5;6mzookeeper [38;5;5m08:38:58.94 [0m
zookeeper       | [38;5;6mzookeeper [38;5;5m08:38:58.99 [0m[38;5;2mINFO [0m ==> ** Starting ZooKeeper setup **
spark-worker-2  | [38;5;6m [38;5;5m08:38:58.99 [0m
spark-worker-2  | [38;5;6m [38;5;5m08:38:59.04 [0m[1mWelcome to the Bitnami spark container[0m
spark-worker-2  | [38;5;6m [38;5;5m08:38:59.07 [0mSubscribe to project updates by watching [1mhttps://github.com/bitnami/bitnami-docker-spark[0m
spark-worker-2  | [38;5;6m [38;5;5m08:38:59.11 [0mSubmit issues and feature requests at [1mhttps://github.com/bitnami/bitnami-docker-spark/issues[0m
spark-worker-4  | [38;5;6m [38;5;5m08:38:59.13 [0m
spark-worker-2  | [38;5;6m [38;5;5m08:38:59.16 [0m
spark-worker-4  | [38;5;6m [38;5;5m08:38:59.19 [0m[1mWelcome to the Bitnami spark container[0m
spark-worker-1  | [38;5;6m [38;5;5m08:38:59.17 [0m
spark-worker-4  | [38;5;6m [38;5;5m08:38:59.21 [0mSubscribe to project updates by watching [1mhttps://github.com/bitnami/bitnami-docker-spark[0m
spark-worker-1  | [38;5;6m [38;5;5m08:38:59.25 [0m[1mWelcome to the Bitnami spark container[0m
spark-worker-4  | [38;5;6m [38;5;5m08:38:59.29 [0mSubmit issues and feature requests at [1mhttps://github.com/bitnami/bitnami-docker-spark/issues[0m
spark           | [38;5;6m [38;5;5m08:38:59.30 [0m
spark-worker-4  | [38;5;6m [38;5;5m08:38:59.34 [0m
spark-worker-1  | [38;5;6m [38;5;5m08:38:59.34 [0mSubscribe to project updates by watching [1mhttps://github.com/bitnami/bitnami-docker-spark[0m
spark-worker-3  | [38;5;6m [38;5;5m08:38:59.35 [0m
spark           | [38;5;6m [38;5;5m08:38:59.37 [0m[1mWelcome to the Bitnami spark container[0m
spark-worker-1  | [38;5;6m [38;5;5m08:38:59.40 [0mSubmit issues and feature requests at [1mhttps://github.com/bitnami/bitnami-docker-spark/issues[0m
spark           | [38;5;6m [38;5;5m08:38:59.41 [0mSubscribe to project updates by watching [1mhttps://github.com/bitnami/bitnami-docker-spark[0m
spark-worker-3  | [38;5;6m [38;5;5m08:38:59.43 [0m[1mWelcome to the Bitnami spark container[0m
kafka           | [38;5;6mkafka [38;5;5m08:38:59.41 [0m
spark-worker-1  | [38;5;6m [38;5;5m08:38:59.45 [0m
spark-worker-2  | [38;5;6m [38;5;5m08:38:59.46 [0m[38;5;2mINFO [0m ==> ** Starting Spark setup **
spark           | [38;5;6m [38;5;5m08:38:59.45 [0mSubmit issues and feature requests at [1mhttps://github.com/bitnami/bitnami-docker-spark/issues[0m
kafka           | [38;5;6mkafka [38;5;5m08:38:59.48 [0m[1mWelcome to the Bitnami kafka container[0m
spark-worker-3  | [38;5;6m [38;5;5m08:38:59.50 [0mSubscribe to project updates by watching [1mhttps://github.com/bitnami/bitnami-docker-spark[0m
spark           | [38;5;6m [38;5;5m08:38:59.51 [0m
kafka           | [38;5;6mkafka [38;5;5m08:38:59.51 [0mSubscribe to project updates by watching [1mhttps://github.com/bitnami/containers[0m
spark-worker-3  | [38;5;6m [38;5;5m08:38:59.54 [0mSubmit issues and feature requests at [1mhttps://github.com/bitnami/bitnami-docker-spark/issues[0m
spark-worker-4  | [38;5;6m [38;5;5m08:38:59.54 [0m[38;5;2mINFO [0m ==> ** Starting Spark setup **
kafka           | [38;5;6mkafka [38;5;5m08:38:59.56 [0mSubmit issues and feature requests at [1mhttps://github.com/bitnami/containers/issues[0m
zookeeper       | [38;5;6mzookeeper [38;5;5m08:38:59.59 [0m[38;5;3mWARN [0m ==> You have set the environment variable ALLOW_ANONYMOUS_LOGIN=yes. For safety reasons, do not use this flag in a production environment.
kafka           | [38;5;6mkafka [38;5;5m08:38:59.61 [0m
spark-worker-3  | [38;5;6m [38;5;5m08:38:59.61 [0m
kafka           | [38;5;6mkafka [38;5;5m08:38:59.65 [0m[38;5;2mINFO [0m ==> ** Starting Kafka setup **
spark-worker-1  | [38;5;6m [38;5;5m08:38:59.66 [0m[38;5;2mINFO [0m ==> ** Starting Spark setup **
spark           | [38;5;6m [38;5;5m08:38:59.69 [0m[38;5;2mINFO [0m ==> ** Starting Spark setup **
spark-worker-3  | [38;5;6m [38;5;5m08:38:59.81 [0m[38;5;2mINFO [0m ==> ** Starting Spark setup **
spark-worker-2  | [38;5;6m [38;5;5m08:38:59.85 [0m[38;5;2mINFO [0m ==> Detected mounted configuration file...
zookeeper       | [38;5;6mzookeeper [38;5;5m08:38:59.89 [0m[38;5;2mINFO [0m ==> Initializing ZooKeeper...
zookeeper       | [38;5;6mzookeeper [38;5;5m08:38:59.91 [0m[38;5;2mINFO [0m ==> User injected custom configuration detected!
spark-worker-2  | [38;5;6m [38;5;5m08:38:59.93 [0m[38;5;2mINFO [0m ==> ** Spark setup finished! **
spark-worker-2  | 
spark-worker-4  | [38;5;6m [38;5;5m08:38:59.95 [0m[38;5;2mINFO [0m ==> Detected mounted configuration file...
spark-worker-4  | [38;5;6m [38;5;5m08:38:59.99 [0m[38;5;2mINFO [0m ==> ** Spark setup finished! **
spark-worker-4  | 
zookeeper       | [38;5;6mzookeeper [38;5;5m08:39:00.01 [0m[38;5;2mINFO [0m ==> Deploying ZooKeeper with persisted data...
zookeeper       | [38;5;6mzookeeper [38;5;5m08:39:00.06 [0m[38;5;2mINFO [0m ==> ** ZooKeeper setup finished! **
zookeeper       | 
spark           | [38;5;6m [38;5;5m08:39:00.07 [0m[38;5;2mINFO [0m ==> Detected mounted configuration file...
spark-worker-1  | [38;5;6m [38;5;5m08:39:00.10 [0m[38;5;2mINFO [0m ==> Detected mounted configuration file...
spark           | [38;5;6m [38;5;5m08:39:00.11 [0m[38;5;2mINFO [0m ==> ** Spark setup finished! **
spark           | 
spark-worker-1  | [38;5;6m [38;5;5m08:39:00.13 [0m[38;5;2mINFO [0m ==> ** Spark setup finished! **
spark-worker-1  | 
spark-worker-2  | [38;5;6m [38;5;5m08:39:00.19 [0m[38;5;2mINFO [0m ==> ** Starting Spark in worker mode **
spark-worker-4  | [38;5;6m [38;5;5m08:39:00.22 [0m[38;5;2mINFO [0m ==> ** Starting Spark in worker mode **
spark-worker-3  | [38;5;6m [38;5;5m08:39:00.25 [0m[38;5;2mINFO [0m ==> Detected mounted configuration file...
zookeeper       | [38;5;6mzookeeper [38;5;5m08:39:00.24 [0m[38;5;2mINFO [0m ==> ** Starting ZooKeeper **
spark-worker-1  | [38;5;6m [38;5;5m08:39:00.32 [0m[38;5;2mINFO [0m ==> ** Starting Spark in worker mode **
spark           | [38;5;6m [38;5;5m08:39:00.32 [0m[38;5;2mINFO [0m ==> ** Starting Spark in master mode **
spark-worker-3  | [38;5;6m [38;5;5m08:39:00.33 [0m[38;5;2mINFO [0m ==> ** Spark setup finished! **
spark-worker-3  | 
zookeeper       | /opt/bitnami/java/bin/java
zookeeper       | ZooKeeper JMX enabled by default
zookeeper       | Using config: /opt/bitnami/zookeeper/bin/../conf/zoo.cfg
spark-worker-3  | [38;5;6m [38;5;5m08:39:00.65 [0m[38;5;2mINFO [0m ==> ** Starting Spark in worker mode **
spark-worker-2  | starting org.apache.spark.deploy.worker.Worker, logging to /opt/bitnami/spark/logs/spark--org.apache.spark.deploy.worker.Worker-1-0d054d7c07ed.out
spark-worker-4  | starting org.apache.spark.deploy.worker.Worker, logging to /opt/bitnami/spark/logs/spark--org.apache.spark.deploy.worker.Worker-1-00a985f891c6.out
spark-worker-1  | starting org.apache.spark.deploy.worker.Worker, logging to /opt/bitnami/spark/logs/spark--org.apache.spark.deploy.worker.Worker-1-573a7459998f.out
spark           | starting org.apache.spark.deploy.master.Master, logging to /opt/bitnami/spark/logs/spark--org.apache.spark.deploy.master.Master-1-406ecabee5d0.out
spark-worker-3  | starting org.apache.spark.deploy.worker.Worker, logging to /opt/bitnami/spark/logs/spark--org.apache.spark.deploy.worker.Worker-1-3be77bba0b3a.out
kafka           | [38;5;6mkafka [38;5;5m08:39:01.48 [0m[38;5;3mWARN [0m ==> You set the environment variable ALLOW_PLAINTEXT_LISTENER=yes. For safety reasons, do not use this flag in a production environment.
kafka           | [38;5;6mkafka [38;5;5m08:39:02.02 [0m[38;5;2mINFO [0m ==> Initializing Kafka...
kafka           | [38;5;6mkafka [38;5;5m08:39:02.32 [0m[38;5;2mINFO [0m ==> No injected configuration files found, creating default config files
cassandra       | CompilerOracle: dontinline org/apache/cassandra/db/Columns$Serializer.deserializeLargeSubset (Lorg/apache/cassandra/io/util/DataInputPlus;Lorg/apache/cassandra/db/Columns;I)Lorg/apache/cassandra/db/Columns;
cassandra       | CompilerOracle: dontinline org/apache/cassandra/db/Columns$Serializer.serializeLargeSubset (Ljava/util/Collection;ILorg/apache/cassandra/db/Columns;ILorg/apache/cassandra/io/util/DataOutputPlus;)V
cassandra       | CompilerOracle: dontinline org/apache/cassandra/db/Columns$Serializer.serializeLargeSubsetSize (Ljava/util/Collection;ILorg/apache/cassandra/db/Columns;I)I
cassandra       | CompilerOracle: dontinline org/apache/cassandra/db/commitlog/AbstractCommitLogSegmentManager.advanceAllocatingFrom (Lorg/apache/cassandra/db/commitlog/CommitLogSegment;)V
cassandra       | CompilerOracle: dontinline org/apache/cassandra/db/transform/BaseIterator.tryGetMoreContents ()Z
cassandra       | CompilerOracle: dontinline org/apache/cassandra/db/transform/StoppingTransformation.stop ()V
cassandra       | CompilerOracle: dontinline org/apache/cassandra/db/transform/StoppingTransformation.stopInPartition ()V
cassandra       | CompilerOracle: dontinline org/apache/cassandra/io/util/BufferedDataOutputStreamPlus.doFlush (I)V
cassandra       | CompilerOracle: dontinline org/apache/cassandra/io/util/BufferedDataOutputStreamPlus.writeExcessSlow ()V
cassandra       | CompilerOracle: dontinline org/apache/cassandra/io/util/BufferedDataOutputStreamPlus.writeSlow (JI)V
cassandra       | CompilerOracle: dontinline org/apache/cassandra/io/util/RebufferingInputStream.readPrimitiveSlowly (I)J
cassandra       | CompilerOracle: inline org/apache/cassandra/db/rows/UnfilteredSerializer.serializeRowBody (Lorg/apache/cassandra/db/rows/Row;ILorg/apache/cassandra/db/SerializationHeader;Lorg/apache/cassandra/io/util/DataOutputPlus;)V
cassandra       | CompilerOracle: inline org/apache/cassandra/io/util/Memory.checkBounds (JJ)V
cassandra       | CompilerOracle: inline org/apache/cassandra/io/util/SafeMemory.checkBounds (JJ)V
cassandra       | CompilerOracle: inline org/apache/cassandra/utils/AsymmetricOrdering.selectBoundary (Lorg/apache/cassandra/utils/AsymmetricOrdering/Op;II)I
cassandra       | CompilerOracle: inline org/apache/cassandra/utils/AsymmetricOrdering.strictnessOfLessThan (Lorg/apache/cassandra/utils/AsymmetricOrdering/Op;)I
cassandra       | CompilerOracle: inline org/apache/cassandra/utils/BloomFilter.indexes (Lorg/apache/cassandra/utils/IFilter/FilterKey;)[J
cassandra       | CompilerOracle: inline org/apache/cassandra/utils/BloomFilter.setIndexes (JJIJ[J)V
cassandra       | CompilerOracle: inline org/apache/cassandra/utils/ByteBufferUtil.compare (Ljava/nio/ByteBuffer;[B)I
cassandra       | CompilerOracle: inline org/apache/cassandra/utils/ByteBufferUtil.compare ([BLjava/nio/ByteBuffer;)I
cassandra       | CompilerOracle: inline org/apache/cassandra/utils/ByteBufferUtil.compareUnsigned (Ljava/nio/ByteBuffer;Ljava/nio/ByteBuffer;)I
cassandra       | CompilerOracle: inline org/apache/cassandra/utils/FastByteOperations$UnsafeOperations.compareTo (Ljava/lang/Object;JILjava/lang/Object;JI)I
cassandra       | CompilerOracle: inline org/apache/cassandra/utils/FastByteOperations$UnsafeOperations.compareTo (Ljava/lang/Object;JILjava/nio/ByteBuffer;)I
cassandra       | CompilerOracle: inline org/apache/cassandra/utils/FastByteOperations$UnsafeOperations.compareTo (Ljava/nio/ByteBuffer;Ljava/nio/ByteBuffer;)I
cassandra       | CompilerOracle: inline org/apache/cassandra/utils/vint/VIntCoding.encodeVInt (JI)[B
spark-worker-3  | Spark Command: /opt/bitnami/java/bin/java -cp /opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/* -Xmx1g org.apache.spark.deploy.worker.Worker --webui-port 8081 spark://spark:7077
spark-worker-3  | ========================================
spark-worker-4  | Spark Command: /opt/bitnami/java/bin/java -cp /opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/* -Xmx1g org.apache.spark.deploy.worker.Worker --webui-port 8081 spark://spark:7077
spark-worker-4  | ========================================
spark-worker-2  | Spark Command: /opt/bitnami/java/bin/java -cp /opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/* -Xmx1g org.apache.spark.deploy.worker.Worker --webui-port 8081 spark://spark:7077
spark-worker-2  | ========================================
spark           | Spark Command: /opt/bitnami/java/bin/java -cp /opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/* -Xmx1g org.apache.spark.deploy.master.Master --host 406ecabee5d0 --port 7077 --webui-port 8080
spark           | ========================================
spark-worker-1  | Spark Command: /opt/bitnami/java/bin/java -cp /opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/* -Xmx1g org.apache.spark.deploy.worker.Worker --webui-port 8081 spark://spark:7077
spark-worker-1  | ========================================
cassandra       | INFO  [main] 2023-04-08 08:39:06,003 YamlConfigurationLoader.java:93 - Configuration location: file:/etc/cassandra/cassandra.yaml
cassandra       | INFO  [main] 2023-04-08 08:39:06,904 Config.java:555 - Node configuration:[allocate_tokens_for_keyspace=null; allow_extra_insecure_udfs=false; allow_insecure_udfs=false; authenticator=AllowAllAuthenticator; authorizer=AllowAllAuthorizer; auto_bootstrap=true; auto_snapshot=true; back_pressure_enabled=false; back_pressure_strategy=org.apache.cassandra.net.RateBasedBackPressure{high_ratio=0.9, factor=5, flow=FAST}; batch_size_fail_threshold_in_kb=50; batch_size_warn_threshold_in_kb=5; batchlog_replay_throttle_in_kb=1024; broadcast_address=172.20.0.10; broadcast_rpc_address=172.20.0.10; buffer_pool_use_heap_if_exhausted=true; cache_load_timeout_seconds=30; cas_contention_timeout_in_ms=1000; cdc_enabled=false; cdc_free_space_check_interval_ms=250; cdc_raw_directory=null; cdc_total_space_in_mb=0; check_for_duplicate_rows_during_compaction=true; check_for_duplicate_rows_during_reads=true; client_encryption_options=<REDACTED>; cluster_name=Test Cluster; column_index_cache_size_in_kb=2; column_index_size_in_kb=64; commit_failure_policy=stop; commitlog_compression=null; commitlog_directory=null; commitlog_max_compression_buffers_in_pool=3; commitlog_periodic_queue_size=-1; commitlog_segment_size_in_mb=32; commitlog_sync=periodic; commitlog_sync_batch_window_in_ms=NaN; commitlog_sync_period_in_ms=10000; commitlog_total_space_in_mb=null; compaction_large_partition_warning_threshold_mb=100; compaction_throughput_mb_per_sec=16; concurrent_compactors=null; concurrent_counter_writes=32; concurrent_materialized_view_writes=32; concurrent_reads=32; concurrent_replicates=null; concurrent_writes=32; counter_cache_keys_to_save=2147483647; counter_cache_save_period=7200; counter_cache_size_in_mb=null; counter_write_request_timeout_in_ms=5000; credentials_cache_max_entries=1000; credentials_update_interval_in_ms=-1; credentials_validity_in_ms=2000; cross_node_timeout=false; data_file_directories=[Ljava.lang.String;@65d6b83b; disk_access_mode=auto; disk_failure_policy=stop; disk_optimization_estimate_percentile=0.95; disk_optimization_page_cross_chance=0.1; disk_optimization_strategy=ssd; dynamic_snitch=true; dynamic_snitch_badness_threshold=0.1; dynamic_snitch_reset_interval_in_ms=600000; dynamic_snitch_update_interval_in_ms=100; enable_drop_compact_storage=false; enable_materialized_views=true; enable_sasi_indexes=true; enable_scripted_user_defined_functions=false; enable_user_defined_functions=false; enable_user_defined_functions_threads=true; encryption_options=<REDACTED>; endpoint_snitch=SimpleSnitch; file_cache_round_up=null; file_cache_size_in_mb=null; force_new_prepared_statement_behaviour=false; gc_log_threshold_in_ms=200; gc_warn_threshold_in_ms=1000; hinted_handoff_disabled_datacenters=[]; hinted_handoff_enabled=true; hinted_handoff_throttle_in_kb=1024; hints_compression=null; hints_directory=null; hints_flush_period_in_ms=10000; incremental_backups=false; index_interval=null; index_summary_capacity_in_mb=null; index_summary_resize_interval_in_minutes=60; initial_token=null; inter_dc_stream_throughput_outbound_megabits_per_sec=200; inter_dc_tcp_nodelay=false; internode_authenticator=null; internode_compression=dc; internode_recv_buff_size_in_bytes=0; internode_send_buff_size_in_bytes=0; key_cache_keys_to_save=2147483647; key_cache_save_period=14400; key_cache_size_in_mb=null; listen_address=172.20.0.10; listen_interface=null; listen_interface_prefer_ipv6=false; listen_on_broadcast_address=false; max_hint_window_in_ms=10800000; max_hints_delivery_threads=2; max_hints_file_size_in_mb=128; max_mutation_size_in_kb=null; max_streaming_retries=3; max_value_size_in_mb=256; memtable_allocation_type=heap_buffers; memtable_cleanup_threshold=null; memtable_flush_writers=0; memtable_heap_space_in_mb=null; memtable_offheap_space_in_mb=null; min_free_space_per_drive_in_mb=50; native_transport_flush_in_batches_legacy=true; native_transport_max_concurrent_connections=-1; native_transport_max_concurrent_connections_per_ip=-1; native_transport_max_concurrent_requests_in_bytes=-1; native_transport_max_concurrent_requests_in_bytes_per_ip=-1; native_transport_max_frame_size_in_mb=256; native_transport_max_negotiable_protocol_version=-2147483648; native_transport_max_threads=128; native_transport_port=9042; native_transport_port_ssl=null; num_tokens=256; otc_backlog_expiration_interval_ms=200; otc_coalescing_enough_coalesced_messages=8; otc_coalescing_strategy=DISABLED; otc_coalescing_window_us=200; partitioner=org.apache.cassandra.dht.Murmur3Partitioner; permissions_cache_max_entries=1000; permissions_update_interval_in_ms=-1; permissions_validity_in_ms=2000; phi_convict_threshold=8.0; prepared_statements_cache_size_mb=null; range_request_timeout_in_ms=10000; read_request_timeout_in_ms=5000; repair_session_max_tree_depth=18; request_scheduler=org.apache.cassandra.scheduler.NoScheduler; request_scheduler_id=null; request_scheduler_options=null; request_timeout_in_ms=10000; role_manager=CassandraRoleManager; roles_cache_max_entries=1000; roles_update_interval_in_ms=-1; roles_validity_in_ms=2000; row_cache_class_name=org.apache.cassandra.cache.OHCProvider; row_cache_keys_to_save=2147483647; row_cache_save_period=0; row_cache_size_in_mb=0; rpc_address=0.0.0.0; rpc_interface=null; rpc_interface_prefer_ipv6=false; rpc_keepalive=true; rpc_listen_backlog=50; rpc_max_threads=2147483647; rpc_min_threads=16; rpc_port=9160; rpc_recv_buff_size_in_bytes=null; rpc_send_buff_size_in_bytes=null; rpc_server_type=sync; saved_caches_directory=null; seed_provider=org.apache.cassandra.locator.SimpleSeedProvider{seeds=172.20.0.10}; server_encryption_options=<REDACTED>; slow_query_log_timeout_in_ms=500; snapshot_before_compaction=false; snapshot_on_duplicate_row_detection=false; ssl_storage_port=7001; sstable_preemptive_open_interval_in_mb=50; start_native_transport=true; start_rpc=false; storage_port=7000; stream_throughput_outbound_megabits_per_sec=200; streaming_keep_alive_period_in_secs=300; streaming_socket_timeout_in_ms=86400000; thrift_framed_transport_size_in_mb=15; thrift_max_message_length_in_mb=16; thrift_prepared_statements_cache_size_mb=null; tombstone_failure_threshold=100000; tombstone_warn_threshold=1000; tracetype_query_ttl=86400; tracetype_repair_ttl=604800; transparent_data_encryption_options=org.apache.cassandra.config.TransparentDataEncryptionOptions@d706f19; trickle_fsync=false; trickle_fsync_interval_in_kb=10240; truncate_request_timeout_in_ms=60000; unlogged_batch_across_partitions_warn_threshold=10; user_defined_function_fail_timeout=1500; user_defined_function_warn_timeout=500; user_function_timeout_policy=die; windows_timer_interval=1; write_request_timeout_in_ms=2000]
cassandra       | INFO  [main] 2023-04-08 08:39:06,905 DatabaseDescriptor.java:381 - DiskAccessMode 'auto' determined to be mmap, indexAccessMode is mmap
cassandra       | INFO  [main] 2023-04-08 08:39:06,906 DatabaseDescriptor.java:439 - Global memtable on-heap threshold is enabled at 480MB
cassandra       | INFO  [main] 2023-04-08 08:39:06,906 DatabaseDescriptor.java:443 - Global memtable off-heap threshold is enabled at 480MB
cassandra       | INFO  [main] 2023-04-08 08:39:07,283 RateBasedBackPressure.java:123 - Initialized back-pressure with high ratio: 0.9, factor: 5, flow: FAST, window size: 2000.
cassandra       | INFO  [main] 2023-04-08 08:39:07,284 DatabaseDescriptor.java:781 - Back-pressure is disabled with strategy org.apache.cassandra.net.RateBasedBackPressure{high_ratio=0.9, factor=5, flow=FAST}.
cassandra       | INFO  [main] 2023-04-08 08:39:07,692 JMXServerUtils.java:253 - Configured JMX server at: service:jmx:rmi://127.0.0.1/jndi/rmi://127.0.0.1:7199/jmxrmi
cassandra       | INFO  [main] 2023-04-08 08:39:07,704 CassandraDaemon.java:490 - Hostname: 3a92f3e97e21
cassandra       | INFO  [main] 2023-04-08 08:39:07,705 CassandraDaemon.java:497 - JVM vendor/version: OpenJDK 64-Bit Server VM/1.8.0_362
cassandra       | INFO  [main] 2023-04-08 08:39:07,711 CassandraDaemon.java:498 - Heap size: 1.877GiB/1.877GiB
cassandra       | INFO  [main] 2023-04-08 08:39:07,712 CassandraDaemon.java:503 - Code Cache Non-heap memory: init = 2555904(2496K) used = 5107840(4988K) committed = 5177344(5056K) max = 134217728(131072K)
cassandra       | INFO  [main] 2023-04-08 08:39:07,714 CassandraDaemon.java:503 - Metaspace Non-heap memory: init = 0(0K) used = 20601144(20118K) committed = 21233664(20736K) max = -1(-1K)
cassandra       | INFO  [main] 2023-04-08 08:39:07,720 CassandraDaemon.java:503 - Compressed Class Space Non-heap memory: init = 0(0K) used = 2444944(2387K) committed = 2621440(2560K) max = 1073741824(1048576K)
cassandra       | INFO  [main] 2023-04-08 08:39:07,722 CassandraDaemon.java:503 - Par Eden Space Heap memory: init = 335544320(327680K) used = 107474016(104955K) committed = 335544320(327680K) max = 335544320(327680K)
cassandra       | INFO  [main] 2023-04-08 08:39:07,727 CassandraDaemon.java:503 - Par Survivor Space Heap memory: init = 41943040(40960K) used = 0(0K) committed = 41943040(40960K) max = 41943040(40960K)
cassandra       | INFO  [main] 2023-04-08 08:39:07,727 CassandraDaemon.java:503 - CMS Old Gen Heap memory: init = 1637875712(1599488K) used = 0(0K) committed = 1637875712(1599488K) max = 1637875712(1599488K)
cassandra       | INFO  [main] 2023-04-08 08:39:07,728 CassandraDaemon.java:505 - Classpath: /etc/cassandra:/opt/cassandra/build/classes/main:/opt/cassandra/build/classes/thrift:/opt/cassandra/lib/HdrHistogram-2.1.9.jar:/opt/cassandra/lib/ST4-4.0.8.jar:/opt/cassandra/lib/airline-0.6.jar:/opt/cassandra/lib/antlr-runtime-3.5.2.jar:/opt/cassandra/lib/apache-cassandra-3.11.14.jar:/opt/cassandra/lib/apache-cassandra-thrift-3.11.14.jar:/opt/cassandra/lib/asm-5.0.4.jar:/opt/cassandra/lib/caffeine-2.2.6.jar:/opt/cassandra/lib/cassandra-driver-core-3.0.1-shaded.jar:/opt/cassandra/lib/commons-cli-1.1.jar:/opt/cassandra/lib/commons-codec-1.9.jar:/opt/cassandra/lib/commons-lang3-3.1.jar:/opt/cassandra/lib/commons-math3-3.2.jar:/opt/cassandra/lib/compress-lzf-0.8.4.jar:/opt/cassandra/lib/concurrent-trees-2.4.0.jar:/opt/cassandra/lib/concurrentlinkedhashmap-lru-1.4.jar:/opt/cassandra/lib/disruptor-3.0.1.jar:/opt/cassandra/lib/ecj-4.4.2.jar:/opt/cassandra/lib/guava-18.0.jar:/opt/cassandra/lib/high-scale-lib-1.0.6.jar:/opt/cassandra/lib/hppc-0.5.4.jar:/opt/cassandra/lib/jackson-annotations-2.13.2.jar:/opt/cassandra/lib/jackson-core-2.13.2.jar:/opt/cassandra/lib/jackson-databind-2.13.2.2.jar:/opt/cassandra/lib/jamm-0.3.0.jar:/opt/cassandra/lib/javax.inject-1.jar:/opt/cassandra/lib/jbcrypt-0.4.jar:/opt/cassandra/lib/jcl-over-slf4j-1.7.25.jar:/opt/cassandra/lib/jctools-core-1.2.1.jar:/opt/cassandra/lib/jflex-1.6.0.jar:/opt/cassandra/lib/jna-4.2.2.jar:/opt/cassandra/lib/joda-time-2.4.jar:/opt/cassandra/lib/json-simple-1.1.jar:/opt/cassandra/lib/libthrift-0.9.2.jar:/opt/cassandra/lib/log4j-over-slf4j-1.7.25.jar:/opt/cassandra/lib/logback-classic-1.2.9.jar:/opt/cassandra/lib/logback-core-1.2.9.jar:/opt/cassandra/lib/lz4-1.3.0.jar:/opt/cassandra/lib/metrics-core-3.1.5.jar:/opt/cassandra/lib/metrics-jvm-3.1.5.jar:/opt/cassandra/lib/metrics-logback-3.1.5.jar:/opt/cassandra/lib/netty-all-4.0.44.Final.jar:/opt/cassandra/lib/ohc-core-0.4.4.jar:/opt/cassandra/lib/ohc-core-j8-0.4.4.jar:/opt/cassandra/lib/reporter-config-base-3.0.3.jar:/opt/cassandra/lib/reporter-config3-3.0.3.jar:/opt/cassandra/lib/sigar-1.6.4.jar:/opt/cassandra/lib/slf4j-api-1.7.25.jar:/opt/cassandra/lib/snakeyaml-1.26.jar:/opt/cassandra/lib/snappy-java-1.1.1.7.jar:/opt/cassandra/lib/snowball-stemmer-1.3.0.581.1.jar:/opt/cassandra/lib/stream-2.5.2.jar:/opt/cassandra/lib/thrift-server-0.3.7.jar:/opt/cassandra/lib/jsr223/*/*.jar::/opt/cassandra/lib/jamm-0.3.0.jar
cassandra       | INFO  [main] 2023-04-08 08:39:07,734 CassandraDaemon.java:507 - JVM Arguments: [-Xloggc:/opt/cassandra/logs/gc.log, -ea, -XX:+UseThreadPriorities, -XX:ThreadPriorityPolicy=42, -XX:+HeapDumpOnOutOfMemoryError, -Xss256k, -XX:StringTableSize=1000003, -XX:+AlwaysPreTouch, -XX:-UseBiasedLocking, -XX:+UseTLAB, -XX:+ResizeTLAB, -XX:+UseNUMA, -XX:+PerfDisableSharedMem, -Djava.net.preferIPv4Stack=true, -XX:+UseParNewGC, -XX:+UseConcMarkSweepGC, -XX:+CMSParallelRemarkEnabled, -XX:SurvivorRatio=8, -XX:MaxTenuringThreshold=1, -XX:CMSInitiatingOccupancyFraction=75, -XX:+UseCMSInitiatingOccupancyOnly, -XX:CMSWaitDuration=10000, -XX:+CMSParallelInitialMarkEnabled, -XX:+CMSEdenChunksRecordAlways, -XX:+CMSClassUnloadingEnabled, -XX:+PrintGCDetails, -XX:+PrintGCDateStamps, -XX:+PrintHeapAtGC, -XX:+PrintTenuringDistribution, -XX:+PrintGCApplicationStoppedTime, -XX:+PrintPromotionFailure, -XX:+UseGCLogFileRotation, -XX:NumberOfGCLogFiles=10, -XX:GCLogFileSize=10M, -Xms1962M, -Xmx1962M, -Xmn400M, -XX:+UseCondCardMark, -XX:CompileCommandFile=/etc/cassandra/hotspot_compiler, -javaagent:/opt/cassandra/lib/jamm-0.3.0.jar, -Dcassandra.jmx.local.port=7199, -Dcom.sun.management.jmxremote.authenticate=false, -Dcom.sun.management.jmxremote.password.file=/etc/cassandra/jmxremote.password, -Djava.library.path=/opt/cassandra/lib/sigar-bin, -Dcassandra.libjemalloc=/usr/local/lib/libjemalloc.so, -XX:OnOutOfMemoryError=kill -9 %p, -Dlogback.configurationFile=logback.xml, -Dcassandra.logdir=/opt/cassandra/logs, -Dcassandra.storagedir=/opt/cassandra/data, -Dcassandra-foreground=yes]
kafka           | [38;5;6mkafka [38;5;5m08:39:07.93 [0m[38;5;2mINFO [0m ==> ** Kafka setup finished! **
kafka           | 
cassandra       | WARN  [main] 2023-04-08 08:39:07,947 NativeLibrary.java:189 - Unable to lock JVM memory (ENOMEM). This can result in part of the JVM being swapped out, especially with mmapped I/O enabled. Increase RLIMIT_MEMLOCK or run Cassandra as root.
cassandra       | INFO  [main] 2023-04-08 08:39:07,956 StartupChecks.java:140 - jemalloc seems to be preloaded from /usr/local/lib/libjemalloc.so
cassandra       | WARN  [main] 2023-04-08 08:39:07,957 StartupChecks.java:169 - JMX is not enabled to receive remote connections. Please see cassandra-env.sh for more info.
cassandra       | INFO  [main] 2023-04-08 08:39:07,960 SigarLibrary.java:44 - Initializing SIGAR library
cassandra       | INFO  [main] 2023-04-08 08:39:08,022 SigarLibrary.java:57 - Could not initialize SIGAR library org.hyperic.sigar.Sigar.getFileSystemListNative()[Lorg/hyperic/sigar/FileSystem; 
cassandra       | INFO  [main] 2023-04-08 08:39:08,023 SigarLibrary.java:185 - Sigar could not be initialized, test for checking degraded mode omitted.
cassandra       | WARN  [main] 2023-04-08 08:39:08,025 StartupChecks.java:311 - Maximum number of memory map areas per process (vm.max_map_count) 262144 is too low, recommended value: 1048575, you can change it with sysctl.
kafka           | [38;5;6mkafka [38;5;5m08:39:08.22 [0m[38;5;2mINFO [0m ==> ** Starting Kafka **
cassandra       | INFO  [main] 2023-04-08 08:39:08,444 QueryProcessor.java:121 - Initialized prepared statement caches with 10 MB (native) and 10 MB (Thrift)
cassandra       | INFO  [main] 2023-04-08 08:39:09,393 ColumnFamilyStore.java:432 - Initializing system.IndexInfo
cassandra       | INFO  [main] 2023-04-08 08:39:11,947 ColumnFamilyStore.java:432 - Initializing system.batches
cassandra       | INFO  [main] 2023-04-08 08:39:12,045 ColumnFamilyStore.java:432 - Initializing system.paxos
cassandra       | INFO  [main] 2023-04-08 08:39:12,126 ColumnFamilyStore.java:432 - Initializing system.local
cassandra       | INFO  [SSTableBatchOpen:1] 2023-04-08 08:39:12,230 BufferPool.java:251 - Global buffer pool is enabled, when pool is exhausted (max is 480.000MiB) it will allocate on heap
cassandra       | INFO  [main] 2023-04-08 08:39:13,298 CacheService.java:103 - Initializing key cache with capacity of 96 MBs.
cassandra       | INFO  [main] 2023-04-08 08:39:13,346 CacheService.java:125 - Initializing row cache with capacity of 0 MBs
cassandra       | INFO  [main] 2023-04-08 08:39:13,358 CacheService.java:154 - Initializing counter cache with capacity of 48 MBs
cassandra       | INFO  [main] 2023-04-08 08:39:13,361 CacheService.java:165 - Scheduling counter cache save to every 7200 seconds (going to save all keys).
cassandra       | INFO  [main] 2023-04-08 08:39:13,424 ColumnFamilyStore.java:432 - Initializing system.peers
cassandra       | INFO  [main] 2023-04-08 08:39:13,446 ColumnFamilyStore.java:432 - Initializing system.peer_events
cassandra       | INFO  [main] 2023-04-08 08:39:13,469 ColumnFamilyStore.java:432 - Initializing system.range_xfers
cassandra       | INFO  [main] 2023-04-08 08:39:13,486 ColumnFamilyStore.java:432 - Initializing system.compaction_history
cassandra       | INFO  [main] 2023-04-08 08:39:13,591 ColumnFamilyStore.java:432 - Initializing system.sstable_activity
cassandra       | INFO  [main] 2023-04-08 08:39:13,713 ColumnFamilyStore.java:432 - Initializing system.size_estimates
cassandra       | INFO  [main] 2023-04-08 08:39:13,749 ColumnFamilyStore.java:432 - Initializing system.available_ranges
cassandra       | INFO  [main] 2023-04-08 08:39:13,763 ColumnFamilyStore.java:432 - Initializing system.transferred_ranges
cassandra       | INFO  [main] 2023-04-08 08:39:13,773 ColumnFamilyStore.java:432 - Initializing system.views_builds_in_progress
cassandra       | INFO  [main] 2023-04-08 08:39:13,787 ColumnFamilyStore.java:432 - Initializing system.built_views
cassandra       | INFO  [main] 2023-04-08 08:39:13,821 ColumnFamilyStore.java:432 - Initializing system.hints
cassandra       | INFO  [main] 2023-04-08 08:39:13,849 ColumnFamilyStore.java:432 - Initializing system.batchlog
cassandra       | INFO  [main] 2023-04-08 08:39:13,907 ColumnFamilyStore.java:432 - Initializing system.prepared_statements
cassandra       | INFO  [main] 2023-04-08 08:39:13,925 ColumnFamilyStore.java:432 - Initializing system.schema_keyspaces
cassandra       | INFO  [main] 2023-04-08 08:39:13,966 ColumnFamilyStore.java:432 - Initializing system.schema_columnfamilies
cassandra       | INFO  [main] 2023-04-08 08:39:13,998 ColumnFamilyStore.java:432 - Initializing system.schema_columns
cassandra       | INFO  [main] 2023-04-08 08:39:14,027 ColumnFamilyStore.java:432 - Initializing system.schema_triggers
cassandra       | INFO  [main] 2023-04-08 08:39:14,056 ColumnFamilyStore.java:432 - Initializing system.schema_usertypes
cassandra       | INFO  [main] 2023-04-08 08:39:14,114 ColumnFamilyStore.java:432 - Initializing system.schema_functions
cassandra       | INFO  [main] 2023-04-08 08:39:14,129 ColumnFamilyStore.java:432 - Initializing system.schema_aggregates
cassandra       | INFO  [main] 2023-04-08 08:39:14,140 ViewManager.java:137 - Not submitting build tasks for views in keyspace system as storage service is not initialized
cassandra       | INFO  [main] 2023-04-08 08:39:14,481 ApproximateTime.java:44 - Scheduling approximate time-check task with a precision of 10 milliseconds
cassandra       | INFO  [main] 2023-04-08 08:39:14,607 ColumnFamilyStore.java:432 - Initializing system_schema.keyspaces
cassandra       | INFO  [main] 2023-04-08 08:39:14,677 ColumnFamilyStore.java:432 - Initializing system_schema.tables
cassandra       | INFO  [main] 2023-04-08 08:39:14,745 ColumnFamilyStore.java:432 - Initializing system_schema.columns
cassandra       | INFO  [main] 2023-04-08 08:39:14,793 ColumnFamilyStore.java:432 - Initializing system_schema.triggers
cassandra       | INFO  [main] 2023-04-08 08:39:14,820 ColumnFamilyStore.java:432 - Initializing system_schema.dropped_columns
cassandra       | INFO  [main] 2023-04-08 08:39:14,844 ColumnFamilyStore.java:432 - Initializing system_schema.views
cassandra       | INFO  [main] 2023-04-08 08:39:14,903 ColumnFamilyStore.java:432 - Initializing system_schema.types
cassandra       | INFO  [main] 2023-04-08 08:39:14,941 ColumnFamilyStore.java:432 - Initializing system_schema.functions
cassandra       | INFO  [main] 2023-04-08 08:39:14,963 ColumnFamilyStore.java:432 - Initializing system_schema.aggregates
cassandra       | INFO  [main] 2023-04-08 08:39:14,992 ColumnFamilyStore.java:432 - Initializing system_schema.indexes
cassandra       | INFO  [main] 2023-04-08 08:39:15,039 ViewManager.java:137 - Not submitting build tasks for views in keyspace system_schema as storage service is not initialized
cassandra       | INFO  [main] 2023-04-08 08:39:15,784 StorageService.java:681 - Populating token metadata from system tables
cassandra       | INFO  [main] 2023-04-08 08:39:15,798 StorageService.java:688 - Token metadata: Normal Tokens:
cassandra       | /172.20.0.10:[-9204311670088686682, -9147718949551361880, -9125916381026253915, -9113395348176352408, -9077725786632385530, -9072650681565041119, -8976925129085027722, -8954019240393070154, -8870238325595972951, -8736328936865926998, -8588485951159506582, -8450687966393799158, -8346960987015952884, -8342751997037309738, -8304991236815158527, -8292925333570208559, -8206338028017287206, -7796014694808437242, -7679771394395784361, -7674822069891585847, -7533906091638889887, -7497670789457994629, -7492050375076659575, -7437549616668462142, -7243679762089550352, -7145813553490112533, -6984542231110212073, -6940478684181231208, -6886324693010711512, -6866718943449171899, -6770788085351500192, -6730321575724998707, -6723032136831776523, -6710955293904547821, -6662911040709682819, -6556984367148701100, -6449813032889249289, -6437123129237247954, -6328162246105311770, -6247233197172879078, -6205217509706451895, -6173377043174900047, -6139569842426909659, -5934459056181036374, -5902775548949435893, -5841066713762149118, -5809995275554375982, -5623985761579832250, -5604845122611400211, -5557233034308579121, -5437971027302424783, -5400122674043282896, -5387568023105770203, -5368872931848159936, -5217564059460101766, -5142663680931762936, -5110443476072798111, -5095158659410343524, -5040689183292468335, -5024154270898615341, -4988122686223580322, -4986191364170132120, -4967326430186712630, -4771234013877346545, -4742714785668466071, -4662489889024112516, -4655779392352789252, -4652049675698716840, -4636017519597645515, -4595241856771260811, -4491562114976033834, -4414425047111846760, -4390658662450436316, -4340211830742721425, -4255035423101866230, -4188305930631917825, -4048009417217718346, -4030494621521214438, -4016637371584020106, -3950908731447359076, -3780771840942953233, -3698251329231500832, -3692590814348824873, -3686176179337211831, -3591520547339398549, -3457803458540937901, -3390333742575094169, -3362855492269839274, -3361356744280241767, -3346568432901113410, -3336876574164691923, -3289049736285278889, -3214675213048887113, -3090325511683358126, -2983586499429837236, -2913051554214045784, -2888123751811102385, -2812974854652124152, -2812632957221131294, -2753150584840424989, -2698426854976528001, -2684716892840804148, -2669647869458383513, -2606254166209246576, -2551989993717288432, -2511303346822941808, -2254820244373189826, -2163853270018164506, -2064295057592380967, -2048514880374397131, -1855360021849311234, -1704731020904936812, -1451941531227533319, -1305919191802594261, -1211261044764097475, -1132010589632812787, -856426661278856850, -767105882690798293, -706396073128012370, -624955800544529598, -589750316916395808, -566338084211069828, -282591125546300450, -275010098672524486, -122632268087239004, -48111472526408849, 79639727197457093, 96974792749787050, 273147335548270753, 352568947295624353, 467966991537642859, 735090150154223628, 745983504574394566, 920641298451809956, 966118627752544802, 966285739997441557, 1021721153697871787, 1044382157927517767, 1117506905949576957, 1157834245554694242, 1165988677878488171, 1205661345071899643, 1228883770831212481, 1229254477220400310, 1283803369372924312, 1292660835213540399, 1300622540604437398, 1324426048013916217, 1415359222851332177, 1424489744667614535, 1521902811112691973, 1726623063463573060, 1732192045838247188, 1799676230835902371, 1849755876682253731, 1909401139977493172, 1964280589491366950, 1977547825165878740, 2063457647743830841, 2102555893886597529, 2159551788072204152, 2358009498505071905, 2373179921292903530, 2483938938072928933, 2546847884062072850, 2701153522441195359, 2720167197934209457, 2805133593129214344, 2823435072514176710, 2973781439469921562, 3041286411459944510, 3051321064478507132, 3057621701992057758, 3105615446288918076, 3140952161599099813, 3343339945601388151, 3429388042603890248, 3713492167251513634, 3715721369279119243, 3814377589820018406, 4085260013135825377, 4143441156697599407, 4247195590033008636, 4249606560179053859, 4395378262921391808, 4433623535867089799, 4440458749147128969, 4459022563637593610, 4469192556929363928, 4537325621498193199, 4540990882033059394, 4605756653674590149, 4605943316394176957, 4633937320169597927, 4717724850089803374, 4771009875280861690, 4898523451640296840, 4901831796027443147, 4914264718558615750, 5077496017458905831, 5115227374986352445, 5151381077931070089, 5253686204575722197, 5259634739055190450, 5281859138615724621, 5297204469142128108, 5377439934067257242, 5409215409791106825, 5410498056833698053, 5510195573828758211, 5608804370557244994, 5618136776184019881, 5741561206681764294, 5807968529756821797, 5824980297143992384, 5845042004567925539, 5845611764720440435, 6159056712533673282, 6199811617615797865, 6306435231476313875, 6337253453213799493, 6346163129964382633, 6353213440895485832, 6392330034203356217, 6449201192167212215, 6510309188009911113, 6544415953428474187, 6739534337484515391, 6817688964973882535, 6983954923711220783, 7162463085842789112, 7198579616098473750, 7209624867952781412, 7249379806916572393, 7309574210896800839, 7346293188827783611, 7373229519702589439, 7449607496961907822, 7480137703582237832, 7516119866812036018, 7539256569147029968, 7654876943696110699, 7936839526678165631, 8058884981234179787, 8320865846041889273, 8408347248763115662, 8587339850687924971, 8806561053122875757, 8887412410696214117, 8942132657122968979, 8962532961406070545, 8973921451644091756, 9010409331992335684, 9030753009777687653, 9063938828812592027, 9154618296381924446]
cassandra       | 
zookeeper       | 2023-04-08 08:39:16,056 [myid:] - INFO  [main:o.a.z.s.q.QuorumPeerConfig@177] - Reading configuration from: /opt/bitnami/zookeeper/bin/../conf/zoo.cfg
zookeeper       | 2023-04-08 08:39:16,171 [myid:] - INFO  [main:o.a.z.s.q.QuorumPeerConfig@440] - clientPortAddress is 0.0.0.0:2181
zookeeper       | 2023-04-08 08:39:16,193 [myid:] - INFO  [main:o.a.z.s.q.QuorumPeerConfig@444] - secureClientPort is not set
zookeeper       | 2023-04-08 08:39:16,194 [myid:] - INFO  [main:o.a.z.s.q.QuorumPeerConfig@460] - observerMasterPort is not set
zookeeper       | 2023-04-08 08:39:16,197 [myid:] - INFO  [main:o.a.z.s.q.QuorumPeerConfig@477] - metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider
zookeeper       | 2023-04-08 08:39:16,229 [myid:1] - INFO  [main:o.a.z.s.DatadirCleanupManager@78] - autopurge.snapRetainCount set to 3
zookeeper       | 2023-04-08 08:39:16,232 [myid:1] - INFO  [main:o.a.z.s.DatadirCleanupManager@79] - autopurge.purgeInterval set to 0
zookeeper       | 2023-04-08 08:39:16,235 [myid:1] - INFO  [main:o.a.z.s.DatadirCleanupManager@101] - Purge task is not scheduled.
zookeeper       | 2023-04-08 08:39:16,238 [myid:1] - WARN  [main:o.a.z.s.q.QuorumPeerMain@139] - Either no config or no quorum defined in config, running in standalone mode
cassandra       | INFO  [main] 2023-04-08 08:39:16,252 ColumnFamilyStore.java:432 - Initializing system_distributed.parent_repair_history
zookeeper       | 2023-04-08 08:39:16,269 [myid:1] - INFO  [main:o.a.z.j.ManagedUtil@46] - Log4j 1.2 jmx support not found; jmx disabled.
zookeeper       | 2023-04-08 08:39:16,287 [myid:1] - INFO  [main:o.a.z.s.q.QuorumPeerConfig@177] - Reading configuration from: /opt/bitnami/zookeeper/bin/../conf/zoo.cfg
zookeeper       | 2023-04-08 08:39:16,292 [myid:1] - INFO  [main:o.a.z.s.q.QuorumPeerConfig@440] - clientPortAddress is 0.0.0.0:2181
zookeeper       | 2023-04-08 08:39:16,296 [myid:1] - INFO  [main:o.a.z.s.q.QuorumPeerConfig@444] - secureClientPort is not set
zookeeper       | 2023-04-08 08:39:16,297 [myid:1] - INFO  [main:o.a.z.s.q.QuorumPeerConfig@460] - observerMasterPort is not set
zookeeper       | 2023-04-08 08:39:16,299 [myid:1] - INFO  [main:o.a.z.s.q.QuorumPeerConfig@477] - metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider
zookeeper       | 2023-04-08 08:39:16,302 [myid:1] - INFO  [main:o.a.z.s.ZooKeeperServerMain@123] - Starting server
cassandra       | INFO  [main] 2023-04-08 08:39:16,332 ColumnFamilyStore.java:432 - Initializing system_distributed.repair_history
cassandra       | INFO  [main] 2023-04-08 08:39:16,384 ColumnFamilyStore.java:432 - Initializing system_distributed.view_build_status
cassandra       | INFO  [main] 2023-04-08 08:39:16,447 ViewManager.java:137 - Not submitting build tasks for views in keyspace system_distributed as storage service is not initialized
cassandra       | INFO  [main] 2023-04-08 08:39:16,479 ColumnFamilyStore.java:432 - Initializing videoanalysis.analysis
cassandra       | INFO  [main] 2023-04-08 08:39:16,500 ColumnFamilyStore.java:432 - Initializing videoanalysis.metrics
cassandra       | INFO  [main] 2023-04-08 08:39:16,519 ColumnFamilyStore.java:432 - Initializing videoanalysis.videos
cassandra       | INFO  [main] 2023-04-08 08:39:16,554 ViewManager.java:137 - Not submitting build tasks for views in keyspace videoanalysis as storage service is not initialized
cassandra       | INFO  [main] 2023-04-08 08:39:16,566 ColumnFamilyStore.java:432 - Initializing system_auth.resource_role_permissons_index
zookeeper       | 2023-04-08 08:39:16,583 [myid:1] - INFO  [main:o.a.z.s.ServerMetrics@64] - ServerMetrics initialized with provider org.apache.zookeeper.metrics.impl.DefaultMetricsProvider@73eb439a
cassandra       | INFO  [main] 2023-04-08 08:39:16,593 ColumnFamilyStore.java:432 - Initializing system_auth.role_members
zookeeper       | 2023-04-08 08:39:16,640 [myid:1] - INFO  [main:o.a.z.s.a.DigestAuthenticationProvider@47] - ACL digest algorithm is: SHA1
zookeeper       | 2023-04-08 08:39:16,641 [myid:1] - INFO  [main:o.a.z.s.a.DigestAuthenticationProvider@61] - zookeeper.DigestAuthenticationProvider.enabled = true
cassandra       | INFO  [main] 2023-04-08 08:39:16,655 ColumnFamilyStore.java:432 - Initializing system_auth.role_permissions
cassandra       | INFO  [main] 2023-04-08 08:39:16,681 ColumnFamilyStore.java:432 - Initializing system_auth.roles
zookeeper       | 2023-04-08 08:39:16,678 [myid:1] - INFO  [main:o.a.z.s.p.FileTxnSnapLog@124] - zookeeper.snapshot.trust.empty : false
zookeeper       | 2023-04-08 08:39:17,057 [myid:1] - INFO  [main:o.a.z.ZookeeperBanner@42] - 
zookeeper       | 2023-04-08 08:39:17,061 [myid:1] - INFO  [main:o.a.z.ZookeeperBanner@42] -   ______                  _                                          
zookeeper       | 2023-04-08 08:39:17,078 [myid:1] - INFO  [main:o.a.z.ZookeeperBanner@42] -  |___  /                 | |                                         
zookeeper       | 2023-04-08 08:39:17,086 [myid:1] - INFO  [main:o.a.z.ZookeeperBanner@42] -     / /    ___     ___   | | __   ___    ___   _ __     ___   _ __   
zookeeper       | 2023-04-08 08:39:17,093 [myid:1] - INFO  [main:o.a.z.ZookeeperBanner@42] -    / /    / _ \   / _ \  | |/ /  / _ \  / _ \ | '_ \   / _ \ | '__|
zookeeper       | 2023-04-08 08:39:17,099 [myid:1] - INFO  [main:o.a.z.ZookeeperBanner@42] -   / /__  | (_) | | (_) | |   <  |  __/ |  __/ | |_) | |  __/ | |    
zookeeper       | 2023-04-08 08:39:17,101 [myid:1] - INFO  [main:o.a.z.ZookeeperBanner@42] -  /_____|  \___/   \___/  |_|\_\  \___|  \___| | .__/   \___| |_|
zookeeper       | 2023-04-08 08:39:17,107 [myid:1] - INFO  [main:o.a.z.ZookeeperBanner@42] -                                               | |                     
cassandra       | INFO  [main] 2023-04-08 08:39:17,141 ViewManager.java:137 - Not submitting build tasks for views in keyspace system_auth as storage service is not initialized
zookeeper       | 2023-04-08 08:39:17,113 [myid:1] - INFO  [main:o.a.z.ZookeeperBanner@42] -                                               |_|                     
cassandra       | INFO  [main] 2023-04-08 08:39:17,146 ColumnFamilyStore.java:432 - Initializing system_traces.events
zookeeper       | 2023-04-08 08:39:17,147 [myid:1] - INFO  [main:o.a.z.ZookeeperBanner@42] - 
cassandra       | INFO  [main] 2023-04-08 08:39:17,179 ColumnFamilyStore.java:432 - Initializing system_traces.sessions
zookeeper       | 2023-04-08 08:39:17,200 [myid:1] - INFO  [main:o.a.z.Environment@98] - Server environment:zookeeper.version=3.8.1-74db005175a4ec545697012f9069cb9dcc8cdda7, built on 2023-01-25 16:31 UTC
zookeeper       | 2023-04-08 08:39:17,201 [myid:1] - INFO  [main:o.a.z.Environment@98] - Server environment:host.name=2c07ed941017
cassandra       | INFO  [main] 2023-04-08 08:39:17,223 ViewManager.java:137 - Not submitting build tasks for views in keyspace system_traces as storage service is not initialized
zookeeper       | 2023-04-08 08:39:17,227 [myid:1] - INFO  [main:o.a.z.Environment@98] - Server environment:java.version=11.0.18
zookeeper       | 2023-04-08 08:39:17,233 [myid:1] - INFO  [main:o.a.z.Environment@98] - Server environment:java.vendor=BellSoft
zookeeper       | 2023-04-08 08:39:17,235 [myid:1] - INFO  [main:o.a.z.Environment@98] - Server environment:java.home=/opt/bitnami/java
zookeeper       | 2023-04-08 08:39:17,236 [myid:1] - INFO  [main:o.a.z.Environment@98] - Server environment:java.class.path=/opt/bitnami/zookeeper/bin/../zookeeper-server/target/classes:/opt/bitnami/zookeeper/bin/../build/classes:/opt/bitnami/zookeeper/bin/../zookeeper-server/target/lib/*.jar:/opt/bitnami/zookeeper/bin/../build/lib/*.jar:/opt/bitnami/zookeeper/bin/../lib/zookeeper-prometheus-metrics-3.8.1.jar:/opt/bitnami/zookeeper/bin/../lib/zookeeper-jute-3.8.1.jar:/opt/bitnami/zookeeper/bin/../lib/zookeeper-3.8.1.jar:/opt/bitnami/zookeeper/bin/../lib/snappy-java-1.1.7.7.jar:/opt/bitnami/zookeeper/bin/../lib/slf4j-api-1.7.30.jar:/opt/bitnami/zookeeper/bin/../lib/simpleclient_servlet-0.9.0.jar:/opt/bitnami/zookeeper/bin/../lib/simpleclient_hotspot-0.9.0.jar:/opt/bitnami/zookeeper/bin/../lib/simpleclient_common-0.9.0.jar:/opt/bitnami/zookeeper/bin/../lib/simpleclient-0.9.0.jar:/opt/bitnami/zookeeper/bin/../lib/netty-transport-native-unix-common-4.1.86.Final.jar:/opt/bitnami/zookeeper/bin/../lib/netty-transport-native-epoll-4.1.86.Final.jar:/opt/bitnami/zookeeper/bin/../lib/netty-transport-classes-epoll-4.1.86.Final.jar:/opt/bitnami/zookeeper/bin/../lib/netty-transport-4.1.86.Final.jar:/opt/bitnami/zookeeper/bin/../lib/netty-resolver-4.1.86.Final.jar:/opt/bitnami/zookeeper/bin/../lib/netty-handler-4.1.86.Final.jar:/opt/bitnami/zookeeper/bin/../lib/netty-common-4.1.86.Final.jar:/opt/bitnami/zookeeper/bin/../lib/netty-codec-4.1.86.Final.jar:/opt/bitnami/zookeeper/bin/../lib/netty-buffer-4.1.86.Final.jar:/opt/bitnami/zookeeper/bin/../lib/metrics-core-4.1.12.1.jar:/opt/bitnami/zookeeper/bin/../lib/logback-core-1.2.10.jar:/opt/bitnami/zookeeper/bin/../lib/logback-classic-1.2.10.jar:/opt/bitnami/zookeeper/bin/../lib/jline-2.14.6.jar:/opt/bitnami/zookeeper/bin/../lib/jetty-util-ajax-9.4.49.v20220914.jar:/opt/bitnami/zookeeper/bin/../lib/jetty-util-9.4.49.v20220914.jar:/opt/bitnami/zookeeper/bin/../lib/jetty-servlet-9.4.49.v20220914.jar:/opt/bitnami/zookeeper/bin/../lib/jetty-server-9.4.49.v20220914.jar:/opt/bitnami/zookeeper/bin/../lib/jetty-security-9.4.49.v20220914.jar:/opt/bitnami/zookeeper/bin/../lib/jetty-io-9.4.49.v20220914.jar:/opt/bitnami/zookeeper/bin/../lib/jetty-http-9.4.49.v20220914.jar:/opt/bitnami/zookeeper/bin/../lib/javax.servlet-api-3.1.0.jar:/opt/bitnami/zookeeper/bin/../lib/jackson-databind-2.13.4.2.jar:/opt/bitnami/zookeeper/bin/../lib/jackson-core-2.13.4.jar:/opt/bitnami/zookeeper/bin/../lib/jackson-annotations-2.13.4.jar:/opt/bitnami/zookeeper/bin/../lib/commons-io-2.11.0.jar:/opt/bitnami/zookeeper/bin/../lib/commons-cli-1.5.0.jar:/opt/bitnami/zookeeper/bin/../lib/audience-annotations-0.12.0.jar:/opt/bitnami/zookeeper/bin/../zookeeper-*.jar:/opt/bitnami/zookeeper/bin/../zookeeper-server/src/main/resources/lib/*.jar:/opt/bitnami/zookeeper/bin/../conf:
cassandra       | INFO  [pool-4-thread-1] 2023-04-08 08:39:17,256 AutoSavingCache.java:174 - Completed loading (28 ms; 14 keys) KeyCache cache
zookeeper       | 2023-04-08 08:39:17,241 [myid:1] - INFO  [main:o.a.z.Environment@98] - Server environment:java.library.path=/usr/java/packages/lib:/usr/lib64:/lib64:/lib:/usr/lib
zookeeper       | 2023-04-08 08:39:17,276 [myid:1] - INFO  [main:o.a.z.Environment@98] - Server environment:java.io.tmpdir=/tmp
zookeeper       | 2023-04-08 08:39:17,277 [myid:1] - INFO  [main:o.a.z.Environment@98] - Server environment:java.compiler=<NA>
zookeeper       | 2023-04-08 08:39:17,286 [myid:1] - INFO  [main:o.a.z.Environment@98] - Server environment:os.name=Linux
zookeeper       | 2023-04-08 08:39:17,287 [myid:1] - INFO  [main:o.a.z.Environment@98] - Server environment:os.arch=amd64
zookeeper       | 2023-04-08 08:39:17,288 [myid:1] - INFO  [main:o.a.z.Environment@98] - Server environment:os.version=5.15.49-linuxkit
zookeeper       | 2023-04-08 08:39:17,301 [myid:1] - INFO  [main:o.a.z.Environment@98] - Server environment:user.name=?
zookeeper       | 2023-04-08 08:39:17,302 [myid:1] - INFO  [main:o.a.z.Environment@98] - Server environment:user.home=?
zookeeper       | 2023-04-08 08:39:17,302 [myid:1] - INFO  [main:o.a.z.Environment@98] - Server environment:user.dir=/
zookeeper       | 2023-04-08 08:39:17,303 [myid:1] - INFO  [main:o.a.z.Environment@98] - Server environment:os.memory.free=1005MB
zookeeper       | 2023-04-08 08:39:17,304 [myid:1] - INFO  [main:o.a.z.Environment@98] - Server environment:os.memory.max=1024MB
zookeeper       | 2023-04-08 08:39:17,304 [myid:1] - INFO  [main:o.a.z.Environment@98] - Server environment:os.memory.total=1024MB
zookeeper       | 2023-04-08 08:39:17,305 [myid:1] - INFO  [main:o.a.z.s.ZooKeeperServer@140] - zookeeper.enableEagerACLCheck = false
zookeeper       | 2023-04-08 08:39:17,321 [myid:1] - INFO  [main:o.a.z.s.ZooKeeperServer@153] - zookeeper.digest.enabled = true
zookeeper       | 2023-04-08 08:39:17,322 [myid:1] - INFO  [main:o.a.z.s.ZooKeeperServer@157] - zookeeper.closeSessionTxn.enabled = true
zookeeper       | 2023-04-08 08:39:17,325 [myid:1] - INFO  [main:o.a.z.s.ZooKeeperServer@1510] - zookeeper.flushDelay = 0 ms
zookeeper       | 2023-04-08 08:39:17,326 [myid:1] - INFO  [main:o.a.z.s.ZooKeeperServer@1519] - zookeeper.maxWriteQueuePollTime = 0 ms
zookeeper       | 2023-04-08 08:39:17,327 [myid:1] - INFO  [main:o.a.z.s.ZooKeeperServer@1528] - zookeeper.maxBatchSize=1000
zookeeper       | 2023-04-08 08:39:17,328 [myid:1] - INFO  [main:o.a.z.s.ZooKeeperServer@275] - zookeeper.intBufferStartingSizeBytes = 1024
cassandra       | INFO  [main] 2023-04-08 08:39:17,359 CommitLog.java:147 - Replaying /opt/cassandra/data/commitlog/CommitLog-6-1679402356315.log, /opt/cassandra/data/commitlog/CommitLog-6-1679402356316.log
zookeeper       | 2023-04-08 08:39:17,361 [myid:1] - INFO  [main:o.a.z.s.BlueThrottle@141] - Weighed connection throttling is disabled
zookeeper       | 2023-04-08 08:39:17,384 [myid:1] - INFO  [main:o.a.z.s.ZooKeeperServer@1311] - minSessionTimeout set to 4000 ms
cassandra       | WARN  [main] 2023-04-08 08:39:17,407 CommitLogReplayer.java:253 - Origin of 1 sstables is unknown or doesn't match the local node; commitLogIntervals for them were ignored
cassandra       | WARN  [main] 2023-04-08 08:39:17,411 CommitLogReplayer.java:253 - Origin of 1 sstables is unknown or doesn't match the local node; commitLogIntervals for them were ignored
zookeeper       | 2023-04-08 08:39:17,406 [myid:1] - INFO  [main:o.a.z.s.ZooKeeperServer@1320] - maxSessionTimeout set to 40000 ms
cassandra       | WARN  [main] 2023-04-08 08:39:17,412 CommitLogReplayer.java:253 - Origin of 1 sstables is unknown or doesn't match the local node; commitLogIntervals for them were ignored
cassandra       | INFO  [main] 2023-04-08 08:39:17,442 CommitLogReader.java:105 - Skipping playback of empty log: CommitLog-6-1679402356316.log
zookeeper       | 2023-04-08 08:39:17,447 [myid:1] - INFO  [main:o.a.z.s.ResponseCache@45] - getData response cache size is initialized with value 400.
zookeeper       | 2023-04-08 08:39:17,450 [myid:1] - INFO  [main:o.a.z.s.ResponseCache@45] - getChildren response cache size is initialized with value 400.
zookeeper       | 2023-04-08 08:39:17,477 [myid:1] - INFO  [main:o.a.z.s.u.RequestPathMetricsCollector@109] - zookeeper.pathStats.slotCapacity = 60
zookeeper       | 2023-04-08 08:39:17,478 [myid:1] - INFO  [main:o.a.z.s.u.RequestPathMetricsCollector@110] - zookeeper.pathStats.slotDuration = 15
zookeeper       | 2023-04-08 08:39:17,479 [myid:1] - INFO  [main:o.a.z.s.u.RequestPathMetricsCollector@111] - zookeeper.pathStats.maxDepth = 6
zookeeper       | 2023-04-08 08:39:17,487 [myid:1] - INFO  [main:o.a.z.s.u.RequestPathMetricsCollector@112] - zookeeper.pathStats.initialDelay = 5
zookeeper       | 2023-04-08 08:39:17,491 [myid:1] - INFO  [main:o.a.z.s.u.RequestPathMetricsCollector@113] - zookeeper.pathStats.delay = 5
zookeeper       | 2023-04-08 08:39:17,500 [myid:1] - INFO  [main:o.a.z.s.u.RequestPathMetricsCollector@114] - zookeeper.pathStats.enabled = false
zookeeper       | 2023-04-08 08:39:17,529 [myid:1] - INFO  [main:o.a.z.s.ZooKeeperServer@1547] - The max bytes for all large requests are set to 104857600
zookeeper       | 2023-04-08 08:39:17,530 [myid:1] - INFO  [main:o.a.z.s.ZooKeeperServer@1561] - The large request threshold is set to -1
zookeeper       | 2023-04-08 08:39:17,541 [myid:1] - INFO  [main:o.a.z.s.AuthenticationHelper@66] - zookeeper.enforce.auth.enabled = false
zookeeper       | 2023-04-08 08:39:17,542 [myid:1] - INFO  [main:o.a.z.s.AuthenticationHelper@67] - zookeeper.enforce.auth.schemes = []
zookeeper       | 2023-04-08 08:39:17,560 [myid:1] - INFO  [main:o.a.z.s.ZooKeeperServer@376] - Created server with tickTime 2000 ms minSessionTimeout 4000 ms maxSessionTimeout 40000 ms clientPortListenBacklog -1 datadir /bitnami/zookeeper/data/version-2 snapdir /bitnami/zookeeper/data/version-2
zookeeper       | 2023-04-08 08:39:18,237 [myid:1] - INFO  [main:o.e.j.u.l.Log@170] - Logging initialized @17024ms to org.eclipse.jetty.util.log.Slf4jLog
spark           | Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
cassandra       | INFO  [main] 2023-04-08 08:39:18,696 CommitLog.java:149 - Log replay complete, 83 replayed mutations
cassandra       | INFO  [main] 2023-04-08 08:39:18,703 StorageService.java:681 - Populating token metadata from system tables
spark-worker-4  | Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
cassandra       | INFO  [main] 2023-04-08 08:39:18,748 StorageService.java:688 - Token metadata: Normal Tokens:
cassandra       | /172.20.0.10:[-9204311670088686682, -9147718949551361880, -9125916381026253915, -9113395348176352408, -9077725786632385530, -9072650681565041119, -8976925129085027722, -8954019240393070154, -8870238325595972951, -8736328936865926998, -8588485951159506582, -8450687966393799158, -8346960987015952884, -8342751997037309738, -8304991236815158527, -8292925333570208559, -8206338028017287206, -7796014694808437242, -7679771394395784361, -7674822069891585847, -7533906091638889887, -7497670789457994629, -7492050375076659575, -7437549616668462142, -7243679762089550352, -7145813553490112533, -6984542231110212073, -6940478684181231208, -6886324693010711512, -6866718943449171899, -6770788085351500192, -6730321575724998707, -6723032136831776523, -6710955293904547821, -6662911040709682819, -6556984367148701100, -6449813032889249289, -6437123129237247954, -6328162246105311770, -6247233197172879078, -6205217509706451895, -6173377043174900047, -6139569842426909659, -5934459056181036374, -5902775548949435893, -5841066713762149118, -5809995275554375982, -5623985761579832250, -5604845122611400211, -5557233034308579121, -5437971027302424783, -5400122674043282896, -5387568023105770203, -5368872931848159936, -5217564059460101766, -5142663680931762936, -5110443476072798111, -5095158659410343524, -5040689183292468335, -5024154270898615341, -4988122686223580322, -4986191364170132120, -4967326430186712630, -4771234013877346545, -4742714785668466071, -4662489889024112516, -4655779392352789252, -4652049675698716840, -4636017519597645515, -4595241856771260811, -4491562114976033834, -4414425047111846760, -4390658662450436316, -4340211830742721425, -4255035423101866230, -4188305930631917825, -4048009417217718346, -4030494621521214438, -4016637371584020106, -3950908731447359076, -3780771840942953233, -3698251329231500832, -3692590814348824873, -3686176179337211831, -3591520547339398549, -3457803458540937901, -3390333742575094169, -3362855492269839274, -3361356744280241767, -3346568432901113410, -3336876574164691923, -3289049736285278889, -3214675213048887113, -3090325511683358126, -2983586499429837236, -2913051554214045784, -2888123751811102385, -2812974854652124152, -2812632957221131294, -2753150584840424989, -2698426854976528001, -2684716892840804148, -2669647869458383513, -2606254166209246576, -2551989993717288432, -2511303346822941808, -2254820244373189826, -2163853270018164506, -2064295057592380967, -2048514880374397131, -1855360021849311234, -1704731020904936812, -1451941531227533319, -1305919191802594261, -1211261044764097475, -1132010589632812787, -856426661278856850, -767105882690798293, -706396073128012370, -624955800544529598, -589750316916395808, -566338084211069828, -282591125546300450, -275010098672524486, -122632268087239004, -48111472526408849, 79639727197457093, 96974792749787050, 273147335548270753, 352568947295624353, 467966991537642859, 735090150154223628, 745983504574394566, 920641298451809956, 966118627752544802, 966285739997441557, 1021721153697871787, 1044382157927517767, 1117506905949576957, 1157834245554694242, 1165988677878488171, 1205661345071899643, 1228883770831212481, 1229254477220400310, 1283803369372924312, 1292660835213540399, 1300622540604437398, 1324426048013916217, 1415359222851332177, 1424489744667614535, 1521902811112691973, 1726623063463573060, 1732192045838247188, 1799676230835902371, 1849755876682253731, 1909401139977493172, 1964280589491366950, 1977547825165878740, 2063457647743830841, 2102555893886597529, 2159551788072204152, 2358009498505071905, 2373179921292903530, 2483938938072928933, 2546847884062072850, 2701153522441195359, 2720167197934209457, 2805133593129214344, 2823435072514176710, 2973781439469921562, 3041286411459944510, 3051321064478507132, 3057621701992057758, 3105615446288918076, 3140952161599099813, 3343339945601388151, 3429388042603890248, 3713492167251513634, 3715721369279119243, 3814377589820018406, 4085260013135825377, 4143441156697599407, 4247195590033008636, 4249606560179053859, 4395378262921391808, 4433623535867089799, 4440458749147128969, 4459022563637593610, 4469192556929363928, 4537325621498193199, 4540990882033059394, 4605756653674590149, 4605943316394176957, 4633937320169597927, 4717724850089803374, 4771009875280861690, 4898523451640296840, 4901831796027443147, 4914264718558615750, 5077496017458905831, 5115227374986352445, 5151381077931070089, 5253686204575722197, 5259634739055190450, 5281859138615724621, 5297204469142128108, 5377439934067257242, 5409215409791106825, 5410498056833698053, 5510195573828758211, 5608804370557244994, 5618136776184019881, 5741561206681764294, 5807968529756821797, 5824980297143992384, 5845042004567925539, 5845611764720440435, 6159056712533673282, 6199811617615797865, 6306435231476313875, 6337253453213799493, 6346163129964382633, 6353213440895485832, 6392330034203356217, 6449201192167212215, 6510309188009911113, 6544415953428474187, 6739534337484515391, 6817688964973882535, 6983954923711220783, 7162463085842789112, 7198579616098473750, 7209624867952781412, 7249379806916572393, 7309574210896800839, 7346293188827783611, 7373229519702589439, 7449607496961907822, 7480137703582237832, 7516119866812036018, 7539256569147029968, 7654876943696110699, 7936839526678165631, 8058884981234179787, 8320865846041889273, 8408347248763115662, 8587339850687924971, 8806561053122875757, 8887412410696214117, 8942132657122968979, 8962532961406070545, 8973921451644091756, 9010409331992335684, 9030753009777687653, 9063938828812592027, 9154618296381924446]
cassandra       | 
spark-worker-3  | Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
spark-worker-4  | 23/04/08 08:39:18 INFO Worker: Started daemon with process name: 95@00a985f891c6
spark           | 23/04/08 08:39:18 INFO Master: Started daemon with process name: 101@406ecabee5d0
spark-worker-1  | Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
spark-worker-3  | 23/04/08 08:39:19 INFO Worker: Started daemon with process name: 95@3be77bba0b3a
cassandra       | INFO  [main] 2023-04-08 08:39:19,164 QueryProcessor.java:174 - Preloaded 0 prepared statements
cassandra       | INFO  [main] 2023-04-08 08:39:19,165 StorageService.java:699 - Cassandra version: 3.11.14
cassandra       | INFO  [main] 2023-04-08 08:39:19,165 StorageService.java:700 - Thrift API version: 20.1.0
cassandra       | INFO  [main] 2023-04-08 08:39:19,165 StorageService.java:701 - CQL supported versions: 3.4.4 (default: 3.4.4)
cassandra       | INFO  [main] 2023-04-08 08:39:19,170 StorageService.java:703 - Native protocol supported versions: 3/v3, 4/v4, 5/v5-beta (default: 4/v4)
spark-worker-4  | 23/04/08 08:39:19 INFO SignalUtils: Registered signal handler for TERM
spark-worker-1  | 23/04/08 08:39:19 INFO Worker: Started daemon with process name: 95@573a7459998f
spark-worker-4  | 23/04/08 08:39:19 INFO SignalUtils: Registered signal handler for HUP
spark-worker-4  | 23/04/08 08:39:19 INFO SignalUtils: Registered signal handler for INT
spark           | 23/04/08 08:39:19 INFO SignalUtils: Registered signal handler for TERM
spark           | 23/04/08 08:39:19 INFO SignalUtils: Registered signal handler for HUP
spark           | 23/04/08 08:39:19 INFO SignalUtils: Registered signal handler for INT
cassandra       | INFO  [main] 2023-04-08 08:39:19,260 IndexSummaryManager.java:87 - Initializing index summary manager with a memory pool size of 96 MB and a resize interval of 60 minutes
cassandra       | INFO  [main] 2023-04-08 08:39:19,329 MessagingService.java:750 - Starting Messaging Service on /172.20.0.10:7000 (eth0)
cassandra       | INFO  [main] 2023-04-08 08:39:19,359 StorageService.java:631 - Unable to gossip with any peers but continuing anyway since node is in its own seed list
cassandra       | INFO  [main] 2023-04-08 08:39:19,403 StorageService.java:785 - Loading persisted ring state
cassandra       | INFO  [main] 2023-04-08 08:39:19,403 StorageService.java:916 - Starting up server gossip
spark-worker-2  | Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
spark-worker-3  | 23/04/08 08:39:19 INFO SignalUtils: Registered signal handler for TERM
spark-worker-3  | 23/04/08 08:39:19 INFO SignalUtils: Registered signal handler for HUP
spark-worker-3  | 23/04/08 08:39:19 INFO SignalUtils: Registered signal handler for INT
spark-worker-1  | 23/04/08 08:39:19 INFO SignalUtils: Registered signal handler for TERM
spark-worker-1  | 23/04/08 08:39:19 INFO SignalUtils: Registered signal handler for HUP
spark-worker-1  | 23/04/08 08:39:19 INFO SignalUtils: Registered signal handler for INT
cassandra       | INFO  [main] 2023-04-08 08:39:19,515 TokenMetadata.java:507 - Updating topology for /172.20.0.10
cassandra       | INFO  [main] 2023-04-08 08:39:19,516 TokenMetadata.java:507 - Updating topology for /172.20.0.10
spark-worker-2  | 23/04/08 08:39:19 INFO Worker: Started daemon with process name: 94@0d054d7c07ed
cassandra       | INFO  [main] 2023-04-08 08:39:19,686 StorageService.java:1104 - Using saved tokens [-1132010589632812787, -1211261044764097475, -122632268087239004, -1305919191802594261, -1451941531227533319, -1704731020904936812, -1855360021849311234, -2048514880374397131, -2064295057592380967, -2163853270018164506, -2254820244373189826, -2511303346822941808, -2551989993717288432, -2606254166209246576, -2669647869458383513, -2684716892840804148, -2698426854976528001, -275010098672524486, -2753150584840424989, -2812632957221131294, -2812974854652124152, -282591125546300450, -2888123751811102385, -2913051554214045784, -2983586499429837236, -3090325511683358126, -3214675213048887113, -3289049736285278889, -3336876574164691923, -3346568432901113410, -3361356744280241767, -3362855492269839274, -3390333742575094169, -3457803458540937901, -3591520547339398549, -3686176179337211831, -3692590814348824873, -3698251329231500832, -3780771840942953233, -3950908731447359076, -4016637371584020106, -4030494621521214438, -4048009417217718346, -4188305930631917825, -4255035423101866230, -4340211830742721425, -4390658662450436316, -4414425047111846760, -4491562114976033834, -4595241856771260811, -4636017519597645515, -4652049675698716840, -4655779392352789252, -4662489889024112516, -4742714785668466071, -4771234013877346545, -48111472526408849, -4967326430186712630, -4986191364170132120, -4988122686223580322, -5024154270898615341, -5040689183292468335, -5095158659410343524, -5110443476072798111, -5142663680931762936, -5217564059460101766, -5368872931848159936, -5387568023105770203, -5400122674043282896, -5437971027302424783, -5557233034308579121, -5604845122611400211, -5623985761579832250, -566338084211069828, -5809995275554375982, -5841066713762149118, -589750316916395808, -5902775548949435893, -5934459056181036374, -6139569842426909659, -6173377043174900047, -6205217509706451895, -6247233197172879078, -624955800544529598, -6328162246105311770, -6437123129237247954, -6449813032889249289, -6556984367148701100, -6662911040709682819, -6710955293904547821, -6723032136831776523, -6730321575724998707, -6770788085351500192, -6866718943449171899, -6886324693010711512, -6940478684181231208, -6984542231110212073, -706396073128012370, -7145813553490112533, -7243679762089550352, -7437549616668462142, -7492050375076659575, -7497670789457994629, -7533906091638889887, -767105882690798293, -7674822069891585847, -7679771394395784361, -7796014694808437242, -8206338028017287206, -8292925333570208559, -8304991236815158527, -8342751997037309738, -8346960987015952884, -8450687966393799158, -856426661278856850, -8588485951159506582, -8736328936865926998, -8870238325595972951, -8954019240393070154, -8976925129085027722, -9072650681565041119, -9077725786632385530, -9113395348176352408, -9125916381026253915, -9147718949551361880, -9204311670088686682, 1021721153697871787, 1044382157927517767, 1117506905949576957, 1157834245554694242, 1165988677878488171, 1205661345071899643, 1228883770831212481, 1229254477220400310, 1283803369372924312, 1292660835213540399, 1300622540604437398, 1324426048013916217, 1415359222851332177, 1424489744667614535, 1521902811112691973, 1726623063463573060, 1732192045838247188, 1799676230835902371, 1849755876682253731, 1909401139977493172, 1964280589491366950, 1977547825165878740, 2063457647743830841, 2102555893886597529, 2159551788072204152, 2358009498505071905, 2373179921292903530, 2483938938072928933, 2546847884062072850, 2701153522441195359, 2720167197934209457, 273147335548270753, 2805133593129214344, 2823435072514176710, 2973781439469921562, 3041286411459944510, 3051321064478507132, 3057621701992057758, 3105615446288918076, 3140952161599099813, 3343339945601388151, 3429388042603890248, 352568947295624353, 3713492167251513634, 3715721369279119243, 3814377589820018406, 4085260013135825377, 4143441156697599407, 4247195590033008636, 4249606560179053859, 4395378262921391808, 4433623535867089799, 4440458749147128969, 4459022563637593610, 4469192556929363928, 4537325621498193199, 4540990882033059394, 4605756653674590149, 4605943316394176957, 4633937320169597927, 467966991537642859, 4717724850089803374, 4771009875280861690, 4898523451640296840, 4901831796027443147, 4914264718558615750, 5077496017458905831, 5115227374986352445, 5151381077931070089, 5253686204575722197, 5259634739055190450, 5281859138615724621, 5297204469142128108, 5377439934067257242, 5409215409791106825, 5410498056833698053, 5510195573828758211, 5608804370557244994, 5618136776184019881, 5741561206681764294, 5807968529756821797, 5824980297143992384, 5845042004567925539, 5845611764720440435, 6159056712533673282, 6199811617615797865, 6306435231476313875, 6337253453213799493, 6346163129964382633, 6353213440895485832, 6392330034203356217, 6449201192167212215, 6510309188009911113, 6544415953428474187, 6739534337484515391, 6817688964973882535, 6983954923711220783, 7162463085842789112, 7198579616098473750, 7209624867952781412, 7249379806916572393, 7309574210896800839, 7346293188827783611, 735090150154223628, 7373229519702589439, 7449607496961907822, 745983504574394566, 7480137703582237832, 7516119866812036018, 7539256569147029968, 7654876943696110699, 7936839526678165631, 79639727197457093, 8058884981234179787, 8320865846041889273, 8408347248763115662, 8587339850687924971, 8806561053122875757, 8887412410696214117, 8942132657122968979, 8962532961406070545, 8973921451644091756, 9010409331992335684, 9030753009777687653, 9063938828812592027, 9154618296381924446, 920641298451809956, 966118627752544802, 966285739997441557, 96974792749787050]
cassandra       | INFO  [main] 2023-04-08 08:39:19,719 StorageService.java:1568 - JOINING: Finish joining ring
cassandra       | INFO  [main] 2023-04-08 08:39:19,795 SecondaryIndexManager.java:512 - Executing pre-join tasks for: CFS(Keyspace='videoanalysis', ColumnFamily='videos')
cassandra       | INFO  [main] 2023-04-08 08:39:19,797 SecondaryIndexManager.java:512 - Executing pre-join tasks for: CFS(Keyspace='videoanalysis', ColumnFamily='analysis')
cassandra       | INFO  [main] 2023-04-08 08:39:19,805 SecondaryIndexManager.java:512 - Executing pre-join tasks for: CFS(Keyspace='videoanalysis', ColumnFamily='metrics')
spark-worker-2  | 23/04/08 08:39:19 INFO SignalUtils: Registered signal handler for TERM
spark-worker-2  | 23/04/08 08:39:19 INFO SignalUtils: Registered signal handler for HUP
spark-worker-2  | 23/04/08 08:39:19 INFO SignalUtils: Registered signal handler for INT
cassandra       | INFO  [main] 2023-04-08 08:39:19,981 StorageService.java:2484 - Node /172.20.0.10 state jump to NORMAL
cassandra       | INFO  [main] 2023-04-08 08:39:20,023 Gossiper.java:1869 - Waiting for gossip to settle...
zookeeper       | 2023-04-08 08:39:20,138 [myid:1] - WARN  [main:o.e.j.s.h.ContextHandler@1662] - o.e.j.s.ServletContextHandler@5454d35e{/,null,STOPPED} contextPath ends with /*
zookeeper       | 2023-04-08 08:39:20,139 [myid:1] - WARN  [main:o.e.j.s.h.ContextHandler@1673] - Empty contextPath
zookeeper       | 2023-04-08 08:39:20,533 [myid:1] - INFO  [main:o.e.j.s.Server@375] - jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 11.0.18+10-LTS
zookeeper       | 2023-04-08 08:39:21,062 [myid:1] - INFO  [main:o.e.j.s.s.DefaultSessionIdManager@334] - DefaultSessionIdManager workerName=node0
zookeeper       | 2023-04-08 08:39:21,064 [myid:1] - INFO  [main:o.e.j.s.s.DefaultSessionIdManager@339] - No SessionScavenger set, using defaults
zookeeper       | 2023-04-08 08:39:21,080 [myid:1] - INFO  [main:o.e.j.s.s.HouseKeeper@132] - node0 Scavenging every 600000ms
zookeeper       | 2023-04-08 08:39:21,129 [myid:1] - WARN  [main:o.e.j.s.ConstraintSecurityHandler@759] - ServletContext@o.e.j.s.ServletContextHandler@5454d35e{/,null,STARTING} has uncovered http methods for path: /*
zookeeper       | 2023-04-08 08:39:21,274 [myid:1] - INFO  [main:o.e.j.s.h.ContextHandler@921] - Started o.e.j.s.ServletContextHandler@5454d35e{/,null,AVAILABLE}
zookeeper       | 2023-04-08 08:39:21,530 [myid:1] - INFO  [main:o.e.j.s.AbstractConnector@333] - Started ServerConnector@1722011b{HTTP/1.1, (http/1.1)}{0.0.0.0:8080}
zookeeper       | 2023-04-08 08:39:21,531 [myid:1] - INFO  [main:o.e.j.s.Server@415] - Started @20331ms
zookeeper       | 2023-04-08 08:39:21,532 [myid:1] - INFO  [main:o.a.z.s.a.JettyAdminServer@196] - Started AdminServer on address 0.0.0.0, port 8080 and command URL /commands
zookeeper       | 2023-04-08 08:39:21,614 [myid:1] - INFO  [main:o.a.z.s.ServerCnxnFactory@169] - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
zookeeper       | 2023-04-08 08:39:21,623 [myid:1] - WARN  [main:o.a.z.s.ServerCnxnFactory@309] - maxCnxns is not configured, using default value 0.
zookeeper       | 2023-04-08 08:39:21,636 [myid:1] - INFO  [main:o.a.z.s.NIOServerCnxnFactory@652] - Configuring NIO connection handler with 10s sessionless connection timeout, 1 selector thread(s), 8 worker threads, and 64 kB direct buffers.
zookeeper       | 2023-04-08 08:39:21,649 [myid:1] - INFO  [main:o.a.z.s.NIOServerCnxnFactory@660] - binding to port 0.0.0.0/0.0.0.0:2181
zookeeper       | 2023-04-08 08:39:21,768 [myid:1] - INFO  [main:o.a.z.s.w.WatchManagerFactory@42] - Using org.apache.zookeeper.server.watch.WatchManager as watch manager
zookeeper       | 2023-04-08 08:39:21,775 [myid:1] - INFO  [main:o.a.z.s.w.WatchManagerFactory@42] - Using org.apache.zookeeper.server.watch.WatchManager as watch manager
zookeeper       | 2023-04-08 08:39:21,791 [myid:1] - INFO  [main:o.a.z.s.ZKDatabase@132] - zookeeper.snapshotSizeFactor = 0.33
zookeeper       | 2023-04-08 08:39:21,796 [myid:1] - INFO  [main:o.a.z.s.ZKDatabase@152] - zookeeper.commitLogCount=500
zookeeper       | 2023-04-08 08:39:21,825 [myid:1] - INFO  [main:o.a.z.s.p.SnapStream@61] - zookeeper.snapshot.compression.method = CHECKED
zookeeper       | 2023-04-08 08:39:21,847 [myid:1] - INFO  [main:o.a.z.s.p.FileSnap@85] - Reading snapshot /bitnami/zookeeper/data/version-2/snapshot.116
zookeeper       | 2023-04-08 08:39:21,936 [myid:1] - INFO  [main:o.a.z.s.DataTree@1705] - The digest in the snapshot has digest version of 2, with zxid as 0x116, and digest value as 299722505601
zookeeper       | 2023-04-08 08:39:22,738 [myid:1] - INFO  [main:o.a.z.a.ZKAuditProvider@42] - ZooKeeper audit is disabled.
zookeeper       | 2023-04-08 08:39:22,750 [myid:1] - INFO  [main:o.a.z.s.p.FileTxnSnapLog@372] - 19 txns loaded in 680 ms
zookeeper       | 2023-04-08 08:39:22,761 [myid:1] - INFO  [main:o.a.z.s.ZKDatabase@289] - Snapshot loaded in 951 ms, highest zxid is 0x129, digest is 303175340226
zookeeper       | 2023-04-08 08:39:22,770 [myid:1] - INFO  [main:o.a.z.s.p.FileTxnSnapLog@479] - Snapshotting: 0x129 to /bitnami/zookeeper/data/version-2/snapshot.129
zookeeper       | 2023-04-08 08:39:22,844 [myid:1] - INFO  [main:o.a.z.s.ZooKeeperServer@558] - Snapshot taken in 74 ms
zookeeper       | 2023-04-08 08:39:22,976 [myid:1] - INFO  [main:o.a.z.s.RequestThrottler@75] - zookeeper.request_throttler.shutdownTimeout = 10000 ms
zookeeper       | 2023-04-08 08:39:22,980 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::o.a.z.s.PrepRequestProcessor@138] - PrepRequestProcessor (sid:0) started, reconfigEnabled=false
zookeeper       | 2023-04-08 08:39:23,424 [myid:1] - INFO  [main:o.a.z.s.ContainerManager@84] - Using checkIntervalMs=60000 maxPerMinute=10000 maxNeverUsedIntervalMs=0
spark-worker-1  | 23/04/08 08:39:24 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
spark-worker-2  | 23/04/08 08:39:24 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
spark           | 23/04/08 08:39:24 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
spark-worker-4  | 23/04/08 08:39:24 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
spark-worker-3  | 23/04/08 08:39:25 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
spark           | 23/04/08 08:39:25 INFO SecurityManager: Changing view acls to: spark
spark           | 23/04/08 08:39:25 INFO SecurityManager: Changing modify acls to: spark
spark           | 23/04/08 08:39:25 INFO SecurityManager: Changing view acls groups to: 
spark           | 23/04/08 08:39:25 INFO SecurityManager: Changing modify acls groups to: 
spark           | 23/04/08 08:39:25 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(spark); groups with view permissions: Set(); users  with modify permissions: Set(spark); groups with modify permissions: Set()
spark-worker-1  | 23/04/08 08:39:26 INFO SecurityManager: Changing view acls to: spark
spark-worker-1  | 23/04/08 08:39:26 INFO SecurityManager: Changing modify acls to: spark
spark-worker-1  | 23/04/08 08:39:26 INFO SecurityManager: Changing view acls groups to: 
spark-worker-1  | 23/04/08 08:39:26 INFO SecurityManager: Changing modify acls groups to: 
spark-worker-1  | 23/04/08 08:39:26 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(spark); groups with view permissions: Set(); users  with modify permissions: Set(spark); groups with modify permissions: Set()
spark-worker-2  | 23/04/08 08:39:26 INFO SecurityManager: Changing view acls to: spark
spark-worker-2  | 23/04/08 08:39:26 INFO SecurityManager: Changing modify acls to: spark
spark-worker-3  | 23/04/08 08:39:26 INFO SecurityManager: Changing view acls to: spark
spark-worker-3  | 23/04/08 08:39:26 INFO SecurityManager: Changing modify acls to: spark
spark-worker-2  | 23/04/08 08:39:26 INFO SecurityManager: Changing view acls groups to: 
spark-worker-2  | 23/04/08 08:39:26 INFO SecurityManager: Changing modify acls groups to: 
spark-worker-2  | 23/04/08 08:39:26 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(spark); groups with view permissions: Set(); users  with modify permissions: Set(spark); groups with modify permissions: Set()
spark-worker-3  | 23/04/08 08:39:26 INFO SecurityManager: Changing view acls groups to: 
spark-worker-3  | 23/04/08 08:39:26 INFO SecurityManager: Changing modify acls groups to: 
spark-worker-3  | 23/04/08 08:39:26 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(spark); groups with view permissions: Set(); users  with modify permissions: Set(spark); groups with modify permissions: Set()
spark-worker-4  | 23/04/08 08:39:26 INFO SecurityManager: Changing view acls to: spark
spark-worker-4  | 23/04/08 08:39:26 INFO SecurityManager: Changing modify acls to: spark
spark-worker-4  | 23/04/08 08:39:26 INFO SecurityManager: Changing view acls groups to: 
spark-worker-4  | 23/04/08 08:39:26 INFO SecurityManager: Changing modify acls groups to: 
spark-worker-4  | 23/04/08 08:39:26 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(spark); groups with view permissions: Set(); users  with modify permissions: Set(spark); groups with modify permissions: Set()
cassandra       | INFO  [main] 2023-04-08 08:39:28,027 Gossiper.java:1900 - No gossip backlog; proceeding
cassandra       | INFO  [main] 2023-04-08 08:39:28,592 NativeTransportService.java:73 - Netty using Java NIO event loop
cassandra       | INFO  [main] 2023-04-08 08:39:28,925 Server.java:158 - Using Netty Version: [netty-buffer=netty-buffer-4.0.44.Final.452812a, netty-codec=netty-codec-4.0.44.Final.452812a, netty-codec-haproxy=netty-codec-haproxy-4.0.44.Final.452812a, netty-codec-http=netty-codec-http-4.0.44.Final.452812a, netty-codec-socks=netty-codec-socks-4.0.44.Final.452812a, netty-common=netty-common-4.0.44.Final.452812a, netty-handler=netty-handler-4.0.44.Final.452812a, netty-tcnative=netty-tcnative-1.1.33.Fork26.142ecbb, netty-transport=netty-transport-4.0.44.Final.452812a, netty-transport-native-epoll=netty-transport-native-epoll-4.0.44.Final.452812a, netty-transport-rxtx=netty-transport-rxtx-4.0.44.Final.452812a, netty-transport-sctp=netty-transport-sctp-4.0.44.Final.452812a, netty-transport-udt=netty-transport-udt-4.0.44.Final.452812a]
cassandra       | INFO  [main] 2023-04-08 08:39:28,926 Server.java:159 - Starting listening for CQL clients on /0.0.0.0:9042 (unencrypted)...
cassandra       | INFO  [main] 2023-04-08 08:39:29,086 CassandraDaemon.java:564 - Not starting RPC server as requested. Use JMX (StorageService->startRPCServer()) or nodetool (enablethrift) to start it
cassandra       | INFO  [main] 2023-04-08 08:39:29,086 CassandraDaemon.java:650 - Startup complete
spark-worker-1  | 23/04/08 08:39:31 INFO Utils: Successfully started service 'sparkWorker' on port 44083.
spark           | 23/04/08 08:39:31 INFO Utils: Successfully started service 'sparkMaster' on port 7077.
spark-worker-2  | 23/04/08 08:39:31 INFO Utils: Successfully started service 'sparkWorker' on port 43433.
spark-worker-3  | 23/04/08 08:39:31 INFO Utils: Successfully started service 'sparkWorker' on port 46113.
spark-worker-4  | 23/04/08 08:39:31 INFO Utils: Successfully started service 'sparkWorker' on port 41531.
spark           | 23/04/08 08:39:31 INFO Master: Starting Spark master at spark://406ecabee5d0:7077
spark           | 23/04/08 08:39:32 INFO Master: Running Spark version 3.0.0
video-app       | https and websocket listening on *:8080
api             | /usr/local/lib/python3.11/site-packages/cassandra/cqlengine/management.py:545: UserWarning: CQLENG_ALLOW_SCHEMA_MANAGEMENT environment variable is not set. Future versions of this package will require this variable to enable management functions.
api             |   warnings.warn(msg)
api             | Traceback (most recent call last):
api             |   File "/app/api.py", line 22, in <module>
api             |     kafka_manager = KafkaManager()
api             |                     ^^^^^^^^^^^^^^
api             |   File "/app/kafka_broker.py", line 16, in __init__
api             |     self.create_topics()
api             |   File "/app/kafka_broker.py", line 29, in create_topics
api             |     self.get_admin().create_topics(new_topics=topic_list, validate_only=False)
api             |     ^^^^^^^^^^^^^^^^
api             |   File "/app/kafka_broker.py", line 19, in get_admin
api             |     return KafkaAdminClient(
api             |            ^^^^^^^^^^^^^^^^^
api             |   File "/usr/local/lib/python3.11/site-packages/kafka/admin/client.py", line 208, in __init__
api             |     self._client = KafkaClient(metrics=self._metrics,
api             |                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
api             |   File "/usr/local/lib/python3.11/site-packages/kafka/client_async.py", line 244, in __init__
api             |     self.config['api_version'] = self.check_version(timeout=check_timeout)
api             |                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
api             |   File "/usr/local/lib/python3.11/site-packages/kafka/client_async.py", line 900, in check_version
api             |     raise Errors.NoBrokersAvailable()
api             | kafka.errors.NoBrokersAvailable: NoBrokersAvailable
api exited with code 1
spark-worker-1  | 23/04/08 08:39:34 INFO Worker: Starting Spark worker 172.20.0.6:44083 with 1 cores, 1024.0 MiB RAM
spark-worker-1  | 23/04/08 08:39:34 INFO Worker: Running Spark version 3.0.0
spark-worker-1  | 23/04/08 08:39:34 INFO Worker: Spark home: /opt/bitnami/spark
kafka           | [2023-04-08 08:39:34,514] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
spark-worker-2  | 23/04/08 08:39:34 INFO Worker: Starting Spark worker 172.20.0.4:43433 with 1 cores, 1024.0 MiB RAM
spark-worker-2  | 23/04/08 08:39:34 INFO Worker: Running Spark version 3.0.0
spark-worker-2  | 23/04/08 08:39:34 INFO Worker: Spark home: /opt/bitnami/spark
spark-worker-1  | 23/04/08 08:39:34 INFO ResourceUtils: ==============================================================
spark-worker-1  | 23/04/08 08:39:34 INFO ResourceUtils: Resources for spark.worker:
spark-worker-1  | 
spark-worker-4  | 23/04/08 08:39:34 INFO Worker: Starting Spark worker 172.20.0.5:41531 with 1 cores, 1024.0 MiB RAM
spark-worker-1  | 23/04/08 08:39:34 INFO ResourceUtils: ==============================================================
spark-worker-3  | 23/04/08 08:39:34 INFO Worker: Starting Spark worker 172.20.0.8:46113 with 1 cores, 1024.0 MiB RAM
spark-worker-2  | 23/04/08 08:39:35 INFO ResourceUtils: ==============================================================
spark-worker-2  | 23/04/08 08:39:35 INFO ResourceUtils: Resources for spark.worker:
spark-worker-2  | 
spark-worker-4  | 23/04/08 08:39:35 INFO Worker: Running Spark version 3.0.0
spark-worker-2  | 23/04/08 08:39:35 INFO ResourceUtils: ==============================================================
spark-worker-4  | 23/04/08 08:39:35 INFO Worker: Spark home: /opt/bitnami/spark
spark-worker-3  | 23/04/08 08:39:35 INFO Worker: Running Spark version 3.0.0
spark-worker-3  | 23/04/08 08:39:35 INFO Worker: Spark home: /opt/bitnami/spark
spark           | 23/04/08 08:39:35 INFO Utils: Successfully started service 'MasterUI' on port 8080.
spark-worker-3  | 23/04/08 08:39:35 INFO ResourceUtils: ==============================================================
spark-worker-4  | 23/04/08 08:39:35 INFO ResourceUtils: ==============================================================
spark-worker-3  | 23/04/08 08:39:35 INFO ResourceUtils: Resources for spark.worker:
spark-worker-3  | 
spark-worker-4  | 23/04/08 08:39:35 INFO ResourceUtils: Resources for spark.worker:
spark-worker-4  | 
spark-worker-3  | 23/04/08 08:39:35 INFO ResourceUtils: ==============================================================
spark-worker-4  | 23/04/08 08:39:35 INFO ResourceUtils: ==============================================================
spark           | 23/04/08 08:39:36 INFO MasterWebUI: Bound MasterWebUI to 0.0.0.0, and started at http://406ecabee5d0:8080
spark-worker-1  | 23/04/08 08:39:36 INFO Utils: Successfully started service 'WorkerUI' on port 8081.
spark-worker-2  | 23/04/08 08:39:36 INFO Utils: Successfully started service 'WorkerUI' on port 8081.
spark-worker-3  | 23/04/08 08:39:36 INFO Utils: Successfully started service 'WorkerUI' on port 8081.
spark-worker-1  | 23/04/08 08:39:36 INFO WorkerWebUI: Bound WorkerWebUI to 0.0.0.0, and started at http://573a7459998f:8081
spark-worker-1  | 23/04/08 08:39:37 INFO Worker: Connecting to master spark:7077...
spark-worker-2  | 23/04/08 08:39:37 INFO WorkerWebUI: Bound WorkerWebUI to 0.0.0.0, and started at http://0d054d7c07ed:8081
spark-worker-2  | 23/04/08 08:39:37 INFO Worker: Connecting to master spark:7077...
spark-worker-4  | 23/04/08 08:39:37 INFO Utils: Successfully started service 'WorkerUI' on port 8081.
spark           | 23/04/08 08:39:37 INFO Master: I have been elected leader! New state: ALIVE
spark-worker-3  | 23/04/08 08:39:37 INFO WorkerWebUI: Bound WorkerWebUI to 0.0.0.0, and started at http://3be77bba0b3a:8081
spark-worker-3  | 23/04/08 08:39:37 INFO Worker: Connecting to master spark:7077...
spark-worker-4  | 23/04/08 08:39:38 INFO WorkerWebUI: Bound WorkerWebUI to 0.0.0.0, and started at http://00a985f891c6:8081
spark-worker-4  | 23/04/08 08:39:38 INFO Worker: Connecting to master spark:7077...
spark-worker-1  | 23/04/08 08:39:38 INFO TransportClientFactory: Successfully created connection to spark/172.20.0.7:7077 after 420 ms (0 ms spent in bootstraps)
spark-worker-2  | 23/04/08 08:39:38 INFO TransportClientFactory: Successfully created connection to spark/172.20.0.7:7077 after 601 ms (0 ms spent in bootstraps)
spark-worker-3  | 23/04/08 08:39:38 INFO TransportClientFactory: Successfully created connection to spark/172.20.0.7:7077 after 411 ms (0 ms spent in bootstraps)
spark-worker-4  | 23/04/08 08:39:38 INFO TransportClientFactory: Successfully created connection to spark/172.20.0.7:7077 after 392 ms (0 ms spent in bootstraps)
kafka           | [2023-04-08 08:39:39,333] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
spark           | 23/04/08 08:39:39 INFO Master: Registering worker 172.20.0.5:41531 with 1 cores, 1024.0 MiB RAM
spark           | 23/04/08 08:39:39 INFO Master: Registering worker 172.20.0.6:44083 with 1 cores, 1024.0 MiB RAM
spark           | 23/04/08 08:39:39 INFO Master: Registering worker 172.20.0.4:43433 with 1 cores, 1024.0 MiB RAM
spark           | 23/04/08 08:39:39 INFO Master: Registering worker 172.20.0.8:46113 with 1 cores, 1024.0 MiB RAM
spark-worker-2  | 23/04/08 08:39:39 INFO Worker: Successfully registered with master spark://406ecabee5d0:7077
spark-worker-3  | 23/04/08 08:39:40 INFO Worker: Successfully registered with master spark://406ecabee5d0:7077
spark-worker-1  | 23/04/08 08:39:40 INFO Worker: Successfully registered with master spark://406ecabee5d0:7077
spark-worker-4  | 23/04/08 08:39:40 INFO Worker: Successfully registered with master spark://406ecabee5d0:7077
kafka           | [2023-04-08 08:39:40,392] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
kafka           | [2023-04-08 08:39:40,399] INFO starting (kafka.server.KafkaServer)
kafka           | [2023-04-08 08:39:40,401] INFO Connecting to zookeeper on zookeeper:2181 (kafka.server.KafkaServer)
kafka           | [2023-04-08 08:39:40,475] INFO [ZooKeeperClient Kafka server] Initializing a new session to zookeeper:2181. (kafka.zookeeper.ZooKeeperClient)
kafka           | [2023-04-08 08:39:40,498] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
kafka           | [2023-04-08 08:39:40,499] INFO Client environment:host.name=3ac0ac2ffb45 (org.apache.zookeeper.ZooKeeper)
kafka           | [2023-04-08 08:39:40,499] INFO Client environment:java.version=11.0.18 (org.apache.zookeeper.ZooKeeper)
kafka           | [2023-04-08 08:39:40,500] INFO Client environment:java.vendor=BellSoft (org.apache.zookeeper.ZooKeeper)
kafka           | [2023-04-08 08:39:40,500] INFO Client environment:java.home=/opt/bitnami/java (org.apache.zookeeper.ZooKeeper)
kafka           | [2023-04-08 08:39:40,500] INFO Client environment:java.class.path=/opt/bitnami/kafka/bin/../libs/activation-1.1.1.jar:/opt/bitnami/kafka/bin/../libs/aopalliance-repackaged-2.6.1.jar:/opt/bitnami/kafka/bin/../libs/argparse4j-0.7.0.jar:/opt/bitnami/kafka/bin/../libs/audience-annotations-0.5.0.jar:/opt/bitnami/kafka/bin/../libs/commons-cli-1.4.jar:/opt/bitnami/kafka/bin/../libs/commons-lang3-3.8.1.jar:/opt/bitnami/kafka/bin/../libs/connect-api-3.4.0.jar:/opt/bitnami/kafka/bin/../libs/connect-basic-auth-extension-3.4.0.jar:/opt/bitnami/kafka/bin/../libs/connect-json-3.4.0.jar:/opt/bitnami/kafka/bin/../libs/connect-mirror-3.4.0.jar:/opt/bitnami/kafka/bin/../libs/connect-mirror-client-3.4.0.jar:/opt/bitnami/kafka/bin/../libs/connect-runtime-3.4.0.jar:/opt/bitnami/kafka/bin/../libs/connect-transforms-3.4.0.jar:/opt/bitnami/kafka/bin/../libs/hk2-api-2.6.1.jar:/opt/bitnami/kafka/bin/../libs/hk2-locator-2.6.1.jar:/opt/bitnami/kafka/bin/../libs/hk2-utils-2.6.1.jar:/opt/bitnami/kafka/bin/../libs/jackson-annotations-2.13.4.jar:/opt/bitnami/kafka/bin/../libs/jackson-core-2.13.4.jar:/opt/bitnami/kafka/bin/../libs/jackson-databind-2.13.4.2.jar:/opt/bitnami/kafka/bin/../libs/jackson-dataformat-csv-2.13.4.jar:/opt/bitnami/kafka/bin/../libs/jackson-datatype-jdk8-2.13.4.jar:/opt/bitnami/kafka/bin/../libs/jackson-jaxrs-base-2.13.4.jar:/opt/bitnami/kafka/bin/../libs/jackson-jaxrs-json-provider-2.13.4.jar:/opt/bitnami/kafka/bin/../libs/jackson-module-jaxb-annotations-2.13.4.jar:/opt/bitnami/kafka/bin/../libs/jackson-module-scala_2.12-2.13.4.jar:/opt/bitnami/kafka/bin/../libs/jakarta.activation-api-1.2.2.jar:/opt/bitnami/kafka/bin/../libs/jakarta.annotation-api-1.3.5.jar:/opt/bitnami/kafka/bin/../libs/jakarta.inject-2.6.1.jar:/opt/bitnami/kafka/bin/../libs/jakarta.validation-api-2.0.2.jar:/opt/bitnami/kafka/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/opt/bitnami/kafka/bin/../libs/jakarta.xml.bind-api-2.3.3.jar:/opt/bitnami/kafka/bin/../libs/javassist-3.27.0-GA.jar:/opt/bitnami/kafka/bin/../libs/javax.annotation-api-1.3.2.jar:/opt/bitnami/kafka/bin/../libs/javax.servlet-api-3.1.0.jar:/opt/bitnami/kafka/bin/../libs/javax.ws.rs-api-2.1.1.jar:/opt/bitnami/kafka/bin/../libs/jaxb-api-2.3.0.jar:/opt/bitnami/kafka/bin/../libs/jersey-client-2.34.jar:/opt/bitnami/kafka/bin/../libs/jersey-common-2.34.jar:/opt/bitnami/kafka/bin/../libs/jersey-container-servlet-2.34.jar:/opt/bitnami/kafka/bin/../libs/jersey-container-servlet-core-2.34.jar:/opt/bitnami/kafka/bin/../libs/jersey-hk2-2.34.jar:/opt/bitnami/kafka/bin/../libs/jersey-server-2.34.jar:/opt/bitnami/kafka/bin/../libs/jetty-client-9.4.48.v20220622.jar:/opt/bitnami/kafka/bin/../libs/jetty-continuation-9.4.48.v20220622.jar:/opt/bitnami/kafka/bin/../libs/jetty-http-9.4.48.v20220622.jar:/opt/bitnami/kafka/bin/../libs/jetty-io-9.4.48.v20220622.jar:/opt/bitnami/kafka/bin/../libs/jetty-security-9.4.48.v20220622.jar:/opt/bitnami/kafka/bin/../libs/jetty-server-9.4.48.v20220622.jar:/opt/bitnami/kafka/bin/../libs/jetty-servlet-9.4.48.v20220622.jar:/opt/bitnami/kafka/bin/../libs/jetty-servlets-9.4.48.v20220622.jar:/opt/bitnami/kafka/bin/../libs/jetty-util-9.4.48.v20220622.jar:/opt/bitnami/kafka/bin/../libs/jetty-util-ajax-9.4.48.v20220622.jar:/opt/bitnami/kafka/bin/../libs/jline-3.21.0.jar:/opt/bitnami/kafka/bin/../libs/jopt-simple-5.0.4.jar:/opt/bitnami/kafka/bin/../libs/jose4j-0.7.9.jar:/opt/bitnami/kafka/bin/../libs/kafka-clients-3.4.0.jar:/opt/bitnami/kafka/bin/../libs/kafka-group-coordinator-3.4.0.jar:/opt/bitnami/kafka/bin/../libs/kafka-log4j-appender-3.4.0.jar:/opt/bitnami/kafka/bin/../libs/kafka-metadata-3.4.0.jar:/opt/bitnami/kafka/bin/../libs/kafka-raft-3.4.0.jar:/opt/bitnami/kafka/bin/../libs/kafka-server-common-3.4.0.jar:/opt/bitnami/kafka/bin/../libs/kafka-shell-3.4.0.jar:/opt/bitnami/kafka/bin/../libs/kafka-storage-3.4.0.jar:/opt/bitnami/kafka/bin/../libs/kafka-storage-api-3.4.0.jar:/opt/bitnami/kafka/bin/../libs/kafka-streams-3.4.0.jar:/opt/bitnami/kafka/bin/../libs/kafka-streams-examples-3.4.0.jar:/opt/bitnami/kafka/bin/../libs/kafka-streams-scala_2.12-3.4.0.jar:/opt/bitnami/kafka/bin/../libs/kafka-streams-test-utils-3.4.0.jar:/opt/bitnami/kafka/bin/../libs/kafka-tools-3.4.0.jar:/opt/bitnami/kafka/bin/../libs/kafka_2.12-3.4.0.jar:/opt/bitnami/kafka/bin/../libs/lz4-java-1.8.0.jar:/opt/bitnami/kafka/bin/../libs/maven-artifact-3.8.4.jar:/opt/bitnami/kafka/bin/../libs/metrics-core-2.2.0.jar:/opt/bitnami/kafka/bin/../libs/metrics-core-4.1.12.1.jar:/opt/bitnami/kafka/bin/../libs/netty-buffer-4.1.78.Final.jar:/opt/bitnami/kafka/bin/../libs/netty-codec-4.1.78.Final.jar:/opt/bitnami/kafka/bin/../libs/netty-common-4.1.78.Final.jar:/opt/bitnami/kafka/bin/../libs/netty-handler-4.1.78.Final.jar:/opt/bitnami/kafka/bin/../libs/netty-resolver-4.1.78.Final.jar:/opt/bitnami/kafka/bin/../libs/netty-transport-4.1.78.Final.jar:/opt/bitnami/kafka/bin/../libs/netty-transport-classes-epoll-4.1.78.Final.jar:/opt/bitnami/kafka/bin/../libs/netty-transport-native-epoll-4.1.78.Final.jar:/opt/bitnami/kafka/bin/../libs/netty-transport-native-unix-common-4.1.78.Final.jar:/opt/bitnami/kafka/bin/../libs/osgi-resource-locator-1.0.3.jar:/opt/bitnami/kafka/bin/../libs/paranamer-2.8.jar:/opt/bitnami/kafka/bin/../libs/plexus-utils-3.3.0.jar:/opt/bitnami/kafka/bin/../libs/reflections-0.9.12.jar:/opt/bitnami/kafka/bin/../libs/reload4j-1.2.19.jar:/opt/bitnami/kafka/bin/../libs/rocksdbjni-7.1.2.jar:/opt/bitnami/kafka/bin/../libs/scala-collection-compat_2.12-2.6.0.jar:/opt/bitnami/kafka/bin/../libs/scala-java8-compat_2.12-1.0.2.jar:/opt/bitnami/kafka/bin/../libs/scala-library-2.12.15.jar:/opt/bitnami/kafka/bin/../libs/scala-logging_2.12-3.9.4.jar:/opt/bitnami/kafka/bin/../libs/scala-reflect-2.12.15.jar:/opt/bitnami/kafka/bin/../libs/slf4j-api-1.7.36.jar:/opt/bitnami/kafka/bin/../libs/slf4j-reload4j-1.7.36.jar:/opt/bitnami/kafka/bin/../libs/snappy-java-1.1.8.4.jar:/opt/bitnami/kafka/bin/../libs/swagger-annotations-2.2.0.jar:/opt/bitnami/kafka/bin/../libs/trogdor-3.4.0.jar:/opt/bitnami/kafka/bin/../libs/zookeeper-3.6.3.jar:/opt/bitnami/kafka/bin/../libs/zookeeper-jute-3.6.3.jar:/opt/bitnami/kafka/bin/../libs/zstd-jni-1.5.2-1.jar (org.apache.zookeeper.ZooKeeper)
kafka           | [2023-04-08 08:39:40,500] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
kafka           | [2023-04-08 08:39:40,500] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
kafka           | [2023-04-08 08:39:40,501] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
kafka           | [2023-04-08 08:39:40,501] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
kafka           | [2023-04-08 08:39:40,501] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
kafka           | [2023-04-08 08:39:40,501] INFO Client environment:os.version=5.15.49-linuxkit (org.apache.zookeeper.ZooKeeper)
kafka           | [2023-04-08 08:39:40,501] INFO Client environment:user.name=? (org.apache.zookeeper.ZooKeeper)
kafka           | [2023-04-08 08:39:40,501] INFO Client environment:user.home=? (org.apache.zookeeper.ZooKeeper)
kafka           | [2023-04-08 08:39:40,501] INFO Client environment:user.dir=/ (org.apache.zookeeper.ZooKeeper)
kafka           | [2023-04-08 08:39:40,501] INFO Client environment:os.memory.free=1009MB (org.apache.zookeeper.ZooKeeper)
kafka           | [2023-04-08 08:39:40,501] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
kafka           | [2023-04-08 08:39:40,501] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
kafka           | [2023-04-08 08:39:40,511] INFO Initiating client connection, connectString=zookeeper:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@3a3e78f (org.apache.zookeeper.ZooKeeper)
kafka           | [2023-04-08 08:39:40,535] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
kafka           | [2023-04-08 08:39:40,558] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
kafka           | [2023-04-08 08:39:40,571] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
kafka           | [2023-04-08 08:39:40,589] INFO Opening socket connection to server zookeeper/172.20.0.2:2181. (org.apache.zookeeper.ClientCnxn)
kafka           | [2023-04-08 08:39:40,612] INFO Socket connection established, initiating session, client: /172.20.0.9:40746, server: zookeeper/172.20.0.2:2181 (org.apache.zookeeper.ClientCnxn)
zookeeper       | 2023-04-08 08:39:40,653 [myid:] - INFO  [SyncThread:0:o.a.z.s.p.FileTxnLog@285] - Creating new log file: log.12a
kafka           | [2023-04-08 08:39:40,691] INFO Session establishment complete on server zookeeper/172.20.0.2:2181, session id = 0x10000009a070000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
kafka           | [2023-04-08 08:39:40,708] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
kafka           | [2023-04-08 08:39:41,498] INFO Cluster ID = Xymdcc3lQP2RMcfXDgK-yQ (kafka.server.KafkaServer)
kafka           | [2023-04-08 08:39:41,953] INFO KafkaConfig values: 
kafka           | 	advertised.listeners = PLAINTEXT://kafka:9092
kafka           | 	alter.config.policy.class.name = null
kafka           | 	alter.log.dirs.replication.quota.window.num = 11
kafka           | 	alter.log.dirs.replication.quota.window.size.seconds = 1
kafka           | 	authorizer.class.name = 
kafka           | 	auto.create.topics.enable = true
kafka           | 	auto.include.jmx.reporter = true
kafka           | 	auto.leader.rebalance.enable = true
kafka           | 	background.threads = 10
kafka           | 	broker.heartbeat.interval.ms = 2000
kafka           | 	broker.id = 1
kafka           | 	broker.id.generation.enable = true
kafka           | 	broker.rack = null
kafka           | 	broker.session.timeout.ms = 9000
kafka           | 	client.quota.callback.class = null
kafka           | 	compression.type = producer
kafka           | 	connection.failed.authentication.delay.ms = 100
kafka           | 	connections.max.idle.ms = 600000
kafka           | 	connections.max.reauth.ms = 0
kafka           | 	control.plane.listener.name = null
kafka           | 	controlled.shutdown.enable = true
kafka           | 	controlled.shutdown.max.retries = 3
kafka           | 	controlled.shutdown.retry.backoff.ms = 5000
kafka           | 	controller.listener.names = null
kafka           | 	controller.quorum.append.linger.ms = 25
kafka           | 	controller.quorum.election.backoff.max.ms = 1000
kafka           | 	controller.quorum.election.timeout.ms = 1000
kafka           | 	controller.quorum.fetch.timeout.ms = 2000
kafka           | 	controller.quorum.request.timeout.ms = 2000
kafka           | 	controller.quorum.retry.backoff.ms = 20
kafka           | 	controller.quorum.voters = []
kafka           | 	controller.quota.window.num = 11
kafka           | 	controller.quota.window.size.seconds = 1
kafka           | 	controller.socket.timeout.ms = 30000
kafka           | 	create.topic.policy.class.name = null
kafka           | 	default.replication.factor = 1
kafka           | 	delegation.token.expiry.check.interval.ms = 3600000
kafka           | 	delegation.token.expiry.time.ms = 86400000
kafka           | 	delegation.token.master.key = null
kafka           | 	delegation.token.max.lifetime.ms = 604800000
kafka           | 	delegation.token.secret.key = null
kafka           | 	delete.records.purgatory.purge.interval.requests = 1
kafka           | 	delete.topic.enable = true
kafka           | 	early.start.listeners = null
kafka           | 	fetch.max.bytes = 57671680
kafka           | 	fetch.purgatory.purge.interval.requests = 1000
kafka           | 	group.initial.rebalance.delay.ms = 0
kafka           | 	group.max.session.timeout.ms = 1800000
kafka           | 	group.max.size = 2147483647
kafka           | 	group.min.session.timeout.ms = 6000
kafka           | 	initial.broker.registration.timeout.ms = 60000
kafka           | 	inter.broker.listener.name = null
kafka           | 	inter.broker.protocol.version = 3.4-IV0
kafka           | 	kafka.metrics.polling.interval.secs = 10
kafka           | 	kafka.metrics.reporters = []
kafka           | 	leader.imbalance.check.interval.seconds = 300
kafka           | 	leader.imbalance.per.broker.percentage = 10
kafka           | 	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
kafka           | 	listeners = PLAINTEXT://:9092
kafka           | 	log.cleaner.backoff.ms = 15000
kafka           | 	log.cleaner.dedupe.buffer.size = 134217728
kafka           | 	log.cleaner.delete.retention.ms = 86400000
kafka           | 	log.cleaner.enable = true
kafka           | 	log.cleaner.io.buffer.load.factor = 0.9
kafka           | 	log.cleaner.io.buffer.size = 524288
kafka           | 	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
kafka           | 	log.cleaner.max.compaction.lag.ms = 9223372036854775807
kafka           | 	log.cleaner.min.cleanable.ratio = 0.5
kafka           | 	log.cleaner.min.compaction.lag.ms = 0
kafka           | 	log.cleaner.threads = 1
kafka           | 	log.cleanup.policy = [delete]
kafka           | 	log.dir = /tmp/kafka-logs
kafka           | 	log.dirs = /bitnami/kafka/data
kafka           | 	log.flush.interval.messages = 9223372036854775807
kafka           | 	log.flush.interval.ms = null
kafka           | 	log.flush.offset.checkpoint.interval.ms = 60000
kafka           | 	log.flush.scheduler.interval.ms = 9223372036854775807
kafka           | 	log.flush.start.offset.checkpoint.interval.ms = 60000
kafka           | 	log.index.interval.bytes = 4096
kafka           | 	log.index.size.max.bytes = 10485760
kafka           | 	log.message.downconversion.enable = true
kafka           | 	log.message.format.version = 3.0-IV1
kafka           | 	log.message.timestamp.difference.max.ms = 9223372036854775807
kafka           | 	log.message.timestamp.type = CreateTime
kafka           | 	log.preallocate = false
kafka           | 	log.retention.bytes = -1
kafka           | 	log.retention.check.interval.ms = 300000
kafka           | 	log.retention.hours = 168
kafka           | 	log.retention.minutes = null
kafka           | 	log.retention.ms = null
kafka           | 	log.roll.hours = 168
kafka           | 	log.roll.jitter.hours = 0
kafka           | 	log.roll.jitter.ms = null
kafka           | 	log.roll.ms = null
kafka           | 	log.segment.bytes = 1073741824
kafka           | 	log.segment.delete.delay.ms = 60000
kafka           | 	max.connection.creation.rate = 2147483647
kafka           | 	max.connections = 2147483647
kafka           | 	max.connections.per.ip = 2147483647
kafka           | 	max.connections.per.ip.overrides = 
kafka           | 	max.incremental.fetch.session.cache.slots = 1000
kafka           | 	message.max.bytes = 1048588
kafka           | 	metadata.log.dir = null
kafka           | 	metadata.log.max.record.bytes.between.snapshots = 20971520
kafka           | 	metadata.log.max.snapshot.interval.ms = 3600000
kafka           | 	metadata.log.segment.bytes = 1073741824
kafka           | 	metadata.log.segment.min.bytes = 8388608
kafka           | 	metadata.log.segment.ms = 604800000
kafka           | 	metadata.max.idle.interval.ms = 500
kafka           | 	metadata.max.retention.bytes = 104857600
kafka           | 	metadata.max.retention.ms = 604800000
kafka           | 	metric.reporters = []
kafka           | 	metrics.num.samples = 2
kafka           | 	metrics.recording.level = INFO
kafka           | 	metrics.sample.window.ms = 30000
kafka           | 	min.insync.replicas = 1
kafka           | 	node.id = 1
kafka           | 	num.io.threads = 8
kafka           | 	num.network.threads = 3
kafka           | 	num.partitions = 1
kafka           | 	num.recovery.threads.per.data.dir = 1
kafka           | 	num.replica.alter.log.dirs.threads = null
kafka           | 	num.replica.fetchers = 1
kafka           | 	offset.metadata.max.bytes = 4096
kafka           | 	offsets.commit.required.acks = -1
kafka           | 	offsets.commit.timeout.ms = 5000
kafka           | 	offsets.load.buffer.size = 5242880
kafka           | 	offsets.retention.check.interval.ms = 600000
kafka           | 	offsets.retention.minutes = 10080
kafka           | 	offsets.topic.compression.codec = 0
kafka           | 	offsets.topic.num.partitions = 50
kafka           | 	offsets.topic.replication.factor = 1
kafka           | 	offsets.topic.segment.bytes = 104857600
kafka           | 	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
kafka           | 	password.encoder.iterations = 4096
kafka           | 	password.encoder.key.length = 128
kafka           | 	password.encoder.keyfactory.algorithm = null
kafka           | 	password.encoder.old.secret = null
kafka           | 	password.encoder.secret = null
kafka           | 	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
kafka           | 	process.roles = []
kafka           | 	producer.id.expiration.check.interval.ms = 600000
kafka           | 	producer.id.expiration.ms = 86400000
kafka           | 	producer.purgatory.purge.interval.requests = 1000
kafka           | 	queued.max.request.bytes = -1
kafka           | 	queued.max.requests = 500
kafka           | 	quota.window.num = 11
kafka           | 	quota.window.size.seconds = 1
kafka           | 	remote.log.index.file.cache.total.size.bytes = 1073741824
kafka           | 	remote.log.manager.task.interval.ms = 30000
kafka           | 	remote.log.manager.task.retry.backoff.max.ms = 30000
kafka           | 	remote.log.manager.task.retry.backoff.ms = 500
kafka           | 	remote.log.manager.task.retry.jitter = 0.2
kafka           | 	remote.log.manager.thread.pool.size = 10
kafka           | 	remote.log.metadata.manager.class.name = null
kafka           | 	remote.log.metadata.manager.class.path = null
kafka           | 	remote.log.metadata.manager.impl.prefix = null
kafka           | 	remote.log.metadata.manager.listener.name = null
kafka           | 	remote.log.reader.max.pending.tasks = 100
kafka           | 	remote.log.reader.threads = 10
kafka           | 	remote.log.storage.manager.class.name = null
kafka           | 	remote.log.storage.manager.class.path = null
kafka           | 	remote.log.storage.manager.impl.prefix = null
kafka           | 	remote.log.storage.system.enable = false
kafka           | 	replica.fetch.backoff.ms = 1000
kafka           | 	replica.fetch.max.bytes = 1048576
kafka           | 	replica.fetch.min.bytes = 1
kafka           | 	replica.fetch.response.max.bytes = 10485760
kafka           | 	replica.fetch.wait.max.ms = 500
kafka           | 	replica.high.watermark.checkpoint.interval.ms = 5000
kafka           | 	replica.lag.time.max.ms = 30000
kafka           | 	replica.selector.class = null
kafka           | 	replica.socket.receive.buffer.bytes = 65536
kafka           | 	replica.socket.timeout.ms = 30000
kafka           | 	replication.quota.window.num = 11
kafka           | 	replication.quota.window.size.seconds = 1
kafka           | 	request.timeout.ms = 30000
kafka           | 	reserved.broker.max.id = 1000
kafka           | 	sasl.client.callback.handler.class = null
kafka           | 	sasl.enabled.mechanisms = [PLAIN, SCRAM-SHA-256, SCRAM-SHA-512]
kafka           | 	sasl.jaas.config = null
kafka           | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
kafka           | 	sasl.kerberos.min.time.before.relogin = 60000
kafka           | 	sasl.kerberos.principal.to.local.rules = [DEFAULT]
kafka           | 	sasl.kerberos.service.name = null
kafka           | 	sasl.kerberos.ticket.renew.jitter = 0.05
kafka           | 	sasl.kerberos.ticket.renew.window.factor = 0.8
kafka           | 	sasl.login.callback.handler.class = null
kafka           | 	sasl.login.class = null
kafka           | 	sasl.login.connect.timeout.ms = null
kafka           | 	sasl.login.read.timeout.ms = null
kafka           | 	sasl.login.refresh.buffer.seconds = 300
kafka           | 	sasl.login.refresh.min.period.seconds = 60
kafka           | 	sasl.login.refresh.window.factor = 0.8
kafka           | 	sasl.login.refresh.window.jitter = 0.05
kafka           | 	sasl.login.retry.backoff.max.ms = 10000
kafka           | 	sasl.login.retry.backoff.ms = 100
kafka           | 	sasl.mechanism.controller.protocol = GSSAPI
kafka           | 	sasl.mechanism.inter.broker.protocol = 
kafka           | 	sasl.oauthbearer.clock.skew.seconds = 30
kafka           | 	sasl.oauthbearer.expected.audience = null
kafka           | 	sasl.oauthbearer.expected.issuer = null
kafka           | 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
kafka           | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
kafka           | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
kafka           | 	sasl.oauthbearer.jwks.endpoint.url = null
kafka           | 	sasl.oauthbearer.scope.claim.name = scope
kafka           | 	sasl.oauthbearer.sub.claim.name = sub
kafka           | 	sasl.oauthbearer.token.endpoint.url = null
kafka           | 	sasl.server.callback.handler.class = null
kafka           | 	sasl.server.max.receive.size = 524288
kafka           | 	security.inter.broker.protocol = PLAINTEXT
kafka           | 	security.providers = null
kafka           | 	socket.connection.setup.timeout.max.ms = 30000
kafka           | 	socket.connection.setup.timeout.ms = 10000
kafka           | 	socket.listen.backlog.size = 50
kafka           | 	socket.receive.buffer.bytes = 102400
kafka           | 	socket.request.max.bytes = 104857600
kafka           | 	socket.send.buffer.bytes = 102400
kafka           | 	ssl.cipher.suites = []
kafka           | 	ssl.client.auth = none
kafka           | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
kafka           | 	ssl.endpoint.identification.algorithm = https
kafka           | 	ssl.engine.factory.class = null
kafka           | 	ssl.key.password = null
kafka           | 	ssl.keymanager.algorithm = SunX509
kafka           | 	ssl.keystore.certificate.chain = null
kafka           | 	ssl.keystore.key = null
kafka           | 	ssl.keystore.location = null
kafka           | 	ssl.keystore.password = null
kafka           | 	ssl.keystore.type = JKS
kafka           | 	ssl.principal.mapping.rules = DEFAULT
kafka           | 	ssl.protocol = TLSv1.3
kafka           | 	ssl.provider = null
kafka           | 	ssl.secure.random.implementation = null
kafka           | 	ssl.trustmanager.algorithm = PKIX
kafka           | 	ssl.truststore.certificates = null
kafka           | 	ssl.truststore.location = null
kafka           | 	ssl.truststore.password = null
kafka           | 	ssl.truststore.type = JKS
kafka           | 	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
kafka           | 	transaction.max.timeout.ms = 900000
kafka           | 	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
kafka           | 	transaction.state.log.load.buffer.size = 5242880
kafka           | 	transaction.state.log.min.isr = 1
kafka           | 	transaction.state.log.num.partitions = 50
kafka           | 	transaction.state.log.replication.factor = 1
kafka           | 	transaction.state.log.segment.bytes = 104857600
kafka           | 	transactional.id.expiration.ms = 604800000
kafka           | 	unclean.leader.election.enable = false
kafka           | 	zookeeper.clientCnxnSocket = null
kafka           | 	zookeeper.connect = zookeeper:2181
kafka           | 	zookeeper.connection.timeout.ms = 18000
kafka           | 	zookeeper.max.in.flight.requests = 10
kafka           | 	zookeeper.metadata.migration.enable = false
kafka           | 	zookeeper.session.timeout.ms = 18000
kafka           | 	zookeeper.set.acl = false
kafka           | 	zookeeper.ssl.cipher.suites = null
kafka           | 	zookeeper.ssl.client.enable = false
kafka           | 	zookeeper.ssl.crl.enable = false
kafka           | 	zookeeper.ssl.enabled.protocols = null
kafka           | 	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
kafka           | 	zookeeper.ssl.keystore.location = null
kafka           | 	zookeeper.ssl.keystore.password = null
kafka           | 	zookeeper.ssl.keystore.type = null
kafka           | 	zookeeper.ssl.ocsp.enable = false
kafka           | 	zookeeper.ssl.protocol = TLSv1.2
kafka           | 	zookeeper.ssl.truststore.location = null
kafka           | 	zookeeper.ssl.truststore.password = null
kafka           | 	zookeeper.ssl.truststore.type = null
kafka           |  (kafka.server.KafkaConfig)
kafka           | [2023-04-08 08:39:42,149] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
kafka           | [2023-04-08 08:39:42,149] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
kafka           | [2023-04-08 08:39:42,159] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
kafka           | [2023-04-08 08:39:42,174] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
kafka           | [2023-04-08 08:39:42,377] INFO Loading logs from log dirs ArrayBuffer(/bitnami/kafka/data) (kafka.log.LogManager)
kafka           | [2023-04-08 08:39:42,389] INFO Skipping recovery for all logs in /bitnami/kafka/data since clean shutdown file was found (kafka.log.LogManager)
kafka           | [2023-04-08 08:39:42,847] INFO [LogLoader partition=__consumer_offsets-30, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka           | [2023-04-08 08:39:43,228] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-30, topicId=NTv8TGJ-RQKKiWlwoEXCQw, topic=__consumer_offsets, partition=30, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 684ms (1/52 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka           | [2023-04-08 08:39:43,369] INFO [LogLoader partition=__consumer_offsets-48, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka           | [2023-04-08 08:39:43,402] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-48, topicId=NTv8TGJ-RQKKiWlwoEXCQw, topic=__consumer_offsets, partition=48, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 154ms (2/52 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka           | [2023-04-08 08:39:43,412] INFO [LogLoader partition=__consumer_offsets-35, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka           | [2023-04-08 08:39:43,421] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-35, topicId=NTv8TGJ-RQKKiWlwoEXCQw, topic=__consumer_offsets, partition=35, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 18ms (3/52 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka           | [2023-04-08 08:39:43,447] INFO [LogLoader partition=__consumer_offsets-6, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka           | [2023-04-08 08:39:43,457] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-6, topicId=NTv8TGJ-RQKKiWlwoEXCQw, topic=__consumer_offsets, partition=6, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 36ms (4/52 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka           | [2023-04-08 08:39:43,479] INFO [LogLoader partition=__consumer_offsets-18, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka           | [2023-04-08 08:39:43,489] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-18, topicId=NTv8TGJ-RQKKiWlwoEXCQw, topic=__consumer_offsets, partition=18, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 32ms (5/52 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka           | [2023-04-08 08:39:43,514] INFO [LogLoader partition=__consumer_offsets-40, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka           | [2023-04-08 08:39:43,527] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-40, topicId=NTv8TGJ-RQKKiWlwoEXCQw, topic=__consumer_offsets, partition=40, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 38ms (6/52 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka           | [2023-04-08 08:39:43,548] INFO [LogLoader partition=__consumer_offsets-26, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka           | [2023-04-08 08:39:43,567] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-26, topicId=NTv8TGJ-RQKKiWlwoEXCQw, topic=__consumer_offsets, partition=26, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 39ms (7/52 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka           | [2023-04-08 08:39:43,578] INFO [LogLoader partition=__consumer_offsets-20, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka           | [2023-04-08 08:39:43,597] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-20, topicId=NTv8TGJ-RQKKiWlwoEXCQw, topic=__consumer_offsets, partition=20, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 29ms (8/52 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka           | [2023-04-08 08:39:43,760] INFO [LogLoader partition=__consumer_offsets-38, dir=/bitnami/kafka/data] Loading producer state till offset 3 with message format version 2 (kafka.log.UnifiedLog$)
kafka           | [2023-04-08 08:39:43,766] INFO [LogLoader partition=__consumer_offsets-38, dir=/bitnami/kafka/data] Reloading from producer snapshot and rebuilding producer state from offset 3 (kafka.log.UnifiedLog$)
kafka           | [2023-04-08 08:39:43,780] INFO [ProducerStateManager partition=__consumer_offsets-38] Loading producer state from snapshot file 'SnapshotFile(/bitnami/kafka/data/__consumer_offsets-38/00000000000000000003.snapshot,3)' (kafka.log.ProducerStateManager)
kafka           | [2023-04-08 08:39:43,819] INFO [LogLoader partition=__consumer_offsets-38, dir=/bitnami/kafka/data] Producer state recovery took 52ms for snapshot load and 1ms for segment recovery from offset 3 (kafka.log.UnifiedLog$)
kafka           | [2023-04-08 08:39:43,832] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-38, topicId=NTv8TGJ-RQKKiWlwoEXCQw, topic=__consumer_offsets, partition=38, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=3) with 1 segments in 234ms (9/52 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka           | [2023-04-08 08:39:43,849] INFO [LogLoader partition=__consumer_offsets-17, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka           | [2023-04-08 08:39:43,860] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-17, topicId=NTv8TGJ-RQKKiWlwoEXCQw, topic=__consumer_offsets, partition=17, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 28ms (10/52 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka           | [2023-04-08 08:39:43,876] INFO [LogLoader partition=__consumer_offsets-2, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka           | [2023-04-08 08:39:43,888] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-2, topicId=NTv8TGJ-RQKKiWlwoEXCQw, topic=__consumer_offsets, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 28ms (11/52 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka           | [2023-04-08 08:39:43,906] INFO [LogLoader partition=__consumer_offsets-41, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka           | [2023-04-08 08:39:43,918] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-41, topicId=NTv8TGJ-RQKKiWlwoEXCQw, topic=__consumer_offsets, partition=41, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 30ms (12/52 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka           | [2023-04-08 08:39:43,928] INFO [LogLoader partition=__consumer_offsets-16, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka           | [2023-04-08 08:39:43,934] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-16, topicId=NTv8TGJ-RQKKiWlwoEXCQw, topic=__consumer_offsets, partition=16, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 15ms (13/52 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka           | [2023-04-08 08:39:43,943] INFO [LogLoader partition=__consumer_offsets-28, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka           | [2023-04-08 08:39:43,951] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-28, topicId=NTv8TGJ-RQKKiWlwoEXCQw, topic=__consumer_offsets, partition=28, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 16ms (14/52 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka           | [2023-04-08 08:39:43,959] INFO [LogLoader partition=__consumer_offsets-10, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka           | [2023-04-08 08:39:43,969] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-10, topicId=NTv8TGJ-RQKKiWlwoEXCQw, topic=__consumer_offsets, partition=10, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 17ms (15/52 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka           | [2023-04-08 08:39:43,978] INFO [LogLoader partition=__consumer_offsets-22, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka           | [2023-04-08 08:39:43,987] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-22, topicId=NTv8TGJ-RQKKiWlwoEXCQw, topic=__consumer_offsets, partition=22, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 18ms (16/52 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka           | [2023-04-08 08:39:43,998] INFO [LogLoader partition=__consumer_offsets-34, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka           | [2023-04-08 08:39:44,007] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-34, topicId=NTv8TGJ-RQKKiWlwoEXCQw, topic=__consumer_offsets, partition=34, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 20ms (17/52 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka           | [2023-04-08 08:39:44,021] INFO [LogLoader partition=__consumer_offsets-47, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka           | [2023-04-08 08:39:44,030] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-47, topicId=NTv8TGJ-RQKKiWlwoEXCQw, topic=__consumer_offsets, partition=47, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 22ms (18/52 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka           | [2023-04-08 08:39:44,039] INFO [LogLoader partition=__consumer_offsets-44, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka           | [2023-04-08 08:39:44,046] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-44, topicId=NTv8TGJ-RQKKiWlwoEXCQw, topic=__consumer_offsets, partition=44, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 16ms (19/52 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka           | [2023-04-08 08:39:44,055] INFO [LogLoader partition=__consumer_offsets-5, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka           | [2023-04-08 08:39:44,063] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-5, topicId=NTv8TGJ-RQKKiWlwoEXCQw, topic=__consumer_offsets, partition=5, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 17ms (20/52 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka           | [2023-04-08 08:39:44,078] INFO [LogLoader partition=__consumer_offsets-37, dir=/bitnami/kafka/data] Loading producer state till offset 3 with message format version 2 (kafka.log.UnifiedLog$)
kafka           | [2023-04-08 08:39:44,078] INFO [LogLoader partition=__consumer_offsets-37, dir=/bitnami/kafka/data] Reloading from producer snapshot and rebuilding producer state from offset 3 (kafka.log.UnifiedLog$)
kafka           | [2023-04-08 08:39:44,078] INFO [ProducerStateManager partition=__consumer_offsets-37] Loading producer state from snapshot file 'SnapshotFile(/bitnami/kafka/data/__consumer_offsets-37/00000000000000000003.snapshot,3)' (kafka.log.ProducerStateManager)
kafka           | [2023-04-08 08:39:44,079] INFO [LogLoader partition=__consumer_offsets-37, dir=/bitnami/kafka/data] Producer state recovery took 1ms for snapshot load and 0ms for segment recovery from offset 3 (kafka.log.UnifiedLog$)
kafka           | [2023-04-08 08:39:44,089] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-37, topicId=NTv8TGJ-RQKKiWlwoEXCQw, topic=__consumer_offsets, partition=37, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=3) with 1 segments in 25ms (21/52 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka           | [2023-04-08 08:39:44,100] INFO [LogLoader partition=__consumer_offsets-39, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka           | [2023-04-08 08:39:44,108] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-39, topicId=NTv8TGJ-RQKKiWlwoEXCQw, topic=__consumer_offsets, partition=39, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 19ms (22/52 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka           | [2023-04-08 08:39:44,121] INFO [LogLoader partition=__consumer_offsets-4, dir=/bitnami/kafka/data] Loading producer state till offset 2 with message format version 2 (kafka.log.UnifiedLog$)
kafka           | [2023-04-08 08:39:44,121] INFO [LogLoader partition=__consumer_offsets-4, dir=/bitnami/kafka/data] Reloading from producer snapshot and rebuilding producer state from offset 2 (kafka.log.UnifiedLog$)
kafka           | [2023-04-08 08:39:44,122] INFO [ProducerStateManager partition=__consumer_offsets-4] Loading producer state from snapshot file 'SnapshotFile(/bitnami/kafka/data/__consumer_offsets-4/00000000000000000002.snapshot,2)' (kafka.log.ProducerStateManager)
kafka           | [2023-04-08 08:39:44,122] INFO [LogLoader partition=__consumer_offsets-4, dir=/bitnami/kafka/data] Producer state recovery took 1ms for snapshot load and 0ms for segment recovery from offset 2 (kafka.log.UnifiedLog$)
kafka           | [2023-04-08 08:39:44,129] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-4, topicId=NTv8TGJ-RQKKiWlwoEXCQw, topic=__consumer_offsets, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=2) with 1 segments in 20ms (23/52 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka           | [2023-04-08 08:39:44,143] INFO [LogLoader partition=__consumer_offsets-27, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka           | [2023-04-08 08:39:44,152] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-27, topicId=NTv8TGJ-RQKKiWlwoEXCQw, topic=__consumer_offsets, partition=27, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 23ms (24/52 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka           | [2023-04-08 08:39:44,162] INFO [LogLoader partition=__consumer_offsets-12, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka           | [2023-04-08 08:39:44,171] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-12, topicId=NTv8TGJ-RQKKiWlwoEXCQw, topic=__consumer_offsets, partition=12, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 19ms (25/52 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka           | [2023-04-08 08:39:44,182] INFO [LogLoader partition=__consumer_offsets-9, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka           | [2023-04-08 08:39:44,189] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-9, topicId=NTv8TGJ-RQKKiWlwoEXCQw, topic=__consumer_offsets, partition=9, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 17ms (26/52 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka           | [2023-04-08 08:39:44,198] INFO [LogLoader partition=__consumer_offsets-42, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka           | [2023-04-08 08:39:44,205] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-42, topicId=NTv8TGJ-RQKKiWlwoEXCQw, topic=__consumer_offsets, partition=42, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 15ms (27/52 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka           | [2023-04-08 08:39:44,216] INFO [LogLoader partition=__consumer_offsets-46, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka           | [2023-04-08 08:39:44,223] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-46, topicId=NTv8TGJ-RQKKiWlwoEXCQw, topic=__consumer_offsets, partition=46, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 18ms (28/52 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka           | [2023-04-08 08:39:44,240] INFO [LogLoader partition=__consumer_offsets-31, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka           | [2023-04-08 08:39:44,250] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-31, topicId=NTv8TGJ-RQKKiWlwoEXCQw, topic=__consumer_offsets, partition=31, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 26ms (29/52 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka           | [2023-04-08 08:39:44,261] INFO [LogLoader partition=__consumer_offsets-15, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka           | [2023-04-08 08:39:44,274] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-15, topicId=NTv8TGJ-RQKKiWlwoEXCQw, topic=__consumer_offsets, partition=15, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 24ms (30/52 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka           | [2023-04-08 08:39:44,284] INFO [LogLoader partition=__consumer_offsets-13, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka           | [2023-04-08 08:39:44,295] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-13, topicId=NTv8TGJ-RQKKiWlwoEXCQw, topic=__consumer_offsets, partition=13, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 21ms (31/52 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka           | [2023-04-08 08:39:44,307] INFO [LogLoader partition=__consumer_offsets-24, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka           | [2023-04-08 08:39:44,315] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-24, topicId=NTv8TGJ-RQKKiWlwoEXCQw, topic=__consumer_offsets, partition=24, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 18ms (32/52 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka           | [2023-04-08 08:39:44,332] INFO [LogLoader partition=__consumer_offsets-0, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka           | [2023-04-08 08:39:44,339] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-0, topicId=NTv8TGJ-RQKKiWlwoEXCQw, topic=__consumer_offsets, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 22ms (33/52 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka           | [2023-04-08 08:39:44,355] INFO Deleted producer state snapshot /bitnami/kafka/data/__consumer_offsets-32/00000000000000000002.snapshot (kafka.log.SnapshotFile)
kafka           | [2023-04-08 08:39:44,355] INFO [LogLoader partition=__consumer_offsets-32, dir=/bitnami/kafka/data] Loading producer state till offset 3 with message format version 2 (kafka.log.UnifiedLog$)
kafka           | [2023-04-08 08:39:44,355] INFO [LogLoader partition=__consumer_offsets-32, dir=/bitnami/kafka/data] Reloading from producer snapshot and rebuilding producer state from offset 3 (kafka.log.UnifiedLog$)
kafka           | [2023-04-08 08:39:44,356] INFO [ProducerStateManager partition=__consumer_offsets-32] Loading producer state from snapshot file 'SnapshotFile(/bitnami/kafka/data/__consumer_offsets-32/00000000000000000003.snapshot,3)' (kafka.log.ProducerStateManager)
kafka           | [2023-04-08 08:39:44,357] INFO [LogLoader partition=__consumer_offsets-32, dir=/bitnami/kafka/data] Producer state recovery took 2ms for snapshot load and 0ms for segment recovery from offset 3 (kafka.log.UnifiedLog$)
kafka           | [2023-04-08 08:39:44,362] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-32, topicId=NTv8TGJ-RQKKiWlwoEXCQw, topic=__consumer_offsets, partition=32, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=3) with 1 segments in 24ms (34/52 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka           | [2023-04-08 08:39:44,373] INFO [LogLoader partition=__consumer_offsets-3, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka           | [2023-04-08 08:39:44,379] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-3, topicId=NTv8TGJ-RQKKiWlwoEXCQw, topic=__consumer_offsets, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 17ms (35/52 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka           | [2023-04-08 08:39:44,392] INFO [LogLoader partition=__consumer_offsets-33, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka           | [2023-04-08 08:39:44,398] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-33, topicId=NTv8TGJ-RQKKiWlwoEXCQw, topic=__consumer_offsets, partition=33, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 19ms (36/52 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka           | [2023-04-08 08:39:44,411] INFO [LogLoader partition=__consumer_offsets-29, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka           | [2023-04-08 08:39:44,417] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-29, topicId=NTv8TGJ-RQKKiWlwoEXCQw, topic=__consumer_offsets, partition=29, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 19ms (37/52 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka           | [2023-04-08 08:39:44,426] INFO [LogLoader partition=__consumer_offsets-8, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka           | [2023-04-08 08:39:44,430] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-8, topicId=NTv8TGJ-RQKKiWlwoEXCQw, topic=__consumer_offsets, partition=8, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 13ms (38/52 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka           | [2023-04-08 08:39:44,439] INFO [LogLoader partition=__consumer_offsets-14, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka           | [2023-04-08 08:39:44,448] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-14, topicId=NTv8TGJ-RQKKiWlwoEXCQw, topic=__consumer_offsets, partition=14, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 18ms (39/52 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka           | [2023-04-08 08:39:44,456] INFO [LogLoader partition=__consumer_offsets-45, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka           | [2023-04-08 08:39:44,461] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-45, topicId=NTv8TGJ-RQKKiWlwoEXCQw, topic=__consumer_offsets, partition=45, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 12ms (40/52 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka           | [2023-04-08 08:39:44,470] INFO [LogLoader partition=frames-0, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka           | [2023-04-08 08:39:44,479] INFO Completed load of Log(dir=/bitnami/kafka/data/frames-0, topicId=AbARUGuiRlC57s0b2k3Ivg, topic=frames, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 18ms (41/52 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka           | [2023-04-08 08:39:44,490] INFO [LogLoader partition=videos-0, dir=/bitnami/kafka/data] Loading producer state till offset 1 with message format version 2 (kafka.log.UnifiedLog$)
kafka           | [2023-04-08 08:39:44,490] INFO [LogLoader partition=videos-0, dir=/bitnami/kafka/data] Reloading from producer snapshot and rebuilding producer state from offset 1 (kafka.log.UnifiedLog$)
kafka           | [2023-04-08 08:39:44,492] INFO [ProducerStateManager partition=videos-0] Loading producer state from snapshot file 'SnapshotFile(/bitnami/kafka/data/videos-0/00000000000000000001.snapshot,1)' (kafka.log.ProducerStateManager)
kafka           | [2023-04-08 08:39:44,493] INFO [LogLoader partition=videos-0, dir=/bitnami/kafka/data] Producer state recovery took 2ms for snapshot load and 0ms for segment recovery from offset 1 (kafka.log.UnifiedLog$)
kafka           | [2023-04-08 08:39:44,497] INFO Completed load of Log(dir=/bitnami/kafka/data/videos-0, topicId=UU2dlzBHSDakK2HrjOsVgA, topic=videos, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=1) with 1 segments in 18ms (42/52 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka           | [2023-04-08 08:39:44,506] INFO [LogLoader partition=__consumer_offsets-19, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka           | [2023-04-08 08:39:44,510] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-19, topicId=NTv8TGJ-RQKKiWlwoEXCQw, topic=__consumer_offsets, partition=19, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 13ms (43/52 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka           | [2023-04-08 08:39:44,524] INFO [LogLoader partition=__consumer_offsets-7, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka           | [2023-04-08 08:39:44,529] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-7, topicId=NTv8TGJ-RQKKiWlwoEXCQw, topic=__consumer_offsets, partition=7, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 19ms (44/52 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka           | [2023-04-08 08:39:44,541] INFO [LogLoader partition=__consumer_offsets-25, dir=/bitnami/kafka/data] Loading producer state till offset 2 with message format version 2 (kafka.log.UnifiedLog$)
kafka           | [2023-04-08 08:39:44,541] INFO [LogLoader partition=__consumer_offsets-25, dir=/bitnami/kafka/data] Reloading from producer snapshot and rebuilding producer state from offset 2 (kafka.log.UnifiedLog$)
kafka           | [2023-04-08 08:39:44,541] INFO [ProducerStateManager partition=__consumer_offsets-25] Loading producer state from snapshot file 'SnapshotFile(/bitnami/kafka/data/__consumer_offsets-25/00000000000000000002.snapshot,2)' (kafka.log.ProducerStateManager)
kafka           | [2023-04-08 08:39:44,542] INFO [LogLoader partition=__consumer_offsets-25, dir=/bitnami/kafka/data] Producer state recovery took 1ms for snapshot load and 0ms for segment recovery from offset 2 (kafka.log.UnifiedLog$)
kafka           | [2023-04-08 08:39:44,549] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-25, topicId=NTv8TGJ-RQKKiWlwoEXCQw, topic=__consumer_offsets, partition=25, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=2) with 1 segments in 19ms (45/52 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka           | [2023-04-08 08:39:44,563] INFO [LogLoader partition=__consumer_offsets-43, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka           | [2023-04-08 08:39:44,571] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-43, topicId=NTv8TGJ-RQKKiWlwoEXCQw, topic=__consumer_offsets, partition=43, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 21ms (46/52 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka           | [2023-04-08 08:39:44,583] INFO [LogLoader partition=__consumer_offsets-11, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka           | [2023-04-08 08:39:44,591] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-11, topicId=NTv8TGJ-RQKKiWlwoEXCQw, topic=__consumer_offsets, partition=11, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 19ms (47/52 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka           | [2023-04-08 08:39:44,605] INFO [LogLoader partition=__consumer_offsets-49, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka           | [2023-04-08 08:39:44,611] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-49, topicId=NTv8TGJ-RQKKiWlwoEXCQw, topic=__consumer_offsets, partition=49, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 20ms (48/52 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka           | [2023-04-08 08:39:44,625] INFO [LogLoader partition=__consumer_offsets-36, dir=/bitnami/kafka/data] Loading producer state till offset 3 with message format version 2 (kafka.log.UnifiedLog$)
kafka           | [2023-04-08 08:39:44,625] INFO [LogLoader partition=__consumer_offsets-36, dir=/bitnami/kafka/data] Reloading from producer snapshot and rebuilding producer state from offset 3 (kafka.log.UnifiedLog$)
kafka           | [2023-04-08 08:39:44,626] INFO [ProducerStateManager partition=__consumer_offsets-36] Loading producer state from snapshot file 'SnapshotFile(/bitnami/kafka/data/__consumer_offsets-36/00000000000000000003.snapshot,3)' (kafka.log.ProducerStateManager)
kafka           | [2023-04-08 08:39:44,628] INFO [LogLoader partition=__consumer_offsets-36, dir=/bitnami/kafka/data] Producer state recovery took 3ms for snapshot load and 0ms for segment recovery from offset 3 (kafka.log.UnifiedLog$)
kafka           | [2023-04-08 08:39:44,634] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-36, topicId=NTv8TGJ-RQKKiWlwoEXCQw, topic=__consumer_offsets, partition=36, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=3) with 1 segments in 23ms (49/52 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka           | [2023-04-08 08:39:44,645] INFO [LogLoader partition=__consumer_offsets-1, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka           | [2023-04-08 08:39:44,650] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-1, topicId=NTv8TGJ-RQKKiWlwoEXCQw, topic=__consumer_offsets, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 16ms (50/52 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka           | [2023-04-08 08:39:44,662] INFO [LogLoader partition=__consumer_offsets-21, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka           | [2023-04-08 08:39:44,668] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-21, topicId=NTv8TGJ-RQKKiWlwoEXCQw, topic=__consumer_offsets, partition=21, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 17ms (51/52 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka           | [2023-04-08 08:39:44,679] INFO [LogLoader partition=__consumer_offsets-23, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
kafka           | [2023-04-08 08:39:44,685] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-23, topicId=NTv8TGJ-RQKKiWlwoEXCQw, topic=__consumer_offsets, partition=23, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 16ms (52/52 completed in /bitnami/kafka/data) (kafka.log.LogManager)
kafka           | [2023-04-08 08:39:44,717] INFO Loaded 52 logs in 2340ms. (kafka.log.LogManager)
kafka           | [2023-04-08 08:39:44,723] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
kafka           | [2023-04-08 08:39:44,727] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
kafka           | [2023-04-08 08:39:44,779] INFO Starting the log cleaner (kafka.log.LogCleaner)
kafka           | [2023-04-08 08:39:45,073] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner)
kafka           | [2023-04-08 08:39:45,158] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
kafka           | [2023-04-08 08:39:45,276] INFO [MetadataCache brokerId=1] Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Map(), epoch=0). (kafka.server.metadata.ZkMetadataCache)
kafka           | [2023-04-08 08:39:45,381] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
kafka           | [2023-04-08 08:39:46,862] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
kafka           | [2023-04-08 08:39:46,881] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.DataPlaneAcceptor)
kafka           | [2023-04-08 08:39:46,973] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
kafka           | [2023-04-08 08:39:46,992] INFO [BrokerToControllerChannelManager broker=1 name=alterPartition]: Starting (kafka.server.BrokerToControllerRequestThread)
kafka           | [2023-04-08 08:39:47,074] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
kafka           | [2023-04-08 08:39:47,080] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
kafka           | [2023-04-08 08:39:47,087] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
kafka           | [2023-04-08 08:39:47,093] INFO [ExpirationReaper-1-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
kafka           | [2023-04-08 08:39:47,156] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
kafka           | [2023-04-08 08:39:47,353] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
kafka           | [2023-04-08 08:39:47,438] INFO Stat of the created znode at /brokers/ids/1 is: 313,313,1680943187408,1680943187408,1,0,0,72057596622077952,194,0,313
kafka           |  (kafka.zk.KafkaZkClient)
kafka           | [2023-04-08 08:39:47,443] INFO Registered broker 1 at path /brokers/ids/1 with addresses: PLAINTEXT://kafka:9092, czxid (broker epoch): 313 (kafka.zk.KafkaZkClient)
kafka           | [2023-04-08 08:39:47,676] INFO [ControllerEventThread controllerId=1] Starting (kafka.controller.ControllerEventManager$ControllerEventThread)
kafka           | [2023-04-08 08:39:47,716] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
kafka           | [2023-04-08 08:39:47,751] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
kafka           | [2023-04-08 08:39:47,751] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
kafka           | [2023-04-08 08:39:47,763] INFO [Controller id=1] 1 successfully elected as the controller. Epoch incremented to 10 and epoch zk version is now 10 (kafka.controller.KafkaController)
kafka           | [2023-04-08 08:39:47,772] INFO [Controller id=1] Registering handlers (kafka.controller.KafkaController)
kafka           | [2023-04-08 08:39:47,790] INFO [Controller id=1] Deleting log dir event notifications (kafka.controller.KafkaController)
kafka           | [2023-04-08 08:39:47,802] INFO [Controller id=1] Deleting isr change notifications (kafka.controller.KafkaController)
kafka           | [2023-04-08 08:39:47,809] INFO [Controller id=1] Initializing controller context (kafka.controller.KafkaController)
kafka           | [2023-04-08 08:39:47,814] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
kafka           | [2023-04-08 08:39:47,872] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
kafka           | [2023-04-08 08:39:47,880] INFO [Controller id=1] Initialized broker epochs cache: Map(1 -> 313) (kafka.controller.KafkaController)
kafka           | [2023-04-08 08:39:48,019] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
kafka           | [2023-04-08 08:39:48,037] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
kafka           | [2023-04-08 08:39:48,047] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
kafka           | [2023-04-08 08:39:48,208] DEBUG [Controller id=1] Register BrokerModifications handler for Set(1) (kafka.controller.KafkaController)
kafka           | [2023-04-08 08:39:48,345] INFO [ExpirationReaper-1-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
kafka           | [2023-04-08 08:39:48,436] DEBUG [Channel manager on controller 1]: Controller 1 trying to connect to broker 1 (kafka.controller.ControllerChannelManager)
kafka           | [2023-04-08 08:39:48,485] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
kafka           | [2023-04-08 08:39:48,516] INFO [Controller id=1] Currently active brokers in the cluster: Set(1) (kafka.controller.KafkaController)
kafka           | [2023-04-08 08:39:48,517] INFO [Controller id=1] Currently shutting brokers in the cluster: Set() (kafka.controller.KafkaController)
kafka           | [2023-04-08 08:39:48,518] INFO [Controller id=1] Current list of topics in the cluster: Set(__consumer_offsets, frames, videos) (kafka.controller.KafkaController)
kafka           | [2023-04-08 08:39:48,519] INFO [Controller id=1] Fetching topic deletions in progress (kafka.controller.KafkaController)
kafka           | [2023-04-08 08:39:48,521] INFO [RequestSendThread controllerId=1] Starting (kafka.controller.RequestSendThread)
kafka           | [2023-04-08 08:39:48,592] INFO [Controller id=1] List of topics to be deleted:  (kafka.controller.KafkaController)
kafka           | [2023-04-08 08:39:48,594] INFO [Controller id=1] List of topics ineligible for deletion:  (kafka.controller.KafkaController)
kafka           | [2023-04-08 08:39:48,595] INFO [Controller id=1] Initializing topic deletion manager (kafka.controller.KafkaController)
kafka           | [2023-04-08 08:39:48,597] INFO [Topic Deletion Manager 1] Initializing manager with initial deletions: Set(), initial ineligible deletions: Set() (kafka.controller.TopicDeletionManager)
kafka           | [2023-04-08 08:39:48,600] INFO [Controller id=1] Sending update metadata request (kafka.controller.KafkaController)
kafka           | [2023-04-08 08:39:48,644] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Enabling request processing. (kafka.network.SocketServer)
kafka           | [2023-04-08 08:39:48,647] INFO [Controller id=1 epoch=10] Sending UpdateMetadata request to brokers Set(1) for 0 partitions (state.change.logger)
kafka           | [2023-04-08 08:39:48,709] INFO [ReplicaStateMachine controllerId=1] Initializing replica state (kafka.controller.ZkReplicaStateMachine)
kafka           | [2023-04-08 08:39:48,752] INFO Kafka version: 3.4.0 (org.apache.kafka.common.utils.AppInfoParser)
kafka           | [2023-04-08 08:39:48,758] INFO Kafka commitId: 2e1947d240607d53 (org.apache.kafka.common.utils.AppInfoParser)
kafka           | [2023-04-08 08:39:48,759] INFO Kafka startTimeMs: 1680943188668 (org.apache.kafka.common.utils.AppInfoParser)
kafka           | [2023-04-08 08:39:48,805] INFO [ReplicaStateMachine controllerId=1] Triggering online replica state changes (kafka.controller.ZkReplicaStateMachine)
kafka           | [2023-04-08 08:39:48,830] INFO [RequestSendThread controllerId=1] Controller 1 connected to kafka:9092 (id: 1 rack: null) for sending state change requests (kafka.controller.RequestSendThread)
kafka           | [2023-04-08 08:39:48,839] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
kafka           | [2023-04-08 08:39:48,947] INFO [Controller id=1 epoch=10] Sending LeaderAndIsr request to broker 1 with 52 become-leader and 0 become-follower partitions (state.change.logger)
kafka           | [2023-04-08 08:39:48,960] INFO [Controller id=1 epoch=10] Sending UpdateMetadata request to brokers Set(1) for 52 partitions (state.change.logger)
kafka           | [2023-04-08 08:39:48,966] INFO [ReplicaStateMachine controllerId=1] Triggering offline replica state changes (kafka.controller.ZkReplicaStateMachine)
kafka           | [2023-04-08 08:39:48,980] DEBUG [ReplicaStateMachine controllerId=1] Started replica state machine with initial state -> Map([Topic=frames,Partition=0,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=30,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=8,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=4,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=26,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=18,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=36,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=13,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=10,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=41,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=21,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=3,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=49,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=33,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=0,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=32,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=37,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=15,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=22,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=11,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=24,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=9,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=46,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=35,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=29,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=45,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=19,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=7,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=27,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=14,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=28,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=44,Replica=1] -> OnlineReplica, [Topic=videos,Partition=0,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=40,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=43,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=34,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=6,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=31,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=47,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=1,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=17,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=20,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=16,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=48,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=12,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=2,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=38,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=42,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=39,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=5,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=25,Replica=1] -> OnlineReplica, [Topic=__consumer_offsets,Partition=23,Replica=1] -> OnlineReplica) (kafka.controller.ZkReplicaStateMachine)
kafka           | [2023-04-08 08:39:48,983] INFO [PartitionStateMachine controllerId=1] Initializing partition state (kafka.controller.ZkPartitionStateMachine)
kafka           | [2023-04-08 08:39:49,009] INFO [PartitionStateMachine controllerId=1] Triggering online partition state changes (kafka.controller.ZkPartitionStateMachine)
kafka           | [2023-04-08 08:39:49,016] DEBUG [PartitionStateMachine controllerId=1] Started partition state machine with initial state -> Map(__consumer_offsets-49 -> OnlinePartition, __consumer_offsets-38 -> OnlinePartition, __consumer_offsets-16 -> OnlinePartition, __consumer_offsets-27 -> OnlinePartition, __consumer_offsets-8 -> OnlinePartition, __consumer_offsets-19 -> OnlinePartition, __consumer_offsets-13 -> OnlinePartition, __consumer_offsets-2 -> OnlinePartition, __consumer_offsets-46 -> OnlinePartition, __consumer_offsets-35 -> OnlinePartition, __consumer_offsets-24 -> OnlinePartition, __consumer_offsets-5 -> OnlinePartition, __consumer_offsets-43 -> OnlinePartition, __consumer_offsets-32 -> OnlinePartition, __consumer_offsets-21 -> OnlinePartition, __consumer_offsets-10 -> OnlinePartition, __consumer_offsets-37 -> OnlinePartition, __consumer_offsets-48 -> OnlinePartition, __consumer_offsets-40 -> OnlinePartition, __consumer_offsets-18 -> OnlinePartition, __consumer_offsets-29 -> OnlinePartition, __consumer_offsets-7 -> OnlinePartition, __consumer_offsets-23 -> OnlinePartition, __consumer_offsets-45 -> OnlinePartition, __consumer_offsets-34 -> OnlinePartition, __consumer_offsets-26 -> OnlinePartition, __consumer_offsets-4 -> OnlinePartition, __consumer_offsets-15 -> OnlinePartition, __consumer_offsets-42 -> OnlinePartition, __consumer_offsets-31 -> OnlinePartition, __consumer_offsets-9 -> OnlinePartition, __consumer_offsets-20 -> OnlinePartition, __consumer_offsets-12 -> OnlinePartition, __consumer_offsets-1 -> OnlinePartition, frames-0 -> OnlinePartition, __consumer_offsets-28 -> OnlinePartition, __consumer_offsets-17 -> OnlinePartition, __consumer_offsets-6 -> OnlinePartition, __consumer_offsets-39 -> OnlinePartition, __consumer_offsets-44 -> OnlinePartition, __consumer_offsets-36 -> OnlinePartition, __consumer_offsets-47 -> OnlinePartition, __consumer_offsets-3 -> OnlinePartition, __consumer_offsets-25 -> OnlinePartition, __consumer_offsets-14 -> OnlinePartition, __consumer_offsets-30 -> OnlinePartition, __consumer_offsets-41 -> OnlinePartition, videos-0 -> OnlinePartition, __consumer_offsets-33 -> OnlinePartition, __consumer_offsets-22 -> OnlinePartition, __consumer_offsets-11 -> OnlinePartition, __consumer_offsets-0 -> OnlinePartition) (kafka.controller.ZkPartitionStateMachine)
kafka           | [2023-04-08 08:39:49,018] INFO [Controller id=1] Ready to serve as the new controller with epoch 10 (kafka.controller.KafkaController)
kafka           | [2023-04-08 08:39:49,046] INFO [Controller id=1] Partitions undergoing preferred replica election:  (kafka.controller.KafkaController)
kafka           | [2023-04-08 08:39:49,047] INFO [Controller id=1] Partitions that completed preferred replica election:  (kafka.controller.KafkaController)
kafka           | [2023-04-08 08:39:49,048] INFO [Controller id=1] Skipping preferred replica election for partitions due to topic deletion:  (kafka.controller.KafkaController)
kafka           | [2023-04-08 08:39:49,049] INFO [Controller id=1] Resuming preferred replica election for partitions:  (kafka.controller.KafkaController)
kafka           | [2023-04-08 08:39:49,053] INFO [Controller id=1] Starting replica leader election (PREFERRED) for partitions  triggered by ZkTriggered (kafka.controller.KafkaController)
kafka           | [2023-04-08 08:39:49,096] INFO [Controller id=1] Starting the controller scheduler (kafka.controller.KafkaController)
kafka           | [2023-04-08 08:39:49,162] INFO [BrokerToControllerChannelManager broker=1 name=alterPartition]: Recorded new controller, from now on will use node kafka:9092 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
kafka           | [2023-04-08 08:39:49,163] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Recorded new controller, from now on will use node kafka:9092 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
kafka           | [2023-04-08 08:39:49,269] INFO [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 for 52 partitions (state.change.logger)
kafka           | [2023-04-08 08:39:49,460] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(__consumer_offsets-22, frames-0, __consumer_offsets-30, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-46, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-37, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-48, videos-0, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-13, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
kafka           | [2023-04-08 08:39:49,464] INFO [Broker id=1] Stopped fetchers as part of LeaderAndIsr request correlationId 1 from controller 1 epoch 10 as part of the become-leader transition for 52 partitions (state.change.logger)
kafka           | [2023-04-08 08:39:49,517] INFO [Partition __consumer_offsets-0 broker=1] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
kafka           | [2023-04-08 08:39:49,523] INFO [Broker id=1] Leader __consumer_offsets-0 with topic id Some(NTv8TGJ-RQKKiWlwoEXCQw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
kafka           | [2023-04-08 08:39:49,544] INFO [Partition __consumer_offsets-29 broker=1] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)
kafka           | [2023-04-08 08:39:49,544] INFO [Broker id=1] Leader __consumer_offsets-29 with topic id Some(NTv8TGJ-RQKKiWlwoEXCQw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
kafka           | [2023-04-08 08:39:49,549] INFO [Partition __consumer_offsets-48 broker=1] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
kafka           | [2023-04-08 08:39:49,549] INFO [Broker id=1] Leader __consumer_offsets-48 with topic id Some(NTv8TGJ-RQKKiWlwoEXCQw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
kafka           | [2023-04-08 08:39:49,566] INFO [Partition __consumer_offsets-10 broker=1] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
kafka           | [2023-04-08 08:39:49,567] INFO [Broker id=1] Leader __consumer_offsets-10 with topic id Some(NTv8TGJ-RQKKiWlwoEXCQw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
kafka           | [2023-04-08 08:39:49,572] INFO [Partition __consumer_offsets-45 broker=1] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
kafka           | [2023-04-08 08:39:49,573] INFO [Broker id=1] Leader __consumer_offsets-45 with topic id Some(NTv8TGJ-RQKKiWlwoEXCQw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
kafka           | [2023-04-08 08:39:49,575] INFO [Partition __consumer_offsets-26 broker=1] Log loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Partition)
kafka           | [2023-04-08 08:39:49,576] INFO [Broker id=1] Leader __consumer_offsets-26 with topic id Some(NTv8TGJ-RQKKiWlwoEXCQw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
kafka           | [2023-04-08 08:39:49,580] INFO [Partition __consumer_offsets-7 broker=1] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
kafka           | [2023-04-08 08:39:49,582] INFO [Broker id=1] Leader __consumer_offsets-7 with topic id Some(NTv8TGJ-RQKKiWlwoEXCQw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
kafka           | [2023-04-08 08:39:49,588] INFO [Partition __consumer_offsets-42 broker=1] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
kafka           | [2023-04-08 08:39:49,589] INFO [Broker id=1] Leader __consumer_offsets-42 with topic id Some(NTv8TGJ-RQKKiWlwoEXCQw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
kafka           | [2023-04-08 08:39:49,594] INFO [Partition __consumer_offsets-4 broker=1] Log loaded for partition __consumer_offsets-4 with initial high watermark 2 (kafka.cluster.Partition)
kafka           | [2023-04-08 08:39:49,594] INFO [Broker id=1] Leader __consumer_offsets-4 with topic id Some(NTv8TGJ-RQKKiWlwoEXCQw) starts at leader epoch 0 from offset 2 with partition epoch 0, high watermark 2, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
kafka           | [2023-04-08 08:39:49,601] INFO [Partition __consumer_offsets-23 broker=1] Log loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Partition)
kafka           | [2023-04-08 08:39:49,602] INFO [Broker id=1] Leader __consumer_offsets-23 with topic id Some(NTv8TGJ-RQKKiWlwoEXCQw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
kafka           | [2023-04-08 08:39:49,606] INFO [Partition __consumer_offsets-1 broker=1] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
kafka           | [2023-04-08 08:39:49,607] INFO [Broker id=1] Leader __consumer_offsets-1 with topic id Some(NTv8TGJ-RQKKiWlwoEXCQw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
kafka           | [2023-04-08 08:39:49,611] INFO [Partition __consumer_offsets-20 broker=1] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
kafka           | [2023-04-08 08:39:49,611] INFO [Broker id=1] Leader __consumer_offsets-20 with topic id Some(NTv8TGJ-RQKKiWlwoEXCQw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
kafka           | [2023-04-08 08:39:49,617] INFO [Partition __consumer_offsets-39 broker=1] Log loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Partition)
kafka           | [2023-04-08 08:39:49,617] INFO [Broker id=1] Leader __consumer_offsets-39 with topic id Some(NTv8TGJ-RQKKiWlwoEXCQw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
kafka           | [2023-04-08 08:39:49,633] INFO [Partition __consumer_offsets-17 broker=1] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
kafka           | [2023-04-08 08:39:49,634] INFO [Broker id=1] Leader __consumer_offsets-17 with topic id Some(NTv8TGJ-RQKKiWlwoEXCQw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
kafka           | [2023-04-08 08:39:49,640] INFO [Partition __consumer_offsets-36 broker=1] Log loaded for partition __consumer_offsets-36 with initial high watermark 3 (kafka.cluster.Partition)
kafka           | [2023-04-08 08:39:49,640] INFO [Broker id=1] Leader __consumer_offsets-36 with topic id Some(NTv8TGJ-RQKKiWlwoEXCQw) starts at leader epoch 0 from offset 3 with partition epoch 0, high watermark 3, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
kafka           | [2023-04-08 08:39:49,641] INFO [Partition __consumer_offsets-14 broker=1] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
kafka           | [2023-04-08 08:39:49,642] INFO [Broker id=1] Leader __consumer_offsets-14 with topic id Some(NTv8TGJ-RQKKiWlwoEXCQw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
kafka           | [2023-04-08 08:39:49,645] INFO [Partition __consumer_offsets-33 broker=1] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
kafka           | [2023-04-08 08:39:49,645] INFO [Broker id=1] Leader __consumer_offsets-33 with topic id Some(NTv8TGJ-RQKKiWlwoEXCQw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
kafka           | [2023-04-08 08:39:49,648] INFO [Partition __consumer_offsets-49 broker=1] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
kafka           | [2023-04-08 08:39:49,649] INFO [Broker id=1] Leader __consumer_offsets-49 with topic id Some(NTv8TGJ-RQKKiWlwoEXCQw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
kafka           | [2023-04-08 08:39:49,652] INFO [Partition __consumer_offsets-11 broker=1] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
kafka           | [2023-04-08 08:39:49,652] INFO [Broker id=1] Leader __consumer_offsets-11 with topic id Some(NTv8TGJ-RQKKiWlwoEXCQw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
kafka           | [2023-04-08 08:39:49,657] INFO [Partition __consumer_offsets-30 broker=1] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
kafka           | [2023-04-08 08:39:49,657] INFO [Broker id=1] Leader __consumer_offsets-30 with topic id Some(NTv8TGJ-RQKKiWlwoEXCQw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
kafka           | [2023-04-08 08:39:49,660] INFO [Partition __consumer_offsets-46 broker=1] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
kafka           | [2023-04-08 08:39:49,660] INFO [Broker id=1] Leader __consumer_offsets-46 with topic id Some(NTv8TGJ-RQKKiWlwoEXCQw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
kafka           | [2023-04-08 08:39:49,663] INFO [Partition __consumer_offsets-27 broker=1] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
kafka           | [2023-04-08 08:39:49,663] INFO [Broker id=1] Leader __consumer_offsets-27 with topic id Some(NTv8TGJ-RQKKiWlwoEXCQw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
kafka           | [2023-04-08 08:39:49,666] INFO [Partition __consumer_offsets-8 broker=1] Log loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Partition)
kafka           | [2023-04-08 08:39:49,666] INFO [Broker id=1] Leader __consumer_offsets-8 with topic id Some(NTv8TGJ-RQKKiWlwoEXCQw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
kafka           | [2023-04-08 08:39:49,668] INFO [Partition __consumer_offsets-24 broker=1] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
kafka           | [2023-04-08 08:39:49,669] INFO [Broker id=1] Leader __consumer_offsets-24 with topic id Some(NTv8TGJ-RQKKiWlwoEXCQw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
kafka           | [2023-04-08 08:39:49,673] INFO [Partition __consumer_offsets-43 broker=1] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
kafka           | [2023-04-08 08:39:49,673] INFO [Broker id=1] Leader __consumer_offsets-43 with topic id Some(NTv8TGJ-RQKKiWlwoEXCQw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
kafka           | [2023-04-08 08:39:49,676] INFO [Partition __consumer_offsets-5 broker=1] Log loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Partition)
kafka           | [2023-04-08 08:39:49,676] INFO [Broker id=1] Leader __consumer_offsets-5 with topic id Some(NTv8TGJ-RQKKiWlwoEXCQw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
kafka           | [2023-04-08 08:39:49,680] INFO [Partition __consumer_offsets-21 broker=1] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
kafka           | [2023-04-08 08:39:49,681] INFO [Broker id=1] Leader __consumer_offsets-21 with topic id Some(NTv8TGJ-RQKKiWlwoEXCQw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
kafka           | [2023-04-08 08:39:49,684] INFO [Partition __consumer_offsets-40 broker=1] Log loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Partition)
kafka           | [2023-04-08 08:39:49,684] INFO [Broker id=1] Leader __consumer_offsets-40 with topic id Some(NTv8TGJ-RQKKiWlwoEXCQw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
kafka           | [2023-04-08 08:39:49,686] INFO [Partition __consumer_offsets-2 broker=1] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
kafka           | [2023-04-08 08:39:49,687] INFO [Broker id=1] Leader __consumer_offsets-2 with topic id Some(NTv8TGJ-RQKKiWlwoEXCQw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
kafka           | [2023-04-08 08:39:49,689] INFO [Partition __consumer_offsets-37 broker=1] Log loaded for partition __consumer_offsets-37 with initial high watermark 3 (kafka.cluster.Partition)
kafka           | [2023-04-08 08:39:49,689] INFO [Broker id=1] Leader __consumer_offsets-37 with topic id Some(NTv8TGJ-RQKKiWlwoEXCQw) starts at leader epoch 0 from offset 3 with partition epoch 0, high watermark 3, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
kafka           | [2023-04-08 08:39:49,690] INFO [Partition __consumer_offsets-18 broker=1] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
kafka           | [2023-04-08 08:39:49,690] INFO [Broker id=1] Leader __consumer_offsets-18 with topic id Some(NTv8TGJ-RQKKiWlwoEXCQw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
kafka           | [2023-04-08 08:39:49,693] INFO [Partition __consumer_offsets-34 broker=1] Log loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Partition)
kafka           | [2023-04-08 08:39:49,693] INFO [Broker id=1] Leader __consumer_offsets-34 with topic id Some(NTv8TGJ-RQKKiWlwoEXCQw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
kafka           | [2023-04-08 08:39:49,696] INFO [Partition __consumer_offsets-15 broker=1] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
kafka           | [2023-04-08 08:39:49,696] INFO [Broker id=1] Leader __consumer_offsets-15 with topic id Some(NTv8TGJ-RQKKiWlwoEXCQw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
kafka           | [2023-04-08 08:39:49,701] INFO [Partition __consumer_offsets-12 broker=1] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
kafka           | [2023-04-08 08:39:49,702] INFO [Broker id=1] Leader __consumer_offsets-12 with topic id Some(NTv8TGJ-RQKKiWlwoEXCQw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
kafka           | [2023-04-08 08:39:49,705] INFO [Partition __consumer_offsets-31 broker=1] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
kafka           | [2023-04-08 08:39:49,705] INFO [Broker id=1] Leader __consumer_offsets-31 with topic id Some(NTv8TGJ-RQKKiWlwoEXCQw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
kafka           | [2023-04-08 08:39:49,709] INFO [Partition frames-0 broker=1] Log loaded for partition frames-0 with initial high watermark 0 (kafka.cluster.Partition)
kafka           | [2023-04-08 08:39:49,709] INFO [Broker id=1] Leader frames-0 with topic id Some(AbARUGuiRlC57s0b2k3Ivg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
kafka           | [2023-04-08 08:39:49,711] INFO [Partition __consumer_offsets-9 broker=1] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
kafka           | [2023-04-08 08:39:49,712] INFO [Broker id=1] Leader __consumer_offsets-9 with topic id Some(NTv8TGJ-RQKKiWlwoEXCQw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
kafka           | [2023-04-08 08:39:49,714] INFO [Partition __consumer_offsets-47 broker=1] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
kafka           | [2023-04-08 08:39:49,714] INFO [Broker id=1] Leader __consumer_offsets-47 with topic id Some(NTv8TGJ-RQKKiWlwoEXCQw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
kafka           | [2023-04-08 08:39:49,716] INFO [Partition __consumer_offsets-19 broker=1] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
kafka           | [2023-04-08 08:39:49,717] INFO [Broker id=1] Leader __consumer_offsets-19 with topic id Some(NTv8TGJ-RQKKiWlwoEXCQw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
kafka           | [2023-04-08 08:39:49,719] INFO [Partition __consumer_offsets-28 broker=1] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
kafka           | [2023-04-08 08:39:49,719] INFO [Broker id=1] Leader __consumer_offsets-28 with topic id Some(NTv8TGJ-RQKKiWlwoEXCQw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
kafka           | [2023-04-08 08:39:49,721] INFO [Partition __consumer_offsets-38 broker=1] Log loaded for partition __consumer_offsets-38 with initial high watermark 3 (kafka.cluster.Partition)
kafka           | [2023-04-08 08:39:49,721] INFO [Broker id=1] Leader __consumer_offsets-38 with topic id Some(NTv8TGJ-RQKKiWlwoEXCQw) starts at leader epoch 0 from offset 3 with partition epoch 0, high watermark 3, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
kafka           | [2023-04-08 08:39:49,722] INFO [Partition __consumer_offsets-35 broker=1] Log loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Partition)
kafka           | [2023-04-08 08:39:49,722] INFO [Broker id=1] Leader __consumer_offsets-35 with topic id Some(NTv8TGJ-RQKKiWlwoEXCQw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
kafka           | [2023-04-08 08:39:49,724] INFO [Partition __consumer_offsets-6 broker=1] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
kafka           | [2023-04-08 08:39:49,725] INFO [Broker id=1] Leader __consumer_offsets-6 with topic id Some(NTv8TGJ-RQKKiWlwoEXCQw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
kafka           | [2023-04-08 08:39:49,727] INFO [Partition __consumer_offsets-44 broker=1] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)
kafka           | [2023-04-08 08:39:49,727] INFO [Broker id=1] Leader __consumer_offsets-44 with topic id Some(NTv8TGJ-RQKKiWlwoEXCQw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
kafka           | [2023-04-08 08:39:49,731] INFO [Partition __consumer_offsets-25 broker=1] Log loaded for partition __consumer_offsets-25 with initial high watermark 2 (kafka.cluster.Partition)
kafka           | [2023-04-08 08:39:49,731] INFO [Broker id=1] Leader __consumer_offsets-25 with topic id Some(NTv8TGJ-RQKKiWlwoEXCQw) starts at leader epoch 0 from offset 2 with partition epoch 0, high watermark 2, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
kafka           | [2023-04-08 08:39:49,731] INFO [Partition __consumer_offsets-16 broker=1] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
kafka           | [2023-04-08 08:39:49,732] INFO [Broker id=1] Leader __consumer_offsets-16 with topic id Some(NTv8TGJ-RQKKiWlwoEXCQw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
kafka           | [2023-04-08 08:39:49,734] INFO [Partition __consumer_offsets-22 broker=1] Log loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Partition)
kafka           | [2023-04-08 08:39:49,734] INFO [Broker id=1] Leader __consumer_offsets-22 with topic id Some(NTv8TGJ-RQKKiWlwoEXCQw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
kafka           | [2023-04-08 08:39:49,736] INFO [Partition __consumer_offsets-41 broker=1] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)
kafka           | [2023-04-08 08:39:49,736] INFO [Broker id=1] Leader __consumer_offsets-41 with topic id Some(NTv8TGJ-RQKKiWlwoEXCQw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
kafka           | [2023-04-08 08:39:49,738] INFO [Partition __consumer_offsets-32 broker=1] Log loaded for partition __consumer_offsets-32 with initial high watermark 3 (kafka.cluster.Partition)
kafka           | [2023-04-08 08:39:49,739] INFO [Broker id=1] Leader __consumer_offsets-32 with topic id Some(NTv8TGJ-RQKKiWlwoEXCQw) starts at leader epoch 0 from offset 3 with partition epoch 0, high watermark 3, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
kafka           | [2023-04-08 08:39:49,739] INFO [Partition __consumer_offsets-3 broker=1] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
kafka           | [2023-04-08 08:39:49,739] INFO [Broker id=1] Leader __consumer_offsets-3 with topic id Some(NTv8TGJ-RQKKiWlwoEXCQw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
kafka           | [2023-04-08 08:39:49,741] INFO [Partition videos-0 broker=1] Log loaded for partition videos-0 with initial high watermark 1 (kafka.cluster.Partition)
kafka           | [2023-04-08 08:39:49,742] INFO [Broker id=1] Leader videos-0 with topic id Some(UU2dlzBHSDakK2HrjOsVgA) starts at leader epoch 0 from offset 1 with partition epoch 0, high watermark 1, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
kafka           | [2023-04-08 08:39:49,742] INFO [Partition __consumer_offsets-13 broker=1] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
kafka           | [2023-04-08 08:39:49,742] INFO [Broker id=1] Leader __consumer_offsets-13 with topic id Some(NTv8TGJ-RQKKiWlwoEXCQw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
kafka           | [2023-04-08 08:39:50,159] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 22 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
kafka           | [2023-04-08 08:39:50,200] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-22 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2023-04-08 08:39:50,239] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 25 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
kafka           | [2023-04-08 08:39:50,239] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-25 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2023-04-08 08:39:50,239] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 28 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
kafka           | [2023-04-08 08:39:50,239] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-28 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2023-04-08 08:39:50,239] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 31 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
kafka           | [2023-04-08 08:39:50,239] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-31 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2023-04-08 08:39:50,239] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 34 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
kafka           | [2023-04-08 08:39:50,239] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-34 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2023-04-08 08:39:50,240] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 37 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
kafka           | [2023-04-08 08:39:50,240] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-37 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2023-04-08 08:39:50,240] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 40 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
kafka           | [2023-04-08 08:39:50,240] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-40 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2023-04-08 08:39:50,240] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 43 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
kafka           | [2023-04-08 08:39:50,240] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-43 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2023-04-08 08:39:50,241] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 46 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
kafka           | [2023-04-08 08:39:50,241] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-46 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2023-04-08 08:39:50,241] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 49 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
kafka           | [2023-04-08 08:39:50,241] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-49 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2023-04-08 08:39:50,241] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 41 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
kafka           | [2023-04-08 08:39:50,241] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-41 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2023-04-08 08:39:50,241] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 44 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
kafka           | [2023-04-08 08:39:50,241] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-44 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2023-04-08 08:39:50,241] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 47 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
kafka           | [2023-04-08 08:39:50,242] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-47 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2023-04-08 08:39:50,242] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 1 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
kafka           | [2023-04-08 08:39:50,242] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-1 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2023-04-08 08:39:50,242] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 4 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
kafka           | [2023-04-08 08:39:50,242] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-4 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2023-04-08 08:39:50,242] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 7 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
kafka           | [2023-04-08 08:39:50,242] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-7 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2023-04-08 08:39:50,242] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 10 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
kafka           | [2023-04-08 08:39:50,242] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-10 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2023-04-08 08:39:50,245] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 13 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
kafka           | [2023-04-08 08:39:50,245] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-13 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2023-04-08 08:39:50,246] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 16 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
kafka           | [2023-04-08 08:39:50,246] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-16 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2023-04-08 08:39:50,246] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 19 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
kafka           | [2023-04-08 08:39:50,246] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-19 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2023-04-08 08:39:50,247] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 2 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
kafka           | [2023-04-08 08:39:50,247] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-2 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2023-04-08 08:39:50,247] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 5 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
kafka           | [2023-04-08 08:39:50,247] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-5 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2023-04-08 08:39:50,247] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 8 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
kafka           | [2023-04-08 08:39:50,247] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-8 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2023-04-08 08:39:50,247] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 11 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
kafka           | [2023-04-08 08:39:50,247] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-11 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2023-04-08 08:39:50,247] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 14 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
kafka           | [2023-04-08 08:39:50,247] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-14 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2023-04-08 08:39:50,247] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 17 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
kafka           | [2023-04-08 08:39:50,248] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-17 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2023-04-08 08:39:50,248] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 20 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
kafka           | [2023-04-08 08:39:50,248] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-20 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2023-04-08 08:39:50,248] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 23 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
kafka           | [2023-04-08 08:39:50,248] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-23 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2023-04-08 08:39:50,248] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 26 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
kafka           | [2023-04-08 08:39:50,248] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-26 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2023-04-08 08:39:50,248] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 29 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
kafka           | [2023-04-08 08:39:50,248] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-29 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2023-04-08 08:39:50,248] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 32 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
kafka           | [2023-04-08 08:39:50,248] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-32 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2023-04-08 08:39:50,248] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 35 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
kafka           | [2023-04-08 08:39:50,248] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-35 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2023-04-08 08:39:50,248] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 38 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
kafka           | [2023-04-08 08:39:50,248] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-38 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2023-04-08 08:39:50,249] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 0 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
kafka           | [2023-04-08 08:39:50,249] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-0 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2023-04-08 08:39:50,249] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 3 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
kafka           | [2023-04-08 08:39:50,249] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-3 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2023-04-08 08:39:50,249] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 6 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
kafka           | [2023-04-08 08:39:50,249] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-6 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2023-04-08 08:39:50,249] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 9 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
kafka           | [2023-04-08 08:39:50,249] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-9 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2023-04-08 08:39:50,249] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 12 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
kafka           | [2023-04-08 08:39:50,249] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-12 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2023-04-08 08:39:50,249] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 15 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
kafka           | [2023-04-08 08:39:50,249] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-15 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2023-04-08 08:39:50,249] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 18 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
kafka           | [2023-04-08 08:39:50,250] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-18 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2023-04-08 08:39:50,250] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 21 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
kafka           | [2023-04-08 08:39:50,250] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-21 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2023-04-08 08:39:50,250] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 24 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
kafka           | [2023-04-08 08:39:50,250] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-24 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2023-04-08 08:39:50,250] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 27 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
kafka           | [2023-04-08 08:39:50,250] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-27 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2023-04-08 08:39:50,250] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 30 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
kafka           | [2023-04-08 08:39:50,250] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-30 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2023-04-08 08:39:50,250] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 33 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
kafka           | [2023-04-08 08:39:50,250] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-33 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2023-04-08 08:39:50,250] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 36 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
kafka           | [2023-04-08 08:39:50,250] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-36 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2023-04-08 08:39:50,250] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 39 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
kafka           | [2023-04-08 08:39:50,250] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-39 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2023-04-08 08:39:50,250] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 42 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
kafka           | [2023-04-08 08:39:50,250] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-42 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2023-04-08 08:39:50,251] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 45 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
kafka           | [2023-04-08 08:39:50,251] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-45 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2023-04-08 08:39:50,251] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 48 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
kafka           | [2023-04-08 08:39:50,251] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-48 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2023-04-08 08:39:50,294] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-22 in 81 milliseconds for epoch 0, of which 51 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2023-04-08 08:39:50,304] INFO [Broker id=1] Finished LeaderAndIsr request in 1035ms correlationId 1 from controller 1 for 52 partitions (state.change.logger)
kafka           | [2023-04-08 08:39:50,570] INFO Loaded member MemberMetadata(memberId=consumer-spark-kafka-source-f1c793d8-c618-47dc-a560-6138e2150b84-312546688-driver-0-1-70bb741f-c94b-4e63-b962-119895ac62b0, groupInstanceId=None, clientId=consumer-spark-kafka-source-f1c793d8-c618-47dc-a560-6138e2150b84-312546688-driver-0-1, clientHost=/172.20.0.8, sessionTimeoutMs=10000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group spark-kafka-source-f1c793d8-c618-47dc-a560-6138e2150b84-312546688-driver-0 with generation 1. (kafka.coordinator.group.GroupMetadata$)
kafka           | [2023-04-08 08:39:50,602] INFO [Broker id=1] Add 52 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 1 epoch 10 with correlation id 2 (state.change.logger)
kafka           | [2023-04-08 08:39:50,630] INFO [GroupCoordinator 1]: Loading group metadata for spark-kafka-source-f1c793d8-c618-47dc-a560-6138e2150b84-312546688-driver-0 with generation 2 (kafka.coordinator.group.GroupCoordinator)
kafka           | [2023-04-08 08:39:50,638] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-25 in 395 milliseconds for epoch 0, of which 66 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2023-04-08 08:39:50,640] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-28 in 401 milliseconds for epoch 0, of which 400 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2023-04-08 08:39:50,641] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-31 in 402 milliseconds for epoch 0, of which 401 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2023-04-08 08:39:50,642] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-34 in 402 milliseconds for epoch 0, of which 401 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2023-04-08 08:39:50,659] INFO Loaded member MemberMetadata(memberId=consumer-spark-kafka-source-625fd33b-0976-4446-b755-7a7404128a49-1876532485-driver-0-1-058c7664-3bfe-43c9-b93f-c4270e5b93be, groupInstanceId=None, clientId=consumer-spark-kafka-source-625fd33b-0976-4446-b755-7a7404128a49-1876532485-driver-0-1, clientHost=/172.20.0.5, sessionTimeoutMs=10000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group spark-kafka-source-625fd33b-0976-4446-b755-7a7404128a49-1876532485-driver-0 with generation 1. (kafka.coordinator.group.GroupMetadata$)
kafka           | [2023-04-08 08:39:50,673] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-37 in 431 milliseconds for epoch 0, of which 402 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2023-04-08 08:39:50,675] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-40 in 435 milliseconds for epoch 0, of which 434 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2023-04-08 08:39:50,678] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-43 in 438 milliseconds for epoch 0, of which 436 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2023-04-08 08:39:50,679] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-46 in 438 milliseconds for epoch 0, of which 437 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2023-04-08 08:39:50,679] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-49 in 438 milliseconds for epoch 0, of which 438 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2023-04-08 08:39:50,680] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-41 in 439 milliseconds for epoch 0, of which 438 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2023-04-08 08:39:50,681] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-44 in 440 milliseconds for epoch 0, of which 439 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2023-04-08 08:39:50,682] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-47 in 439 milliseconds for epoch 0, of which 439 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2023-04-08 08:39:50,682] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-1 in 440 milliseconds for epoch 0, of which 440 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2023-04-08 08:39:50,694] INFO Loaded member MemberMetadata(memberId=consumer-spark-kafka-source-ca8f0046-178f-49d7-8f97-577d75511aae-2032089917-driver-0-1-21c0c8dc-ee98-4843-86d4-03622a553df5, groupInstanceId=None, clientId=consumer-spark-kafka-source-ca8f0046-178f-49d7-8f97-577d75511aae-2032089917-driver-0-1, clientHost=/172.20.0.8, sessionTimeoutMs=10000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group spark-kafka-source-ca8f0046-178f-49d7-8f97-577d75511aae-2032089917-driver-0 with generation 1. (kafka.coordinator.group.GroupMetadata$)
kafka           | [2023-04-08 08:39:50,701] INFO [GroupCoordinator 1]: Loading group metadata for spark-kafka-source-ca8f0046-178f-49d7-8f97-577d75511aae-2032089917-driver-0 with generation 2 (kafka.coordinator.group.GroupCoordinator)
kafka           | [2023-04-08 08:39:50,702] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-4 in 460 milliseconds for epoch 0, of which 441 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2023-04-08 08:39:50,703] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-7 in 461 milliseconds for epoch 0, of which 461 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2023-04-08 08:39:50,704] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-10 in 462 milliseconds for epoch 0, of which 462 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2023-04-08 08:39:50,705] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-13 in 459 milliseconds for epoch 0, of which 459 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2023-04-08 08:39:50,705] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-16 in 459 milliseconds for epoch 0, of which 459 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2023-04-08 08:39:50,705] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-19 in 459 milliseconds for epoch 0, of which 459 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2023-04-08 08:39:50,706] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-2 in 459 milliseconds for epoch 0, of which 459 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2023-04-08 08:39:50,707] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-5 in 459 milliseconds for epoch 0, of which 459 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2023-04-08 08:39:50,707] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-8 in 460 milliseconds for epoch 0, of which 460 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2023-04-08 08:39:50,708] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-11 in 461 milliseconds for epoch 0, of which 461 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2023-04-08 08:39:50,709] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-14 in 462 milliseconds for epoch 0, of which 461 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2023-04-08 08:39:50,709] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-17 in 461 milliseconds for epoch 0, of which 461 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2023-04-08 08:39:50,710] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-20 in 462 milliseconds for epoch 0, of which 461 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2023-04-08 08:39:50,711] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-23 in 463 milliseconds for epoch 0, of which 462 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2023-04-08 08:39:50,714] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-26 in 466 milliseconds for epoch 0, of which 464 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2023-04-08 08:39:50,715] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-29 in 467 milliseconds for epoch 0, of which 466 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2023-04-08 08:39:50,729] INFO Loaded member MemberMetadata(memberId=consumer-spark-kafka-source-c9199515-7ca1-4db7-9760-0e59e1265922-18944558-driver-0-1-b069391d-f1eb-43ab-83b1-6ae92dbaeda1, groupInstanceId=None, clientId=consumer-spark-kafka-source-c9199515-7ca1-4db7-9760-0e59e1265922-18944558-driver-0-1, clientHost=/172.20.0.4, sessionTimeoutMs=10000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group spark-kafka-source-c9199515-7ca1-4db7-9760-0e59e1265922-18944558-driver-0 with generation 1. (kafka.coordinator.group.GroupMetadata$)
kafka           | [2023-04-08 08:39:50,731] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-32 in 483 milliseconds for epoch 0, of which 467 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2023-04-08 08:39:50,731] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-35 in 483 milliseconds for epoch 0, of which 483 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2023-04-08 08:39:50,744] INFO Loaded member MemberMetadata(memberId=consumer-spark-kafka-source-c017b955-a914-49cd-99bd-b1819b2e0b10-775729445-driver-0-1-aae510ee-c71d-4183-b63d-bdfede8ddcc1, groupInstanceId=None, clientId=consumer-spark-kafka-source-c017b955-a914-49cd-99bd-b1819b2e0b10-775729445-driver-0-1, clientHost=/172.20.0.8, sessionTimeoutMs=10000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group spark-kafka-source-c017b955-a914-49cd-99bd-b1819b2e0b10-775729445-driver-0 with generation 1. (kafka.coordinator.group.GroupMetadata$)
kafka           | [2023-04-08 08:39:50,745] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-38 in 497 milliseconds for epoch 0, of which 484 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2023-04-08 08:39:50,746] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-0 in 497 milliseconds for epoch 0, of which 497 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2023-04-08 08:39:50,746] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-3 in 497 milliseconds for epoch 0, of which 497 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2023-04-08 08:39:50,747] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-6 in 498 milliseconds for epoch 0, of which 498 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2023-04-08 08:39:50,747] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-9 in 498 milliseconds for epoch 0, of which 498 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2023-04-08 08:39:50,748] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-12 in 499 milliseconds for epoch 0, of which 499 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2023-04-08 08:39:50,748] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-15 in 499 milliseconds for epoch 0, of which 499 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2023-04-08 08:39:50,749] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-18 in 499 milliseconds for epoch 0, of which 498 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2023-04-08 08:39:50,750] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-21 in 500 milliseconds for epoch 0, of which 499 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2023-04-08 08:39:50,750] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-24 in 500 milliseconds for epoch 0, of which 500 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2023-04-08 08:39:50,751] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-27 in 501 milliseconds for epoch 0, of which 501 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2023-04-08 08:39:50,751] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-30 in 501 milliseconds for epoch 0, of which 501 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2023-04-08 08:39:50,752] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-33 in 502 milliseconds for epoch 0, of which 501 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2023-04-08 08:39:50,767] INFO Loaded member MemberMetadata(memberId=consumer-spark-kafka-source-65377cb3-8264-494d-bbfa-84065412a92f--863544072-driver-0-1-1b363cc3-d581-40e1-9b2b-891f62822774, groupInstanceId=None, clientId=consumer-spark-kafka-source-65377cb3-8264-494d-bbfa-84065412a92f--863544072-driver-0-1, clientHost=/172.20.0.5, sessionTimeoutMs=10000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group spark-kafka-source-65377cb3-8264-494d-bbfa-84065412a92f--863544072-driver-0 with generation 1. (kafka.coordinator.group.GroupMetadata$)
kafka           | [2023-04-08 08:39:50,770] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-36 in 520 milliseconds for epoch 0, of which 502 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2023-04-08 08:39:50,771] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-39 in 520 milliseconds for epoch 0, of which 520 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2023-04-08 08:39:50,771] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-42 in 520 milliseconds for epoch 0, of which 520 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2023-04-08 08:39:50,772] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-45 in 521 milliseconds for epoch 0, of which 520 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2023-04-08 08:39:50,772] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-48 in 521 milliseconds for epoch 0, of which 521 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2023-04-08 08:39:54,119] INFO [Controller id=1] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
kafka           | [2023-04-08 08:39:54,122] TRACE [Controller id=1] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
kafka           | [2023-04-08 08:39:54,169] DEBUG [Controller id=1] Topics not in preferred replica for broker 1 Map() (kafka.controller.KafkaController)
kafka           | [2023-04-08 08:39:54,177] TRACE [Controller id=1] Leader imbalance ratio for broker 1 is 0.0 (kafka.controller.KafkaController)
kafka           | [2023-04-08 08:40:14,776] INFO [LocalLog partition=videos-0, dir=/bitnami/kafka/data] Rolled new log segment at offset 1 in 25 ms. (kafka.log.LocalLog)
kafka           | [2023-04-08 08:40:14,787] INFO [UnifiedLog partition=videos-0, dir=/bitnami/kafka/data] Deleting segment LogSegment(baseOffset=0, size=334, lastModifiedTime=1679401643713, largestRecordTimestamp=Some(1679401643488)) due to retention time 604800000ms breach based on the largest record timestamp in the segment (kafka.log.UnifiedLog)
kafka           | [2023-04-08 08:40:14,810] INFO [UnifiedLog partition=videos-0, dir=/bitnami/kafka/data] Incremented log start offset to 1 due to segment deletion (kafka.log.UnifiedLog)
kafka           | [2023-04-08 08:41:14,798] INFO [LocalLog partition=videos-0, dir=/bitnami/kafka/data] Deleting segment files LogSegment(baseOffset=0, size=334, lastModifiedTime=1679401643713, largestRecordTimestamp=Some(1679401643488)) (kafka.log.LocalLog$)
kafka           | [2023-04-08 08:41:14,819] INFO Deleted log /bitnami/kafka/data/videos-0/00000000000000000000.log.deleted. (kafka.log.LogSegment)
kafka           | [2023-04-08 08:41:14,908] INFO Deleted offset index /bitnami/kafka/data/videos-0/00000000000000000000.index.deleted. (kafka.log.LogSegment)
kafka           | [2023-04-08 08:41:14,910] INFO Deleted time index /bitnami/kafka/data/videos-0/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
api             | /usr/local/lib/python3.11/site-packages/cassandra/cqlengine/management.py:545: UserWarning: CQLENG_ALLOW_SCHEMA_MANAGEMENT environment variable is not set. Future versions of this package will require this variable to enable management functions.
api             |   warnings.warn(msg)
api             |  * Serving Flask app 'api'
api             |  * Debug mode: off
api             | [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
api             |  * Running on all addresses (0.0.0.0)
api             |  * Running on http://127.0.0.1:8000
api             |  * Running on http://172.20.0.11:8000
api             | [33mPress CTRL+C to quit[0m
spark           | 23/04/08 08:42:17 INFO Master: Registering app frames-storage
spark           | 23/04/08 08:42:17 INFO Master: Registered app frames-storage with ID app-20230408084217-0000
spark           | 23/04/08 08:42:18 INFO Master: Launching executor app-20230408084217-0000/0 on worker worker-20230408083931-172.20.0.6-44083
spark-worker-1  | 23/04/08 08:42:18 INFO Worker: Asked to launch executor app-20230408084217-0000/0 for frames-storage
spark-worker-1  | 23/04/08 08:42:19 INFO SecurityManager: Changing view acls to: spark
spark-worker-1  | 23/04/08 08:42:19 INFO SecurityManager: Changing modify acls to: spark
spark-worker-1  | 23/04/08 08:42:19 INFO SecurityManager: Changing view acls groups to: 
spark-worker-1  | 23/04/08 08:42:19 INFO SecurityManager: Changing modify acls groups to: 
spark-worker-1  | 23/04/08 08:42:19 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(spark); groups with view permissions: Set(); users  with modify permissions: Set(spark); groups with modify permissions: Set()
spark-worker-1  | 23/04/08 08:42:19 INFO ExecutorRunner: Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=32891" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@406ecabee5d0:32891" "--executor-id" "0" "--hostname" "172.20.0.6" "--cores" "1" "--app-id" "app-20230408084217-0000" "--worker-url" "spark://Worker@172.20.0.6:44083"
video-app       | Frontend connected
api             | 172.20.0.1 - - [08/Apr/2023 08:43:55] "OPTIONS /analysis/rtmp-endpoint HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:43:56] "[35m[1mPOST /analysis/rtmp-endpoint HTTP/1.1[0m" 201 -
video-app       | ffmpeg_stdout ffmpeg version 4.3.5-0+deb11u1
video-app       | ffmpeg_stdout  Copyright (c) 2000-2022 the FFmpeg developers
video-app       | ffmpeg_stdout 
video-app       | 
video-app       | ffmpeg_stdout   built with gcc 10 (Debian 10.2.1-6)
video-app       | 
video-app       | ffmpeg_stdout   configuration: --prefix=/usr --extra-version=0+deb11u1 --toolchain=hardened --libdir=/usr/lib/aarch64-linux-gnu --incdir=/usr/include/aarch64-linux-gnu --arch=arm64 --enable-gpl --disable-stripping --enable-avresample --disable-filter=resample --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librsvg --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared
video-app       | 
video-app       | ffmpeg_stdout   libavutil      56. 51.100 / 56. 51.100
video-app       | 
video-app       | ffmpeg_stdout   libavcodec     58. 91.100 / 58. 91.100
video-app       | 
video-app       | ffmpeg_stdout   libavformat    58. 45.100 / 58. 45.100
video-app       | 
video-app       | ffmpeg_stdout   libavdevice    58. 10.100 / 58. 10.100
video-app       | 
video-app       | ffmpeg_stdout   libavfilter     7. 85.100 /  7. 85.100
video-app       | 
video-app       | ffmpeg_stdout   libavresample   4.  0.  0 /  4.  0.  0
video-app       | 
video-app       | ffmpeg_stdout   libswscale      5.  7.100 /  5.  7.100
video-app       | 
video-app       | ffmpeg_stdout   libswresample   3.  7.100 /  3.  7.100
video-app       | 
video-app       | ffmpeg_stdout   libpostproc    55.  7.100 / 55.  7.100
video-app       | 
api             | 172.20.0.1 - - [08/Apr/2023 08:43:57] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:43:58] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
video-app       | ffmpeg_stdout Input #0, matroska,webm, from 'pipe:':
video-app       | 
video-app       | ffmpeg_stdout   Metadata:
video-app       | 
video-app       | ffmpeg_stdout     encoder         : 
video-app       | ffmpeg_stdout Chrome
video-app       |   Duration: N/A, start: 0.000000, bitrate: N/A
video-app       |     Stream #0:0(eng): Video: vp8, yuv420p(tv, bt709/bt709/iec61966-2-1, progressive), 480x480, SAR 1:1 DAR 1:1, 29.97 tbr, 1k tbn, 1k tbc
video-app       | ffmpeg_stdout  (default)
video-app       |     Metadata:
video-app       |       alpha_mode      : 1
video-app       | 
video-app       | ffmpeg_stdout Codec AVOption b (set bitrate (in bits/s)) specified for output file #0 (rtmp://nginx/live/ff010947-011d-4173-b134-05002cde18eb) has not been used for any stream. The most likely reason is either wrong type (e.g. a video option with no video streams) or that it is a private option of some encoder which was not actually used for any stream.
video-app       | 
video-app       | ffmpeg_stdout Stream mapping:
video-app       | 
video-app       | ffmpeg_stdout   Stream #0:0 -> #0:0
video-app       | ffmpeg_stdout  (vp8 (native) -> h264 (libx264))
video-app       | ffmpeg_stdout 
video-app       | 
video-app       | ffmpeg_stdout [libx264 @ 0xaaaadb115c60] 
video-app       | ffmpeg_stdout VBV bufsize set but maxrate unspecified, ignored
video-app       | 
video-app       | ffmpeg_stdout [libx264 @ 0xaaaadb115c60] 
video-app       | ffmpeg_stdout using SAR=1/1
video-app       | 
video-app       | ffmpeg_stdout [libx264 @ 0xaaaadb115c60] 
video-app       | ffmpeg_stdout using cpu capabilities: ARMv8 NEON
video-app       | 
video-app       | ffmpeg_stdout [libx264 @ 0xaaaadb115c60] 
video-app       | ffmpeg_stdout profile Constrained Baseline, level 3.0, 4:2:0, 8-bit
video-app       | 
video-app       | ffmpeg_stdout [libx264 @ 0xaaaadb115c60] 
video-app       | ffmpeg_stdout 264 - core 160 r3011 cde9a93 - H.264/MPEG-4 AVC codec - Copyleft 2003-2020 - http://www.videolan.org/x264.html - options: cabac=0 ref=1 deblock=0:0:0 analyse=0:0 me=dia subme=0 psy=1 psy_rd=1.00:0.00 mixed_ref=0 me_range=16 chroma_me=1 trellis=0 8x8dct=0 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=0 threads=4 lookahead_threads=4 sliced_threads=1 slices=4 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=0 weightp=0 keyint=30 keyint_min=16 scenecut=0 intra_refresh=0 rc=crf mbtree=0 crf=25.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=0
video-app       | 
video-app       | ffmpeg_stdout Output #0, flv, to 'rtmp://nginx/live/ff010947-011d-4173-b134-05002cde18eb':
video-app       | 
video-app       | ffmpeg_stdout   Metadata:
video-app       | 
video-app       | ffmpeg_stdout     encoder         : 
video-app       | ffmpeg_stdout Lavf58.45.100
video-app       | ffmpeg_stdout 
video-app       | 
video-app       | ffmpeg_stdout     Stream #0:0
video-app       | ffmpeg_stdout (eng)
video-app       | ffmpeg_stdout : Video: h264 (libx264) ([7][0][0][0] / 0x0007), yuv420p, 480x480 [SAR 1:1 DAR 1:1], q=-1--1
video-app       | ffmpeg_stdout , 
video-app       | ffmpeg_stdout 15 fps, 
video-app       | ffmpeg_stdout 1k tbn, 
video-app       | ffmpeg_stdout 15 tbc
video-app       | ffmpeg_stdout  (default)
video-app       | ffmpeg_stdout 
video-app       | 
video-app       | ffmpeg_stdout     Metadata:
video-app       | 
video-app       | ffmpeg_stdout       alpha_mode      : 
video-app       | ffmpeg_stdout 1
video-app       | ffmpeg_stdout 
video-app       | 
video-app       | ffmpeg_stdout       encoder         : 
video-app       | ffmpeg_stdout Lavc58.91.100 libx264
video-app       | ffmpeg_stdout 
video-app       | 
video-app       | ffmpeg_stdout     Side data:
video-app       | 
video-app       | ffmpeg_stdout       
video-app       | ffmpeg_stdout cpb: 
video-app       | ffmpeg_stdout bitrate max/min/avg: 0/0/0 buffer size: 5000 
video-app       | ffmpeg_stdout vbv_delay: N/A
video-app       | ffmpeg_stdout 
video-app       | 
api             | 172.20.0.1 - - [08/Apr/2023 08:43:59] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
video-app       | ffmpeg_stdout frame=   42 fps=0.0 q=23.0 size=     308kB time=00:00:02.73 bitrate= 922.2kbits/s dup=0 drop=8 speed=5.46x    
video-app       | ffmpeg_stdout frame=   47 fps= 46 q=23.0 size=     342kB time=00:00:03.06 bitrate= 912.8kbits/s dup=0 drop=10 speed=2.99x    
api             | 172.20.0.1 - - [08/Apr/2023 08:44:00] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
video-app       | ffmpeg_stdout frame=   55 fps= 35 q=22.0 size=     398kB time=00:00:03.60 bitrate= 904.4kbits/s dup=0 drop=11 speed=2.29x    
video-app       | ffmpeg_stdout frame=   63 fps= 30 q=24.0 size=     463kB time=00:00:04.13 bitrate= 917.1kbits/s dup=0 drop=13 speed=1.97x    
api             | 172.20.0.1 - - [08/Apr/2023 08:44:01] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
video-app       | ffmpeg_stdout frame=   71 fps= 27 q=21.0 size=     505kB time=00:00:04.66 bitrate= 886.7kbits/s dup=0 drop=15 speed=1.78x    
video-app       | ffmpeg_stdout frame=   80 fps= 25 q=22.0 size=     558kB time=00:00:05.26 bitrate= 868.2kbits/s dup=0 drop=17 speed=1.65x    
api             | 172.20.0.1 - - [08/Apr/2023 08:44:02] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
video-app       | ffmpeg_stdout frame=   88 fps= 24 q=21.0 size=     616kB time=00:00:05.80 bitrate= 869.3kbits/s dup=0 drop=19 speed=1.55x    
video-app       | ffmpeg_stdout frame=   96 fps= 22 q=20.0 size=     681kB time=00:00:06.33 bitrate= 880.8kbits/s dup=0 drop=21 speed=1.48x    
api             | 172.20.0.1 - - [08/Apr/2023 08:44:03] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
video-app       | ffmpeg_stdout frame=  104 fps= 22 q=20.0 size=     726kB time=00:00:06.86 bitrate= 865.7kbits/s dup=0 drop=23 speed=1.43x    
video-app       | ffmpeg_stdout frame=  112 fps= 21 q=19.0 size=     774kB time=00:00:07.40 bitrate= 857.0kbits/s dup=0 drop=25 speed=1.39x    
api             | 172.20.0.1 - - [08/Apr/2023 08:44:04] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
video-app       | ffmpeg_stdout frame=  120 fps= 20 q=22.0 size=     819kB time=00:00:07.93 bitrate= 845.9kbits/s dup=0 drop=27 speed=1.35x    
video-app       | ffmpeg_stdout frame=  128 fps= 20 q=21.0 size=     892kB time=00:00:08.46 bitrate= 862.6kbits/s dup=0 drop=29 speed=1.32x    
api             | 172.20.0.1 - - [08/Apr/2023 08:44:05] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
video-app       | ffmpeg_stdout frame=  136 fps= 20 q=21.0 size=     940kB time=00:00:09.00 bitrate= 855.2kbits/s dup=0 drop=31 speed=1.29x    
video-app       | ffmpeg_stdout frame=  144 fps= 19 q=20.0 size=     982kB time=00:00:09.53 bitrate= 844.0kbits/s dup=0 drop=33 speed=1.27x    
api             | 172.20.0.1 - - [08/Apr/2023 08:44:06] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
video-app       | ffmpeg_stdout frame=  152 fps= 19 q=25.0 size=    1049kB time=00:00:10.06 bitrate= 853.9kbits/s dup=0 drop=34 speed=1.25x    
api             | 172.20.0.1 - - [08/Apr/2023 08:44:07] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
video-app       | ffmpeg_stdout frame=  160 fps= 19 q=21.0 size=    1088kB time=00:00:10.60 bitrate= 840.9kbits/s dup=0 drop=36 speed=1.24x    
video-app       | ffmpeg_stdout frame=  169 fps= 19 q=20.0 size=    1134kB time=00:00:11.20 bitrate= 829.7kbits/s dup=0 drop=38 speed=1.23x    
api             | 172.20.0.1 - - [08/Apr/2023 08:44:08] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
video-app       | ffmpeg_stdout frame=  177 fps= 18 q=20.0 size=    1172kB time=00:00:11.73 bitrate= 818.0kbits/s dup=0 drop=40 speed=1.21x    
video-app       | ffmpeg_stdout frame=  185 fps= 18 q=22.0 size=    1233kB time=00:00:12.26 bitrate= 823.2kbits/s dup=0 drop=42 speed= 1.2x    
api             | 172.20.0.1 - - [08/Apr/2023 08:44:09] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
video-app       | ffmpeg_stdout frame=  193 fps= 18 q=20.0 size=    1270kB time=00:00:12.80 bitrate= 812.8kbits/s dup=0 drop=44 speed=1.19x    
video-app       | ffmpeg_stdout frame=  201 fps= 18 q=20.0 size=    1315kB time=00:00:13.33 bitrate= 807.6kbits/s dup=0 drop=46 speed=1.18x    
api             | 172.20.0.1 - - [08/Apr/2023 08:44:10] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
video-app       | ffmpeg_stdout frame=  209 fps= 18 q=20.0 size=    1353kB time=00:00:13.86 bitrate= 799.5kbits/s dup=0 drop=48 speed=1.18x    
video-app       | ffmpeg_stdout frame=  217 fps= 18 q=20.0 size=    1416kB time=00:00:14.40 bitrate= 805.4kbits/s dup=0 drop=50 speed=1.16x    
api             | 172.20.0.1 - - [08/Apr/2023 08:44:11] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
video-app       | ffmpeg_stdout frame=  225 fps= 17 q=22.0 size=    1462kB time=00:00:14.93 bitrate= 801.8kbits/s dup=0 drop=52 speed=1.16x    
video-app       | ffmpeg_stdout frame=  233 fps= 17 q=22.0 size=    1510kB time=00:00:15.46 bitrate= 799.8kbits/s dup=0 drop=54 speed=1.15x    
api             | 172.20.0.1 - - [08/Apr/2023 08:44:12] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
video-app       | ffmpeg_stdout frame=  241 fps= 17 q=18.0 size=    1580kB time=00:00:16.00 bitrate= 809.2kbits/s dup=0 drop=55 speed=1.15x    
video-app       | ffmpeg_stdout frame=  249 fps= 17 q=21.0 size=    1625kB time=00:00:16.53 bitrate= 805.4kbits/s dup=0 drop=57 speed=1.14x    
api             | 172.20.0.1 - - [08/Apr/2023 08:44:13] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
video-app       | ffmpeg_stdout frame=  258 fps= 17 q=21.0 size=    1677kB time=00:00:17.13 bitrate= 801.9kbits/s dup=0 drop=59 speed=1.14x    
video-app       | ffmpeg_stdout frame=  266 fps= 17 q=21.0 size=    1729kB time=00:00:17.66 bitrate= 801.6kbits/s dup=0 drop=61 speed=1.13x    
api             | 172.20.0.1 - - [08/Apr/2023 08:44:15] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
video-app       | ffmpeg_stdout frame=  274 fps= 17 q=22.0 size=    1792kB time=00:00:18.20 bitrate= 806.8kbits/s dup=0 drop=63 speed=1.13x    
video-app       | ffmpeg_stdout frame=  282 fps= 17 q=21.0 size=    1833kB time=00:00:18.73 bitrate= 801.5kbits/s dup=0 drop=65 speed=1.12x    
api             | 172.20.0.1 - - [08/Apr/2023 08:44:16] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
video-app       | ffmpeg_stdout frame=  290 fps= 17 q=19.0 size=    1877kB time=00:00:19.26 bitrate= 798.1kbits/s dup=0 drop=67 speed=1.12x    
api             | 172.20.0.1 - - [08/Apr/2023 08:44:16] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
video-app       | ffmpeg_stdout frame=  298 fps= 17 q=21.0 size=    1915kB time=00:00:19.80 bitrate= 792.3kbits/s dup=0 drop=69 speed=1.12x    
video-app       | ffmpeg_stdout frame=  306 fps= 17 q=21.0 size=    1982kB time=00:00:20.33 bitrate= 798.5kbits/s dup=0 drop=71 speed=1.11x    
api             | 172.20.0.1 - - [08/Apr/2023 08:44:17] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
video-app       | ffmpeg_stdout frame=  314 fps= 17 q=21.0 size=    2027kB time=00:00:20.86 bitrate= 795.8kbits/s dup=0 drop=73 speed=1.11x    
video-app       | ffmpeg_stdout frame=  322 fps= 17 q=21.0 size=    2078kB time=00:00:21.40 bitrate= 795.4kbits/s dup=0 drop=75 speed= 1.1x    
api             | 172.20.0.1 - - [08/Apr/2023 08:44:18] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
video-app       | ffmpeg_stdout frame=  330 fps= 17 q=21.0 size=    2124kB time=00:00:21.93 bitrate= 793.2kbits/s dup=0 drop=76 speed= 1.1x    
video-app       | ffmpeg_stdout frame=  338 fps= 17 q=21.0 size=    2182kB time=00:00:22.46 bitrate= 795.6kbits/s dup=0 drop=78 speed= 1.1x    
api             | 172.20.0.1 - - [08/Apr/2023 08:44:19] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
video-app       | ffmpeg_stdout frame=  346 fps= 16 q=21.0 size=    2226kB time=00:00:23.00 bitrate= 793.0kbits/s dup=0 drop=80 speed= 1.1x    
api             | 172.20.0.1 - - [08/Apr/2023 08:44:20] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
video-app       | ffmpeg_stdout frame=  355 fps= 16 q=20.0 size=    2281kB time=00:00:23.60 bitrate= 791.7kbits/s dup=0 drop=82 speed= 1.1x    
video-app       | ffmpeg_stdout frame=  363 fps= 16 q=23.0 size=    2341kB time=00:00:24.13 bitrate= 794.7kbits/s dup=0 drop=84 speed=1.09x    
api             | 172.20.0.1 - - [08/Apr/2023 08:44:21] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
video-app       | ffmpeg_stdout frame=  371 fps= 16 q=23.0 size=    2392kB time=00:00:24.66 bitrate= 794.3kbits/s dup=0 drop=86 speed=1.09x    
video-app       | ffmpeg_stdout frame=  379 fps= 16 q=23.0 size=    2449kB time=00:00:25.20 bitrate= 796.2kbits/s dup=0 drop=88 speed=1.09x    
api             | 172.20.0.1 - - [08/Apr/2023 08:44:22] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
video-app       | ffmpeg_stdout frame=  387 fps= 16 q=24.0 size=    2510kB time=00:00:25.73 bitrate= 798.9kbits/s dup=0 drop=90 speed=1.09x    
video-app       | ffmpeg_stdout frame=  395 fps= 16 q=23.0 size=    2576kB time=00:00:26.26 bitrate= 803.2kbits/s dup=0 drop=92 speed=1.08x    
video-app       | streamming stopped
video-app       | ffmpeg process ended!
video-app       | ffmpeg_stdout [matroska,webm @ 0xaaaadb105610] File ended prematurely at pos. 2643561 (0x285669)
video-app       | 
video-app       | ffmpeg_stdout [flv @ 0xaaaadb108580] Failed to update header with correct duration.
video-app       | [flv @ 0xaaaadb108580] Failed to update header with correct filesize.
video-app       | 
video-app       | ffmpeg_stdout frame=  398 fps= 16 q=21.0 Lsize=    2593kB time=00:00:26.46 bitrate= 802.6kbits/s dup=0 drop=93 speed=1.09x    
video-app       | video:2584kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.356970%
video-app       | 
video-app       | ffmpeg_stdout [libx264 @ 0xaaaadb115c60] frame I:14    Avg QP:18.64  size: 30246
video-app       | [libx264 @ 0xaaaadb115c60] frame P:384   Avg QP:21.51  size:  5786
video-app       | [libx264 @ 0xaaaadb115c60] mb I  I16..4: 100.0%  0.0%  0.0%
video-app       | [libx264 @ 0xaaaadb115c60] mb P  I16..4:  4.7%  0.0%  0.0%  P16..4: 54.2%  0.0%  0.0%  0.0%  0.0%    skip:41.0%
video-app       | [libx264 @ 0xaaaadb115c60] coded y,uvDC,uvAC intra: 29.0% 53.3% 21.0% inter: 26.3% 36.5% 1.6%
video-app       | [libx264 @ 0xaaaadb115c60] i16 v,h,dc,p: 35% 21% 22% 21%
video-app       | [libx264 @ 0xaaaadb115c60] i8c dc,h,v,p: 49% 24% 19%  8%
video-app       | [libx264 @ 0xaaaadb115c60] kb/s:797.57
video-app       | 
video-app       | ffmpeg_stdout Exiting normally, received signal 2.
video-app       | 
nginx           | 172.20.0.12 [08/Apr/2023:08:44:23 +0000] PUBLISH "live" "ff010947-011d-4173-b134-05002cde18eb" "" - 2653503 529 "" "FMLE/3.0 (compatible; Lavf58.45" (24s)
video-app       | ffmpeg exit!255
api             | 172.20.0.1 - - [08/Apr/2023 08:44:23] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:44:24] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:44:25] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:44:26] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:44:27] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:44:28] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:44:29] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:44:30] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:44:31] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:44:32] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:44:33] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:44:34] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:44:35] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:44:36] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:44:37] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:44:38] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:44:39] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:44:41] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:44:42] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:44:43] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:44:44] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:44:45] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:44:46] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:44:47] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:44:48] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:44:49] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:44:50] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:44:51] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:44:52] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:44:53] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
kafka           | [2023-04-08 08:44:54,163] INFO [Controller id=1] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
kafka           | [2023-04-08 08:44:54,166] TRACE [Controller id=1] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
kafka           | [2023-04-08 08:44:54,191] DEBUG [Controller id=1] Topics not in preferred replica for broker 1 Map() (kafka.controller.KafkaController)
kafka           | [2023-04-08 08:44:54,191] TRACE [Controller id=1] Leader imbalance ratio for broker 1 is 0.0 (kafka.controller.KafkaController)
api             | 172.20.0.1 - - [08/Apr/2023 08:44:54] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:44:55] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:44:56] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:44:57] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:44:58] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:44:59] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:45:00] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:45:01] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:45:02] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:45:03] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:45:04] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:45:05] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:45:06] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:45:07] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:45:08] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:45:09] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:45:09] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:45:10] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:45:11] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:45:12] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:45:14] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:45:15] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:45:16] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:45:17] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:45:18] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:45:19] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:45:20] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:45:21] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:45:22] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:45:23] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:45:24] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:45:25] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:45:26] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:45:27] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:45:28] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:45:29] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:45:30] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:45:31] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:45:32] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:45:33] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:45:34] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:45:35] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:45:36] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:45:37] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:45:38] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:45:39] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:45:40] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:45:41] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:45:42] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:45:43] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:45:44] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:45:45] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:45:46] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:45:47] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:45:48] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:45:49] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:45:50] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:45:51] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:45:52] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:45:53] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:45:54] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:45:55] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:45:56] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:45:57] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:45:58] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:45:59] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:46:00] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:46:01] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:46:02] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:46:03] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:46:04] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:46:05] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:46:06] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:46:07] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:46:08] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:46:09] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:46:10] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:46:11] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:46:12] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:46:13] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:46:14] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:46:15] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:46:16] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:46:17] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:46:18] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:46:19] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:46:20] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:46:21] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:46:22] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:46:23] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:46:24] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:46:25] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:46:26] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:46:27] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:46:28] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:46:29] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:46:30] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:46:31] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:46:32] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:46:33] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:46:34] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:46:35] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:46:36] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:46:37] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:46:38] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:46:39] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:46:40] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:46:41] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:46:42] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:46:43] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:46:44] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:46:45] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:46:46] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:46:47] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:46:48] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:46:49] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:46:50] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:46:51] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:46:52] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:46:53] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:46:54] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:46:55] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:46:56] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:46:57] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:46:58] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:46:59] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:47:00] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:47:01] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:47:02] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:47:03] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:47:04] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:47:05] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:47:06] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:47:07] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:47:08] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:47:08] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:47:09] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:47:10] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:47:11] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:47:12] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:47:13] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:47:14] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:47:15] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:47:16] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:47:17] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:47:18] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:47:19] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:47:20] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:47:21] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:47:22] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:47:23] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:47:24] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:47:25] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:47:26] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:47:27] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:47:28] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:47:29] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:47:30] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:47:31] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:47:32] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:47:33] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:47:34] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:47:35] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:47:36] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:47:37] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:47:38] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:47:39] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:47:40] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:47:41] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:47:42] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:47:43] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:47:44] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:47:45] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:47:46] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:47:47] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:47:48] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:47:49] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:47:50] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:47:51] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:47:53] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:47:54] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:47:55] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:47:55] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:47:56] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:47:57] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:47:59] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:47:59] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:48:00] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:48:01] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:48:02] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:48:03] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:48:05] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:48:06] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:48:07] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:48:08] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:48:09] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:48:10] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:48:11] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:48:12] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:48:13] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:48:14] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:48:15] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:48:16] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:48:17] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:48:18] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:48:19] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:48:20] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:48:21] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:48:22] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:48:23] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:48:24] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:48:25] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:48:26] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:48:27] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:48:28] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:48:29] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:48:30] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:48:31] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:48:32] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:48:33] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:48:34] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:48:35] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:48:36] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:48:37] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:48:38] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:48:39] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:48:40] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:48:41] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:48:42] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:48:43] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:48:44] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:48:45] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:48:46] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:48:47] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:48:48] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:48:49] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:48:50] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:48:51] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:48:52] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:48:53] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:48:54] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:48:55] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:48:56] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:48:57] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:48:58] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:48:59] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:49:00] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:49:01] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:49:02] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:49:03] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:49:04] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:49:05] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:49:06] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:49:07] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:49:08] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:49:09] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:49:10] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:49:11] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:49:12] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:49:13] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:49:14] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:49:15] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:49:16] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:49:17] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:49:18] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:49:19] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:49:20] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:49:21] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:49:22] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:49:23] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:49:24] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:49:25] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:49:26] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:49:27] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:49:27] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:49:28] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:49:29] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:49:30] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:49:31] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:49:32] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:49:33] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:49:34] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:49:35] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:49:36] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:49:37] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:49:38] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:49:39] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:49:41] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:49:42] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:49:43] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:49:44] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:49:45] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:49:46] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:49:47] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
kafka           | [2023-04-08 08:49:47,917] INFO [GroupMetadataManager brokerId=1] Group spark-kafka-source-f1c793d8-c618-47dc-a560-6138e2150b84-312546688-driver-0 transitioned to Dead in generation 2 (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2023-04-08 08:49:48,031] INFO [LocalLog partition=__consumer_offsets-25, dir=/bitnami/kafka/data] Rolled new log segment at offset 2 in 25 ms. (kafka.log.LocalLog)
kafka           | [2023-04-08 08:49:48,042] INFO [GroupMetadataManager brokerId=1] Group spark-kafka-source-ca8f0046-178f-49d7-8f97-577d75511aae-2032089917-driver-0 transitioned to Dead in generation 2 (kafka.coordinator.group.GroupMetadataManager)
kafka           | [2023-04-08 08:49:48,049] INFO [LocalLog partition=__consumer_offsets-4, dir=/bitnami/kafka/data] Rolled new log segment at offset 2 in 5 ms. (kafka.log.LocalLog)
api             | 172.20.0.1 - - [08/Apr/2023 08:49:48] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:49:49] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:49:50] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:49:51] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:49:52] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:49:53] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
kafka           | [2023-04-08 08:49:54,177] INFO [Controller id=1] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
kafka           | [2023-04-08 08:49:54,177] TRACE [Controller id=1] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
kafka           | [2023-04-08 08:49:54,193] DEBUG [Controller id=1] Topics not in preferred replica for broker 1 Map() (kafka.controller.KafkaController)
kafka           | [2023-04-08 08:49:54,193] TRACE [Controller id=1] Leader imbalance ratio for broker 1 is 0.0 (kafka.controller.KafkaController)
api             | 172.20.0.1 - - [08/Apr/2023 08:49:54] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:49:55] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:49:56] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:49:57] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:49:58] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:49:59] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:50:00] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
kafka           | [2023-04-08 08:50:00,952] INFO Cleaner 0: Beginning cleaning of log __consumer_offsets-25 (kafka.log.LogCleaner)
kafka           | [2023-04-08 08:50:00,956] INFO Cleaner 0: Building offset map for __consumer_offsets-25... (kafka.log.LogCleaner)
kafka           | [2023-04-08 08:50:01,126] INFO Cleaner 0: Building offset map for log __consumer_offsets-25 for 1 segments in offset range [0, 2). (kafka.log.LogCleaner)
kafka           | [2023-04-08 08:50:01,214] INFO Cleaner 0: Offset map for log __consumer_offsets-25 complete. (kafka.log.LogCleaner)
kafka           | [2023-04-08 08:50:01,218] INFO Cleaner 0: Cleaning log __consumer_offsets-25 (cleaning prior to Tue Mar 21 12:52:41 UTC 2023, discarding tombstones prior to upper bound deletion horizon Thu Jan 01 00:00:00 UTC 1970)... (kafka.log.LogCleaner)
api             | 172.20.0.1 - - [08/Apr/2023 08:50:01] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
kafka           | [2023-04-08 08:50:01,241] INFO Cleaner 0: Cleaning LogSegment(baseOffset=0, size=778, lastModifiedTime=1679403161094, largestRecordTimestamp=Some(1679403161086)) in log __consumer_offsets-25 into 0 with an upper bound deletion horizon 0 computed from the segment last modified time of 1679403161094,retaining deletes. (kafka.log.LogCleaner)
kafka           | [2023-04-08 08:50:01,292] INFO Cleaner 0: Swapping in cleaned segment LogSegment(baseOffset=0, size=180, lastModifiedTime=1679403161094, largestRecordTimestamp=Some(1679403161086)) for segment(s) List(LogSegment(baseOffset=0, size=778, lastModifiedTime=1679403161094, largestRecordTimestamp=Some(1679403161086))) in log Log(dir=/bitnami/kafka/data/__consumer_offsets-25, topicId=NTv8TGJ-RQKKiWlwoEXCQw, topic=__consumer_offsets, partition=25, highWatermark=3, lastStableOffset=3, logStartOffset=0, logEndOffset=3) (kafka.log.LogCleaner)
kafka           | [2023-04-08 08:50:01,331] INFO [kafka-log-cleaner-thread-0]: 
kafka           | 	Log cleaner thread 0 cleaned log __consumer_offsets-25 (dirty section = [0, 2])
kafka           | 	0.0 MB of log processed in 0.4 seconds (0.0 MB/sec).
kafka           | 	Indexed 0.0 MB in 0.3 seconds (0.0 Mb/sec, 72.9% of total time)
kafka           | 	Buffer utilization: 0.0%
kafka           | 	Cleaned 0.0 MB in 0.1 seconds (0.0 Mb/sec, 27.1% of total time)
kafka           | 	Start size: 0.0 MB (2 messages)
kafka           | 	End size: 0.0 MB (1 messages)
kafka           | 	76.9% size reduction (50.0% fewer messages)
kafka           |  (kafka.log.LogCleaner)
kafka           | [2023-04-08 08:50:01,350] INFO Cleaner 0: Beginning cleaning of log __consumer_offsets-4 (kafka.log.LogCleaner)
kafka           | [2023-04-08 08:50:01,350] INFO Cleaner 0: Building offset map for __consumer_offsets-4... (kafka.log.LogCleaner)
kafka           | [2023-04-08 08:50:01,369] INFO Cleaner 0: Building offset map for log __consumer_offsets-4 for 1 segments in offset range [0, 2). (kafka.log.LogCleaner)
kafka           | [2023-04-08 08:50:01,370] INFO Cleaner 0: Offset map for log __consumer_offsets-4 complete. (kafka.log.LogCleaner)
kafka           | [2023-04-08 08:50:01,371] INFO Cleaner 0: Cleaning log __consumer_offsets-4 (cleaning prior to Tue Mar 21 12:49:52 UTC 2023, discarding tombstones prior to upper bound deletion horizon Thu Jan 01 00:00:00 UTC 1970)... (kafka.log.LogCleaner)
kafka           | [2023-04-08 08:50:01,374] INFO Cleaner 0: Cleaning LogSegment(baseOffset=0, size=783, lastModifiedTime=1679402992455, largestRecordTimestamp=Some(1679402992453)) in log __consumer_offsets-4 into 0 with an upper bound deletion horizon 0 computed from the segment last modified time of 1679402992455,retaining deletes. (kafka.log.LogCleaner)
kafka           | [2023-04-08 08:50:01,378] INFO Cleaner 0: Swapping in cleaned segment LogSegment(baseOffset=0, size=181, lastModifiedTime=1679402992455, largestRecordTimestamp=Some(1679402992453)) for segment(s) List(LogSegment(baseOffset=0, size=783, lastModifiedTime=1679402992455, largestRecordTimestamp=Some(1679402992453))) in log Log(dir=/bitnami/kafka/data/__consumer_offsets-4, topicId=NTv8TGJ-RQKKiWlwoEXCQw, topic=__consumer_offsets, partition=4, highWatermark=3, lastStableOffset=3, logStartOffset=0, logEndOffset=3) (kafka.log.LogCleaner)
kafka           | [2023-04-08 08:50:01,384] INFO [kafka-log-cleaner-thread-0]: 
kafka           | 	Log cleaner thread 0 cleaned log __consumer_offsets-4 (dirty section = [0, 2])
kafka           | 	0.0 MB of log processed in 0.0 seconds (0.0 MB/sec).
kafka           | 	Indexed 0.0 MB in 0.0 seconds (0.0 Mb/sec, 64.5% of total time)
kafka           | 	Buffer utilization: 0.0%
kafka           | 	Cleaned 0.0 MB in 0.0 seconds (0.1 Mb/sec, 35.5% of total time)
kafka           | 	Start size: 0.0 MB (2 messages)
kafka           | 	End size: 0.0 MB (1 messages)
kafka           | 	76.9% size reduction (50.0% fewer messages)
kafka           |  (kafka.log.LogCleaner)
api             | 172.20.0.1 - - [08/Apr/2023 08:50:02] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:50:03] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:50:04] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:50:05] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:50:06] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:50:07] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:50:08] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:50:09] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:50:10] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:50:11] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:50:12] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:50:13] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:50:14] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:50:15] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:50:16] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:50:17] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:50:18] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:50:19] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:50:20] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:50:21] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:50:22] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:50:23] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:50:24] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:50:25] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:50:26] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:50:27] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:50:28] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:50:29] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:50:30] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:50:31] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:50:32] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:50:33] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:50:34] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:50:35] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:50:36] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:50:37] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:50:38] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:50:39] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
api             | 172.20.0.1 - - [08/Apr/2023 08:50:40] "GET /analysis/ff010947-011d-4173-b134-05002cde18eb HTTP/1.1" 200 -
video-app       | socket disconnected
kafka           | [2023-04-08 08:51:01,300] INFO [UnifiedLog partition=__consumer_offsets-25, dir=/bitnami/kafka/data] Deleting segment files LogSegment(baseOffset=0, size=778, lastModifiedTime=1679403161094, largestRecordTimestamp=Some(1679403161086)) (kafka.log.LocalLog$)
kafka           | [2023-04-08 08:51:01,304] INFO Deleted log /bitnami/kafka/data/__consumer_offsets-25/00000000000000000000.log.deleted. (kafka.log.LogSegment)
kafka           | [2023-04-08 08:51:01,306] INFO Deleted offset index /bitnami/kafka/data/__consumer_offsets-25/00000000000000000000.index.deleted. (kafka.log.LogSegment)
kafka           | [2023-04-08 08:51:01,306] INFO Deleted time index /bitnami/kafka/data/__consumer_offsets-25/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
kafka           | [2023-04-08 08:51:01,377] INFO [UnifiedLog partition=__consumer_offsets-4, dir=/bitnami/kafka/data] Deleting segment files LogSegment(baseOffset=0, size=783, lastModifiedTime=1679402992455, largestRecordTimestamp=Some(1679402992453)) (kafka.log.LocalLog$)
kafka           | [2023-04-08 08:51:01,379] INFO Deleted log /bitnami/kafka/data/__consumer_offsets-4/00000000000000000000.log.deleted. (kafka.log.LogSegment)
kafka           | [2023-04-08 08:51:01,379] INFO Deleted offset index /bitnami/kafka/data/__consumer_offsets-4/00000000000000000000.index.deleted. (kafka.log.LogSegment)
kafka           | [2023-04-08 08:51:01,379] INFO Deleted time index /bitnami/kafka/data/__consumer_offsets-4/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
spark-worker-1  | 23/04/08 08:53:09 INFO Worker: Executor app-20230408084217-0000/0 finished with state EXITED message Command exited with code 56 exitStatus 56
spark-worker-1  | 23/04/08 08:53:09 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 0
spark-worker-1  | 23/04/08 08:53:09 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20230408084217-0000, execId=0)
spark           | 23/04/08 08:53:09 INFO Master: Removing executor app-20230408084217-0000/0 because it is EXITED
spark           | 23/04/08 08:53:09 INFO Master: Launching executor app-20230408084217-0000/1 on worker worker-20230408083931-172.20.0.6-44083
spark-worker-1  | 23/04/08 08:53:09 INFO Worker: Asked to launch executor app-20230408084217-0000/1 for frames-storage
spark-worker-1  | 23/04/08 08:53:09 INFO SecurityManager: Changing view acls to: spark
spark-worker-1  | 23/04/08 08:53:09 INFO SecurityManager: Changing modify acls to: spark
spark-worker-1  | 23/04/08 08:53:09 INFO SecurityManager: Changing view acls groups to: 
spark-worker-1  | 23/04/08 08:53:09 INFO SecurityManager: Changing modify acls groups to: 
spark-worker-1  | 23/04/08 08:53:09 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(spark); groups with view permissions: Set(); users  with modify permissions: Set(spark); groups with modify permissions: Set()
spark-worker-1  | 23/04/08 08:53:09 INFO ExecutorRunner: Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=32891" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@406ecabee5d0:32891" "--executor-id" "1" "--hostname" "172.20.0.6" "--cores" "1" "--app-id" "app-20230408084217-0000" "--worker-url" "spark://Worker@172.20.0.6:44083"
kafka           | [2023-04-08 08:54:54,179] INFO [Controller id=1] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
kafka           | [2023-04-08 08:54:54,184] TRACE [Controller id=1] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
kafka           | [2023-04-08 08:54:54,200] DEBUG [Controller id=1] Topics not in preferred replica for broker 1 Map() (kafka.controller.KafkaController)
kafka           | [2023-04-08 08:54:54,200] TRACE [Controller id=1] Leader imbalance ratio for broker 1 is 0.0 (kafka.controller.KafkaController)
spark-worker-1  | 23/04/08 08:59:20 INFO Worker: Executor app-20230408084217-0000/1 finished with state EXITED message Command exited with code 1 exitStatus 1
spark-worker-1  | 23/04/08 08:59:20 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 1
spark-worker-1  | 23/04/08 08:59:20 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20230408084217-0000, execId=1)
spark           | 23/04/08 08:59:20 INFO Master: Removing executor app-20230408084217-0000/1 because it is EXITED
spark           | 23/04/08 08:59:20 INFO Master: Launching executor app-20230408084217-0000/2 on worker worker-20230408083931-172.20.0.6-44083
spark-worker-1  | 23/04/08 08:59:20 INFO Worker: Asked to launch executor app-20230408084217-0000/2 for frames-storage
spark-worker-1  | 23/04/08 08:59:21 INFO SecurityManager: Changing view acls to: spark
spark-worker-1  | 23/04/08 08:59:21 INFO SecurityManager: Changing modify acls to: spark
spark-worker-1  | 23/04/08 08:59:21 INFO SecurityManager: Changing view acls groups to: 
spark-worker-1  | 23/04/08 08:59:21 INFO SecurityManager: Changing modify acls groups to: 
spark-worker-1  | 23/04/08 08:59:21 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(spark); groups with view permissions: Set(); users  with modify permissions: Set(spark); groups with modify permissions: Set()
spark-worker-1  | 23/04/08 08:59:21 INFO ExecutorRunner: Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=32891" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@406ecabee5d0:32891" "--executor-id" "2" "--hostname" "172.20.0.6" "--cores" "1" "--app-id" "app-20230408084217-0000" "--worker-url" "spark://Worker@172.20.0.6:44083"
kafka           | [2023-04-08 08:59:54,183] INFO [Controller id=1] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
kafka           | [2023-04-08 08:59:54,184] TRACE [Controller id=1] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
kafka           | [2023-04-08 08:59:54,189] DEBUG [Controller id=1] Topics not in preferred replica for broker 1 Map() (kafka.controller.KafkaController)
kafka           | [2023-04-08 08:59:54,189] TRACE [Controller id=1] Leader imbalance ratio for broker 1 is 0.0 (kafka.controller.KafkaController)
kafka           | [2023-04-08 09:04:54,177] INFO [Controller id=1] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
kafka           | [2023-04-08 09:04:54,181] TRACE [Controller id=1] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
kafka           | [2023-04-08 09:04:54,207] DEBUG [Controller id=1] Topics not in preferred replica for broker 1 Map() (kafka.controller.KafkaController)
kafka           | [2023-04-08 09:04:54,208] TRACE [Controller id=1] Leader imbalance ratio for broker 1 is 0.0 (kafka.controller.KafkaController)
spark-worker-1  | 23/04/08 09:05:30 INFO Worker: Executor app-20230408084217-0000/2 finished with state EXITED message Command exited with code 1 exitStatus 1
spark-worker-1  | 23/04/08 09:05:30 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 2
spark-worker-1  | 23/04/08 09:05:30 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20230408084217-0000, execId=2)
spark           | 23/04/08 09:05:30 INFO Master: Removing executor app-20230408084217-0000/2 because it is EXITED
spark           | 23/04/08 09:05:30 INFO Master: Launching executor app-20230408084217-0000/3 on worker worker-20230408083931-172.20.0.6-44083
spark-worker-1  | 23/04/08 09:05:30 INFO Worker: Asked to launch executor app-20230408084217-0000/3 for frames-storage
spark-worker-1  | 23/04/08 09:05:30 INFO SecurityManager: Changing view acls to: spark
spark-worker-1  | 23/04/08 09:05:30 INFO SecurityManager: Changing modify acls to: spark
spark-worker-1  | 23/04/08 09:05:30 INFO SecurityManager: Changing view acls groups to: 
spark-worker-1  | 23/04/08 09:05:30 INFO SecurityManager: Changing modify acls groups to: 
spark-worker-1  | 23/04/08 09:05:30 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(spark); groups with view permissions: Set(); users  with modify permissions: Set(spark); groups with modify permissions: Set()
spark-worker-1  | 23/04/08 09:05:30 INFO ExecutorRunner: Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=32891" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@406ecabee5d0:32891" "--executor-id" "3" "--hostname" "172.20.0.6" "--cores" "1" "--app-id" "app-20230408084217-0000" "--worker-url" "spark://Worker@172.20.0.6:44083"
kafka           | [2023-04-08 09:09:54,191] INFO [Controller id=1] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
kafka           | [2023-04-08 09:09:54,192] TRACE [Controller id=1] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
kafka           | [2023-04-08 09:09:54,196] DEBUG [Controller id=1] Topics not in preferred replica for broker 1 Map() (kafka.controller.KafkaController)
kafka           | [2023-04-08 09:09:54,197] TRACE [Controller id=1] Leader imbalance ratio for broker 1 is 0.0 (kafka.controller.KafkaController)
spark-worker-1  | 23/04/08 09:11:47 INFO Worker: Executor app-20230408084217-0000/3 finished with state EXITED message Command exited with code 1 exitStatus 1
spark-worker-1  | 23/04/08 09:11:47 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 3
spark-worker-1  | 23/04/08 09:11:47 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20230408084217-0000, execId=3)
spark           | 23/04/08 09:11:47 INFO Master: Removing executor app-20230408084217-0000/3 because it is EXITED
spark           | 23/04/08 09:11:47 INFO Master: Launching executor app-20230408084217-0000/4 on worker worker-20230408083931-172.20.0.6-44083
spark-worker-1  | 23/04/08 09:11:47 INFO Worker: Asked to launch executor app-20230408084217-0000/4 for frames-storage
spark-worker-1  | 23/04/08 09:11:47 INFO SecurityManager: Changing view acls to: spark
spark-worker-1  | 23/04/08 09:11:47 INFO SecurityManager: Changing modify acls to: spark
spark-worker-1  | 23/04/08 09:11:47 INFO SecurityManager: Changing view acls groups to: 
spark-worker-1  | 23/04/08 09:11:47 INFO SecurityManager: Changing modify acls groups to: 
spark-worker-1  | 23/04/08 09:11:47 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(spark); groups with view permissions: Set(); users  with modify permissions: Set(spark); groups with modify permissions: Set()
spark-worker-1  | 23/04/08 09:11:47 INFO ExecutorRunner: Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=32891" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@406ecabee5d0:32891" "--executor-id" "4" "--hostname" "172.20.0.6" "--cores" "1" "--app-id" "app-20230408084217-0000" "--worker-url" "spark://Worker@172.20.0.6:44083"
